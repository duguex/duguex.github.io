<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"tobedetermined.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="TODO">
<meta property="og:url" content="http://tobedetermined.com/page/2/index.html">
<meta property="og:site_name" content="TODO">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Mingzhe Liu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://tobedetermined.com/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>TODO</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">TODO</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Mingzhe Liu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/duguex" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;duguex" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:duguex@126.com" title="E-Mail → mailto:duguex@126.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/python/" class="post-title-link" itemprop="url">python</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 21:08:13" itemprop="dateCreated datePublished" datetime="2024-06-15T21:08:13+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:20" itemprop="dateModified" datetime="2024-07-30T00:45:20+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="排序的稳定性"><a href="#排序的稳定性" class="headerlink" title="排序的稳定性"></a>排序的稳定性</h1><p>numpy.argsort 函数是稳定的排序算法，它保证相等元素的相对顺序不会改变。</p>
<p>当 numpy.argsort 函数对数组进行排序时，它会返回一个索引数组，该数组指示原始数组中的元素在排序后的数组中的位置。如果两个元素在排序前相等，那么在排序后它们的相对顺序不会改变。</p>
<h1 id="conda-删除环境"><a href="#conda-删除环境" class="headerlink" title="conda 删除环境"></a>conda 删除环境</h1><p>conda remove -n glm4 –all</p>
<h1 id="清理conda缓存"><a href="#清理conda缓存" class="headerlink" title="清理conda缓存"></a>清理conda缓存</h1><p>conda clean –all </p>
<h1 id="install-py4vasp"><a href="#install-py4vasp" class="headerlink" title="install py4vasp"></a>install py4vasp</h1><p><a target="_blank" rel="noopener" href="https://github.com/vasp-dev/py4vasp">https://github.com/vasp-dev/py4vasp</a><br><a target="_blank" rel="noopener" href="https://vasp.at/py4vasp/latest/">https://vasp.at/py4vasp/latest/</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:vasp-dev/py4vasp.git</span><br><span class="line">conda create --name py4vasp-env python=3.8</span><br><span class="line">conda activate py4vasp-env</span><br><span class="line">conda install -c conda-forge poetry</span><br><span class="line">conda install -c conda-forge mdtraj</span><br><span class="line">poetry install</span><br><span class="line">poetry run pytest</span><br></pre></td></tr></table></figure>

<h1 id="material-project-api"><a href="#material-project-api" class="headerlink" title="material project api"></a>material project api</h1><p>pip install mp_api</p>
<p>mpcontribs-client not installed. Install the package to query MPContribs data, or construct pourbaix diagrams: ‘pip install mpcontribs-client’</p>
<p>conda install -c conda-forge mdtraj<br>pip install py4vasp</p>
<p>from mp_api.client import MPRester</p>
<p>DeprecationWarning: Accessing summary data through MPRester.summary is deprecated. Please use MPRester.materials.summary instead.</p>
<p>with MPRester(“your_api_key_here”) as mpr:<br>    #do stuff with mpr…</p>
<p><a target="_blank" rel="noopener" href="https://docs.materialsproject.org/downloading-data/using-the-api/querying-data">material project new api</a></p>
<h1 id="conda-update"><a href="#conda-update" class="headerlink" title="conda update"></a>conda update</h1><p>conda update –all<br>conda update numpy<br>conda update conda</p>
<p>conda remove numpy<br>conda clean –all</p>
<h1 id="remove-all-packages-installed-with-pip"><a href="#remove-all-packages-installed-with-pip" class="headerlink" title="remove all packages installed with pip"></a>remove all packages installed with pip</h1><p>pip freeze | xargs pip uninstall -y<br>pip cache purge</p>
<h2 id="remote-jupyter-setting"><a href="#remote-jupyter-setting" class="headerlink" title="remote jupyter setting"></a>remote jupyter setting</h2><p>conda install -c conda-forge jupyterlab<br>jupyter lab –generate-config</p>
<p>c.NotebookApp.ip &#x3D; ‘*’<br>c.NotebookApp.allow_remote_access &#x3D; True</p>
<h1 id="c-NotebookApp-open-browser-False"><a href="#c-NotebookApp-open-browser-False" class="headerlink" title="c.NotebookApp.open_browser &#x3D; False"></a>c.NotebookApp.open_browser &#x3D; False</h1><h1 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a>pytorch</h1><p>docker run –gpus all -it –rm nvcr.io&#x2F;nvidia&#x2F;pytorch:23.12-py3<br>docker run –gpus all –ipc&#x3D;host –ulimit memlock&#x3D;-1 –ulimit stack&#x3D;67108864 …<br>NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be<br>   insufficient for PyTorch.  NVIDIA recommends the use of the following flags:<br>   docker run –gpus all –ipc&#x3D;host –ulimit memlock&#x3D;-1 –ulimit stack&#x3D;67108864 …</p>
<p>docker run –gpus all –ipc&#x3D;host –ulimit memlock&#x3D;-1 –ulimit stack&#x3D;67108864 -it  nvcr.io&#x2F;nvidia&#x2F;pytorch:23.12-py3</p>
<h1 id="in-jupyter-notebook-cli"><a href="#in-jupyter-notebook-cli" class="headerlink" title="in jupyter notebook cli"></a>in jupyter notebook cli</h1><p>pip install vs python -m pip install<br>When installing packages using pip, the recommended approach is to use python -m pip install instead of pip install. Refer the Installing Python Modules documentation.</p>
<p>!pip install vs %pip install<br>Any command prefixed with ! is treated as a shell command in Jupyter cells. Thus !pip install <module> is treated as a simple shell command that translates to pip install <module>. However the recommendation is to use python -m pip install <module>. To get this desired behavior one must use %pip install <module></p>
<p>%conda install<br>However when installing packages in Jupyter into a conda environment, use of conda install is preferred over pip install. Hence its highly recommended that one use %conda install in jupyter notebooks when dealing with Conda enviornments.</p>
<p>More information<br>See here for further details <a target="_blank" rel="noopener" href="https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/">https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/</a></p>
<h1 id="去除重复conda-env-list-中环境"><a href="#去除重复conda-env-list-中环境" class="headerlink" title="去除重复conda env list 中环境"></a>去除重复conda env list 中环境</h1><p>remove C:\Users\dugue.conda\environments.txt</p>
<h1 id="super"><a href="#super" class="headerlink" title="super"></a>super</h1><p>super 是一个内置函数，用于调用父类（或超类）的方法。它常常用在 <strong>init</strong> 方法中，以确保父类的初始化方法被正确地调用，但它也可以用来调用父类中的其他方法。</p>
<p>子类 继承 基类&#x3D;&#x3D;父类&#x3D;&#x3D;超类</p>
<h1 id="enum-可以作为字典的键"><a href="#enum-可以作为字典的键" class="headerlink" title="enum 可以作为字典的键"></a>enum 可以作为字典的键</h1><p>在Python中，<code>enum</code>是一个枚举类型，它是一种特殊的类，用于创建一组有限且唯一的值。<code>RunType</code>可能是一个<code>enum</code>，它定义了一组相关的常量，这些常量可能代表了某种运行类型。</p>
<p>例如，<code>RunType</code>可能被定义为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RunType</span>(<span class="title class_ inherited__">Enum</span>):</span><br><span class="line">    TRAIN = <span class="number">1</span></span><br><span class="line">    TEST = <span class="number">2</span></span><br><span class="line">    VALIDATE = <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>RunType</code>是一个<code>enum</code>，它有三个成员：<code>TRAIN</code>，<code>TEST</code>和<code>VALIDATE</code>，它们分别被赋值为1，2和3。</p>
<p>然而，没有具体的代码或文档，我无法提供关于<code>RunType</code>的更多具体信息。你需要查看定义<code>RunType</code>的代码或文档以获取更多详细信息。</p>
<p>是的，Python中的枚举（enum）可以作为字典的键。这是因为枚举值在Python中是唯一的，因此它们可以用作字典的键。以下是一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Color</span>(<span class="title class_ inherited__">Enum</span>):</span><br><span class="line">    RED = <span class="number">1</span></span><br><span class="line">    GREEN = <span class="number">2</span></span><br><span class="line">    BLUE = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">color_dict = &#123;</span><br><span class="line">    Color.RED: <span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">    Color.GREEN: <span class="string">&#x27;green&#x27;</span>,</span><br><span class="line">    Color.BLUE: <span class="string">&#x27;blue&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(color_dict[Color.RED])  <span class="comment"># 输出：&#x27;red&#x27;</span></span><br></pre></td></tr></table></figure>

<p>在这个例子中，我们定义了一个名为<code>Color</code>的枚举，然后使用这个枚举的值作为字典<code>color_dict</code>的键。</p>
<h1 id="property-装饰器"><a href="#property-装饰器" class="headerlink" title="@property 装饰器"></a>@property 装饰器</h1><p>在Python中，<code>@property</code>是一个装饰器，它可以将一个方法转换为属性，使得你可以像访问属性一样访问这个方法，而不需要在调用它时加上括号。</p>
<p>以下是一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Circle</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, radius</span>):</span><br><span class="line">        self._radius = radius</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">radius</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._radius</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">diameter</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._radius * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">area</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">3.14</span> * self._radius ** <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>radius</code>、<code>diameter</code>和<code>area</code>都是属性，你可以像访问属性一样访问它们：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c = Circle(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(c.radius)  <span class="comment"># 输出：5</span></span><br><span class="line"><span class="built_in">print</span>(c.diameter)  <span class="comment"># 输出：10</span></span><br><span class="line"><span class="built_in">print</span>(c.area)  <span class="comment"># 输出：78.5</span></span><br></pre></td></tr></table></figure>

<p>注意，虽然<code>radius</code>、<code>diameter</code>和<code>area</code>看起来像属性，但它们实际上是方法。<code>@property</code>装饰器使得你可以像访问属性一样访问这些方法。</p>
<h1 id="Jupyter-notebook-文件路径"><a href="#Jupyter-notebook-文件路径" class="headerlink" title="Jupyter notebook 文件路径"></a>Jupyter notebook 文件路径</h1><p>如果你在 Jupyter notebook 中使用文件名（而不是完整的文件路径）来打开或写入文件，那么文件将会被写入到当前的工作目录中。你可以使用 Python 的 <code>os</code> 模块的 <code>getcwd</code> 函数来查看当前的工作目录。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="built_in">print</span>(os.getcwd())</span><br></pre></td></tr></table></figure>

<p>这将会打印出当前的工作目录。</p>
<p>如果你想改变当前的工作目录，你可以使用 <code>os</code> 模块的 <code>chdir</code> 函数。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.chdir(<span class="string">&#x27;/path/to/your/directory&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>然后，当你使用文件名来打开或写入文件时，文件将会被写入到新的工作目录中。</p>
<h1 id="mpi4py-conda"><a href="#mpi4py-conda" class="headerlink" title="mpi4py conda"></a>mpi4py conda</h1><p>conda install conda-forge::mpi4py<br>conda install anaconda::numpy scipy</p>
<h1 id="pytorch-cpu"><a href="#pytorch-cpu" class="headerlink" title="pytorch cpu"></a>pytorch cpu</h1><p>PyTorch 默认会使用所有可用的 CPU 核心来进行计算。然而，你可以通过设置环境变量 <code>OMP_NUM_THREADS</code> 来限制 PyTorch 使用的 CPU 核心数。</p>
<p>如果你想查看 PyTorch 实际使用了多少 CPU 核心，你可以使用 Python 的 <code>os</code> 模块来获取 <code>OMP_NUM_THREADS</code> 环境变量的值。以下是一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">num_threads = os.environ.get(<span class="string">&#x27;OMP_NUM_THREADS&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PyTorch is using <span class="subst">&#123;num_threads&#125;</span> CPU cores.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>如果 <code>OMP_NUM_THREADS</code> 环境变量没有被设置，那么 <code>os.environ.get(&#39;OMP_NUM_THREADS&#39;)</code> 将返回 <code>None</code>，这意味着 PyTorch 将使用所有可用的 CPU 核心。</p>
<p>请注意，这只是一个近似的方法，它可能无法准确地反映 PyTorch 实际使用的 CPU 核心数。如果你需要更精确的信息，你可能需要使用操作系统的工具（如 Linux 的 <code>top</code> 或 <code>htop</code> 命令）来监视 PyTorch 的 CPU 使用情况。</p>
<h1 id="pykan"><a href="#pykan" class="headerlink" title="pykan"></a>pykan</h1><p>actually install the latest version of python and other packages instead of following the instructions in the requirements.txt file</p>
<p>matplotlib&#x3D;&#x3D;3.6.2<br>numpy&#x3D;&#x3D;1.24.4<br>scikit_learn&#x3D;&#x3D;1.1.3<br>setuptools&#x3D;&#x3D;65.5.0<br>sympy&#x3D;&#x3D;1.11.1<br>torch&#x3D;&#x3D;2.2.2<br>tqdm&#x3D;&#x3D;4.66.2</p>
<p>matplotlib         3.9.0<br>numpy              1.26.4<br>scikit-learn       1.5.0<br>setuptools         68.0.0<br>sympy              1.12.1<br>torch              2.3.1+cu121<br>tqdm               4.66.4</p>
<p>conda create –name pykan-env python&#x3D;3.9.7<br>conda activate pykan-env<br>pip install git+<a target="_blank" rel="noopener" href="https://github.com/KindXiaoming/pykan.git">https://github.com/KindXiaoming/pykan.git</a>  # For GitHub installation</p>
<h1 id="or"><a href="#or" class="headerlink" title="or"></a>or</h1><p>pip install pykan  # For PyPI installation only pykan not with its requirements</p>
<p>pip install -r C:&#x2F;Users&#x2F;dugue&#x2F;Downloads&#x2F;pykan-master&#x2F;requirements.txt<br>pip install -r C:&#x2F;Users&#x2F;dugue&#x2F;Downloads&#x2F;pykan-master&#x2F;requirements_new.txt</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/get-started/locally/#windows-pip">https://pytorch.org/get-started/locally/#windows-pip</a><br>pip3 install torch torchvision torchaudio –index-url <a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/cu121">https://download.pytorch.org/whl/cu121</a></p>
<p>pip3 install –pre torch torchvision torchaudio –index-url <a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/nightly/cu124">https://download.pytorch.org/whl/nightly/cu124</a></p>
<p>cuda 12.2 pytorch cuda 12.1 mismatch but it works</p>
<p>在 PyKan 中，<code>beta</code> 是一个参数，它控制了 KAN (Kernelized Attention Network) 中的注意力机制的强度。<code>beta</code> 参数决定了模型在处理输入数据时，对于不同部分的关注程度。</p>
<p>具体来说，<code>beta</code> 参数控制了注意力权重的分布。较大的 <code>beta</code> 值会使得注意力权重更集中，即模型会更关注某些特定的输入部分。相反，较小的 <code>beta</code> 值会使得注意力权重更分散，即模型会更平均地关注所有的输入部分。</p>
<p>在训练模型时，<code>beta</code> 可以作为一个超参数进行调整，以找到最优的模型性能。</p>
<h1 id="pykan-with-large-network-scale-error"><a href="#pykan-with-large-network-scale-error" class="headerlink" title="pykan with large network scale error"></a>pykan with large network scale error</h1><p><a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/125892">https://github.com/pytorch/pytorch/issues/125892</a></p>
<p>File c:\Users\dugue\Downloads\pykan-master\kan\spline.py:138, in curve2coef(x_eval, y_eval, grid, k, device)<br>    136 mat &#x3D; B_batch(x_eval, grid, k, device&#x3D;device).permute(0, 2, 1)<br>    137 # coef &#x3D; torch.linalg.lstsq(mat, y_eval.unsqueeze(dim&#x3D;2)).solution[:, :, 0]<br>–&gt; 138 coef &#x3D; torch.linalg.lstsq(mat.to(device), y_eval.unsqueeze(dim&#x3D;2).to(device),<br>    139                           driver&#x3D;’gelsy’ if device &#x3D;&#x3D; ‘cpu’ else ‘gels’).solution[:, :, 0]<br>    140 return coef.to(device)</p>
<p>RuntimeError: false INTERNAL ASSERT FAILED at “..\aten\src\ATen\native\BatchLinearAlgebra.cpp”:1538, please report a bug to PyTorch. torch.linalg.lstsq: (Batch element 0): Argument 6 has illegal value. Most certainly there is a bug in the implementation calling the backend library.</p>
<p>I’m on it. Could you please share your environment versions by following commands?</p>
<p>wget <a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/pytorch/pytorch/main/torch/utils/collect_env.py">https://raw.githubusercontent.com/pytorch/pytorch/main/torch/utils/collect_env.py</a><br>python collect_env.py</p>
<p>It works fine on nightly version, you can install it by:<br>pip install –pre –upgrade torch torchvision torchaudio –index-url <a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/nightly">https://download.pytorch.org/whl/nightly</a></p>
<p>$ curl -fsSL <a target="_blank" rel="noopener" href="https://gist.githubusercontent.com/shink/ff8e666f17dd6f7f115cae2fae8e075b/raw/9d0d5e2047ac838174faa3cc626e068281bc5a84/kan.py">https://gist.githubusercontent.com/shink/ff8e666f17dd6f7f115cae2fae8e075b/raw/9d0d5e2047ac838174faa3cc626e068281bc5a84/kan.py</a> | python -<br>torch.Size([1000, 2])<br>torch.Size([1000, 1])<br>train loss: 1.21e-01 | test loss: 1.24e-01 | reg: 2.61e+01 : 100%|██| 20&#x2F;20 [00:38&lt;00:00,  1.94s&#x2F;it]<br>train loss: 1.82e-03 | test loss: 1.96e-03 | reg: 1.17e+01 : 100%|██| 50&#x2F;50 [01:00&lt;00:00,  1.21s&#x2F;it]<br>fixing (0,0,0) with x^4, r2&#x3D;0.8006412982940674<br>fixing (0,0,1) with sin, r2&#x3D;0.9999699592590332<br>fixing (0,1,0) with sin, r2&#x3D;0.9219197034835815<br>fixing (0,1,1) with x^2, r2&#x3D;0.9999983310699463<br>fixing (1,0,0) with log, r2&#x3D;0.7761432528495789<br>fixing (1,1,0) with exp, r2&#x3D;1.0000001192092896<br>train loss: nan | test loss: nan | reg: nan : 100%|█████████████████| 50&#x2F;50 [01:10&lt;00:00,  1.40s&#x2F;it]</p>
<p>$ python torch&#x2F;utils&#x2F;collect_env.py<br>Collecting environment information…<br>PyTorch version: 2.4.0.dev20240509<br>Is debug build: False<br>CUDA used to build PyTorch: None<br>ROCM used to build PyTorch: N&#x2F;A</p>
<p>OS: macOS 14.4.1 (arm64)<br>GCC version: Could not collect<br>Clang version: 15.0.0 (clang-1500.3.9.4)<br>CMake version: Could not collect<br>Libc version: N&#x2F;A</p>
<p>Python version: 3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ] (64-bit runtime)<br>Python platform: macOS-14.4.1-arm64-arm-64bit<br>Is CUDA available: False<br>CUDA runtime version: No CUDA<br>CUDA_MODULE_LOADING set to: N&#x2F;A<br>GPU models and configuration: No CUDA<br>Nvidia driver version: No CUDA<br>cuDNN version: No CUDA<br>HIP runtime version: N&#x2F;A<br>MIOpen runtime version: N&#x2F;A<br>Is XNNPACK available: True</p>
<p>CPU:<br>Apple M3 Pro</p>
<p>Versions of relevant libraries:<br>[pip3] numpy&#x3D;&#x3D;1.26.4<br>[pip3] torch&#x3D;&#x3D;2.4.0.dev20240509<br>[pip3] torchaudio&#x3D;&#x3D;2.2.0.dev20240509<br>[pip3] torchvision&#x3D;&#x3D;0.19.0.dev20240509<br>[conda] numpy                     1.26.4                   pypi_0    pypi<br>[conda] torch                     2.4.0.dev20240509          pypi_0    pypi<br>[conda] torchaudio                2.2.0.dev20240509          pypi_0    pypi<br>[conda] torchvision               0.19.0.dev20240509          pypi_0    pypi</p>
<p>要使<code>argparse</code>接受没有任何输入（即使定义了位置参数）而不引发错误，你需要将位置参数（<code>tags</code>）改为可选参数。这通常通过使用<code>-</code>或<code>--</code>前缀来实现。然而，如果你想保持<code>tags</code>作为一个不带<code>-</code>或<code>--</code>的参数，并允许用户不提供任何<code>tags</code>，你可以将<a href="command:_github.copilot.openSymbolFromReferences?%5B%7B%22%24mid%22%3A1%2C%22fsPath%22%3A%22c%3A%5C%5CUsers%5C%5Cdugue%5C%5C.vscode-insiders%5C%5Cextensions%5C%5Cms-python.vscode-pylance-2024.6.101%5C%5Cdist%5C%5Ctypeshed-fallback%5C%5Cstdlib%5C%5Cargparse.pyi%22%2C%22_sep%22%3A1%2C%22path%22%3A%22%2Fc%3A%2FUsers%2Fdugue%2F.vscode-insiders%2Fextensions%2Fms-python.vscode-pylance-2024.6.101%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fargparse.pyi%22%2C%22scheme%22%3A%22file%22%7D%2C%7B%22line%22%3A88%2C%22character%22%3A8%7D%5D" title="c:\Users\dugue.vscode-insiders\extensions\ms-python.vscode-pylance-2024.6.101\dist\typeshed-fallback\stdlib\argparse.pyi"><code>nargs</code></a>设置为<code>*</code>而不是<code>+</code>。这样，<code>tags</code>参数可以接受零个或多个输入值，如果用户没有提供任何值，<code>tags</code>将默认为一个空列表。</p>
<p>修改后的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;tags&quot;</span>,</span><br><span class="line">    nargs=<span class="string">&quot;*&quot;</span>,</span><br><span class="line">    default=[],</span><br><span class="line">    <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">    <span class="built_in">help</span>=<span class="string">&quot;specify the features of the job by tags.&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这样，如果用户没有提供任何<code>tags</code>，程序不会引发错误，并且<code>tags</code>参数将是一个空列表。</p>
<h1 id="popen-os-system"><a href="#popen-os-system" class="headerlink" title="popen os.system"></a>popen os.system</h1><p>在Python中，<a href="command:_github.copilot.openSymbolFromReferences?%5B%7B%22%24mid%22%3A1%2C%22fsPath%22%3A%22c%3A%5C%5CUsers%5C%5Cdugue%5C%5COneDrive%5C%5Cblog%5C%5Csource%5C%5C_posts%5C%5Cpython.md%22%2C%22_sep%22%3A1%2C%22path%22%3A%22%2Fc%3A%2FUsers%2Fdugue%2FOneDrive%2Fblog%2Fsource%2F_posts%2Fpython.md%22%2C%22scheme%22%3A%22file%22%7D%2C%7B%22line%22%3A347%2C%22character%22%3A0%7D%5D" title="c:\Users\dugue\OneDrive\blog\source_posts\python.md"><code>os.system</code></a>和<a href="command:_github.copilot.openSymbolFromReferences?%5B%7B%22%24mid%22%3A1%2C%22fsPath%22%3A%22c%3A%5C%5CUsers%5C%5Cdugue%5C%5COneDrive%5C%5Cblog%5C%5Csource%5C%5C_posts%5C%5Cpython.md%22%2C%22_sep%22%3A1%2C%22path%22%3A%22%2Fc%3A%2FUsers%2Fdugue%2FOneDrive%2Fblog%2Fsource%2F_posts%2Fpython.md%22%2C%22scheme%22%3A%22file%22%7D%2C%7B%22line%22%3A347%2C%22character%22%3A0%7D%5D" title="c:\Users\dugue\OneDrive\blog\source_posts\python.md"><code>os.popen</code></a>都用于执行外部命令，但它们在功能和用法上有一些关键区别：</p>
<h3 id="os-system"><a href="#os-system" class="headerlink" title="os.system"></a><a href="command:_github.copilot.openSymbolFromReferences?%5B%7B%22%24mid%22%3A1%2C%22fsPath%22%3A%22c%3A%5C%5CUsers%5C%5Cdugue%5C%5COneDrive%5C%5Cblog%5C%5Csource%5C%5C_posts%5C%5Cpython.md%22%2C%22_sep%22%3A1%2C%22path%22%3A%22%2Fc%3A%2FUsers%2Fdugue%2FOneDrive%2Fblog%2Fsource%2F_posts%2Fpython.md%22%2C%22scheme%22%3A%22file%22%7D%2C%7B%22line%22%3A347%2C%22character%22%3A0%7D%5D" title="c:\Users\dugue\OneDrive\blog\source_posts\python.md"><code>os.system</code></a></h3><ul>
<li><a href="command:_github.copilot.openSymbolFromReferences?%5B%7B%22%24mid%22%3A1%2C%22fsPath%22%3A%22c%3A%5C%5CUsers%5C%5Cdugue%5C%5COneDrive%5C%5Cblog%5C%5Csource%5C%5C_posts%5C%5Cpython.md%22%2C%22_sep%22%3A1%2C%22path%22%3A%22%2Fc%3A%2FUsers%2Fdugue%2FOneDrive%2Fblog%2Fsource%2F_posts%2Fpython.md%22%2C%22scheme%22%3A%22file%22%7D%2C%7B%22line%22%3A347%2C%22character%22%3A0%7D%5D" title="c:\Users\dugue\OneDrive\blog\source_posts\python.md"><code>os.system(command)</code></a>执行指定的命令并返回命令执行后的状态码（通常，0表示成功）。</li>
<li>它不返回命令的输出，只返回一个状态码。</li>
<li>执行期间，当前Python脚本会等待命令执行完成。</li>
<li>用法更简单，但功能较为基础。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">status = os.system(<span class="string">&#x27;echo Hello World&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Status:&#x27;</span>, status)</span><br></pre></td></tr></table></figure>

<h3 id="os-popen"><a href="#os-popen" class="headerlink" title="os.popen"></a><code>os.popen</code></h3><ul>
<li><code>os.popen(command)</code>执行指定的命令并返回一个文件对象，可以用来读取命令的标准输出。</li>
<li>通过这个文件对象，你可以获取命令的输出结果。</li>
<li>它允许更复杂的交互，比如读取命令的输出进行处理。</li>
<li><code>os.popen</code>已在较新版本的Python中被<code>subprocess</code>模块的功能所取代，但仍可用于简单的用途。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">stream = os.popen(<span class="string">&#x27;echo Hello World&#x27;</span>)</span><br><span class="line">output = stream.read()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Output:&#x27;</span>, output)</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>使用<a href="command:_github.copilot.openSymbolFromReferences?%5B%7B%22%24mid%22%3A1%2C%22fsPath%22%3A%22c%3A%5C%5CUsers%5C%5Cdugue%5C%5COneDrive%5C%5Cblog%5C%5Csource%5C%5C_posts%5C%5Cpython.md%22%2C%22_sep%22%3A1%2C%22path%22%3A%22%2Fc%3A%2FUsers%2Fdugue%2FOneDrive%2Fblog%2Fsource%2F_posts%2Fpython.md%22%2C%22scheme%22%3A%22file%22%7D%2C%7B%22line%22%3A347%2C%22character%22%3A0%7D%5D" title="c:\Users\dugue\OneDrive\blog\source_posts\python.md"><code>os.system</code></a>时，你只能知道命令是否成功执行（通过状态码），但不能获取命令的输出。</li>
<li>使用<a href="command:_github.copilot.openSymbolFromReferences?%5B%7B%22%24mid%22%3A1%2C%22fsPath%22%3A%22c%3A%5C%5CUsers%5C%5Cdugue%5C%5COneDrive%5C%5Cblog%5C%5Csource%5C%5C_posts%5C%5Cpython.md%22%2C%22_sep%22%3A1%2C%22path%22%3A%22%2Fc%3A%2FUsers%2Fdugue%2FOneDrive%2Fblog%2Fsource%2F_posts%2Fpython.md%22%2C%22scheme%22%3A%22file%22%7D%2C%7B%22line%22%3A347%2C%22character%22%3A0%7D%5D" title="c:\Users\dugue\OneDrive\blog\source_posts\python.md"><code>os.popen</code></a>时，你可以读取命令的输出，这对于需要处理或检查外部命令输出的情况非常有用。</li>
<li>对于更复杂的需求，如需要更细粒度的控制执行过程、环境变量、输入输出重定向等，推荐使用<code>subprocess</code>模块。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/resource-management/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/resource-management/" class="post-title-link" itemprop="url">resource_management</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 21:06:39" itemprop="dateCreated datePublished" datetime="2024-06-15T21:06:39+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:20" itemprop="dateModified" datetime="2024-07-30T00:45:20+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="python-ssh"><a href="#python-ssh" class="headerlink" title="python ssh"></a>python ssh</h1><p>Paramiko</p>
<p>在不同集群本地部署不同版本的命令<br>通过控制节点统一调度</p>
<p>核心知识点（亮点）：</p>
<ol>
<li>Python连接远程Linux服务器</li>
<li>执行命令并返回结果</li>
<li>上传文件到远程Linux服务器</li>
<li>从远程Linux下载文件</li>
</ol>
<h1 id="安装paramiko库"><a href="#安装paramiko库" class="headerlink" title="安装paramiko库"></a>安装paramiko库</h1><p>pip install ecdsa<br>pip install Crypto<br>pip install Twisted<br>pip install paramiko</p>
<h1 id="paramiko核心组件"><a href="#paramiko核心组件" class="headerlink" title="paramiko核心组件"></a>paramiko核心组件</h1><p>SSH组件：SSHClient，作用类似于Linux的ssh命令，用于执行远程命令。</p>
<p>SFTP组件：SFTPClient，作用类似于Linux的sftp命令，用于文件上传、下载、修改文件权限等。</p>
<h2 id="SSHClient"><a href="#SSHClient" class="headerlink" title="SSHClient"></a>SSHClient</h2><p>SSHClient常用方法介绍</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paramiko</span><br><span class="line">ip = <span class="string">&quot;远程Linux的IP地址&quot;</span></span><br><span class="line">port = <span class="number">22</span></span><br><span class="line">user = <span class="string">&quot;root&quot;</span></span><br><span class="line">password = <span class="string">&quot;密码&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SSHClient 实例对象</span></span><br><span class="line">ssh = paramiko.SSHClient()</span><br><span class="line"><span class="comment"># 调用方法，表示没有存储远程机器的公钥，允许访问</span></span><br><span class="line">ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())</span><br><span class="line"><span class="comment"># 连接远程机器，地址，端口，用户名密码</span></span><br><span class="line">ssh.connect(ip, port, user, password, timeout=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入linux命令</span></span><br><span class="line">command1 = <span class="string">&quot;ls&quot;</span></span><br><span class="line">ssh.exec_command(command1)</span><br><span class="line"><span class="comment"># stdout 为正确输出，stderr为错误输出</span></span><br><span class="line">stdin, stdout, stderr = ssh.exec_command(command2)</span><br><span class="line"><span class="comment"># 输出命令执行结果</span></span><br><span class="line">result = stdout.read()</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入linux命令</span></span><br><span class="line">command = <span class="string">&quot;cd /www/wwwroot ;ls&quot;</span></span><br><span class="line">stdin, stdout, stderr = ssh.exec_command(command)</span><br><span class="line"><span class="comment"># 输出命令执行结果</span></span><br><span class="line">result = stdout.read()</span><br><span class="line"><span class="comment"># bytes 转 str</span></span><br><span class="line">result = <span class="built_in">str</span>(result)</span><br><span class="line">result = result.split(<span class="string">&#x27;\\n&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">     <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<h2 id="SFTPClient"><a href="#SFTPClient" class="headerlink" title="SFTPClient"></a>SFTPClient</h2><p>SFTPClient常用方法介绍</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 获取Transport实例</span></span><br><span class="line">tran = paramiko.Transport((<span class="string">&#x27;远程Linux的ip&#x27;</span>, <span class="number">22</span>))</span><br><span class="line"><span class="comment"># 连接SSH服务端，使用password</span></span><br><span class="line">tran.connect(username=<span class="string">&quot;用户名&quot;</span>, password=<span class="string">&#x27;密码&#x27;</span>)</span><br><span class="line"><span class="comment"># 获取SFTP实例</span></span><br><span class="line">sftp = paramiko.SFTPClient.from_transport(tran)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上传的本地/远程文件路径</span></span><br><span class="line">localpath = <span class="string">&quot;D:/公众号/0603/辰哥.txt&quot;</span></span><br><span class="line">remotepath = <span class="string">&quot;/www/wwwroot//辰哥.txt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行上传动作</span></span><br><span class="line">sftp.put(localpath, remotepath)</span><br><span class="line"><span class="comment"># 关闭连接</span></span><br><span class="line">tran.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载文件</span></span><br><span class="line">localpath2 = <span class="string">&quot;D:/公众号/0603/Python研究者.txt&quot;</span></span><br><span class="line">remotepath2 = <span class="string">&quot;/www/wwwroot/Python研究者.txt&quot;</span></span><br><span class="line"><span class="comment"># 执行下载动作</span></span><br><span class="line">sftp.get(remotepath2, localpath2)</span><br><span class="line"><span class="comment"># 关闭连接</span></span><br><span class="line">tran.close()</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paramiko</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">creat_path</span>(<span class="params">Dir</span>):</span><br><span class="line">	<span class="comment"># localPath = filePath.rpartition(&quot;/&quot;)[0]</span></span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(Dir):</span><br><span class="line">		os.makedirs(Dir)	</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_log</span>(<span class="params">content</span>):</span><br><span class="line">	creat_path(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">	log = <span class="built_in">open</span>(<span class="string">&#x27;log/log&#x27;</span>+time.strftime(<span class="string">&quot;_%Y-%m-%d&quot;</span>, time.localtime())+<span class="string">&#x27;.txt&#x27;</span>, <span class="string">&quot;a&quot;</span>)</span><br><span class="line">	log.write(time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S &quot;</span>, time.localtime()) + content +<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SFTPConnector</span>:</span><br><span class="line">	<span class="comment"># paramiko log</span></span><br><span class="line">	creat_path(<span class="string">&#x27;./log/paramiko/&#x27;</span>)</span><br><span class="line">	paramiko.util.log_to_file(<span class="string">&#x27;./log/paramiko/log&#x27;</span> + time.strftime(<span class="string">&quot;_%Y-%m-%d&quot;</span>, time.localtime()))</span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hostname, port, username, password, keyFile</span>):</span><br><span class="line">		self.hostname = hostname</span><br><span class="line">		self.port = port</span><br><span class="line">		self.username = username</span><br><span class="line">		self.password = password</span><br><span class="line">		self.keyFile = keyFile</span><br><span class="line"></span><br><span class="line">		self.transport = self._init_transport()</span><br><span class="line">		self.sftpClient = self._init_sftp_client()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">_init_transport</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="comment"># 配置私钥</span></span><br><span class="line">		sftp_key = paramiko.RSAKey.from_private_key_file(self.keyFile,self.password)</span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">			<span class="comment"># 获取Transport会话实例</span></span><br><span class="line">			transport = paramiko.Transport((self.hostname, self.port))</span><br><span class="line">			<span class="comment"># 连接SSH服务端</span></span><br><span class="line">			<span class="comment"># # 多重验证不能用connect</span></span><br><span class="line">			<span class="comment"># # transport.connect(username=username, password=password, pkey=sftp_key)</span></span><br><span class="line">			<span class="comment"># transport.connect()</span></span><br><span class="line">			transport.start_client(event=<span class="literal">None</span>, timeout=<span class="number">15</span>)</span><br><span class="line">			transport.get_remote_server_key()</span><br><span class="line">			transport.auth_publickey(username=self.username, key=sftp_key)</span><br><span class="line">			<span class="comment"># # multi-step authentication有bug</span></span><br><span class="line">			<span class="comment"># # tran.auth_password(username, password, event=None)</span></span><br><span class="line">			<span class="comment"># 手动发送二次验证 https://github.com/paramiko/paramiko/issues/894</span></span><br><span class="line">			msg = paramiko.Message()</span><br><span class="line">			msg.add_byte(paramiko.common.cMSG_USERAUTH_REQUEST)</span><br><span class="line">			msg.add_string(self.username)</span><br><span class="line">			msg.add_string(<span class="string">&#x27;ssh-connection&#x27;</span>)</span><br><span class="line">			msg.add_string(<span class="string">&#x27;password&#x27;</span>)</span><br><span class="line">			msg.add_boolean(<span class="literal">False</span>)</span><br><span class="line">			<span class="comment"># cast bytes or unicode to unicode</span></span><br><span class="line">			py3_password = paramiko.py3compat.u(self.password)</span><br><span class="line">			msg.add_string(py3_password)</span><br><span class="line">			transport._send_message(msg)</span><br><span class="line">			<span class="keyword">return</span> transport</span><br><span class="line">		<span class="keyword">except</span> SSHException <span class="keyword">as</span> e:</span><br><span class="line">			save_log(<span class="string">&#x27;++ERROR++ SSH connect exception:&#x27;</span>,e)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">_init_sftp_client</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">			<span class="comment"># 获取SFTP实例</span></span><br><span class="line">			sftpClient = paramiko.SFTPClient.from_transport(self.transport)</span><br><span class="line">			<span class="keyword">return</span> sftpClient	</span><br><span class="line">		<span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">			save_log(<span class="string">&#x27;++ERROR++ SFTP exception:&#x27;</span>,e)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>how to login a remote server with both password and One-Time Password by paramiko</p>
<p>conda install conda-forge::pyotp<br>conda install anaconda::pip<br>pip install paramiko<br><em>conda install anaconda::paramiko</em></p>
<h1 id="next-terminal"><a href="#next-terminal" class="headerlink" title="next terminal"></a>next terminal</h1><p><a target="_blank" rel="noopener" href="https://github.com/dushixiang/next-terminal">text</a></p>
<h1 id="next-terminal-1"><a href="#next-terminal-1" class="headerlink" title="next-terminal"></a>next-terminal</h1><p>version: ‘3.3’<br>services:<br>  guacd:<br>    image: dushixiang&#x2F;guacd:latest<br>    volumes:<br>      - .&#x2F;data:&#x2F;usr&#x2F;local&#x2F;next-terminal&#x2F;data<br>    restart:<br>          always<br>  next-terminal:<br>    image: dushixiang&#x2F;next-terminal:latest<br>    environment:<br>      DB: sqlite<br>      GUACD_HOSTNAME: guacd<br>      GUACD_PORT: 4822<br>    ports:<br>      - “8088:8088”<br>    volumes:<br>      - &#x2F;etc&#x2F;localtime:&#x2F;etc&#x2F;localtime<br>      - .&#x2F;data:&#x2F;usr&#x2F;local&#x2F;next-terminal&#x2F;data<br>    restart:<br>      always</p>
<h1 id="semaphore"><a href="#semaphore" class="headerlink" title="semaphore"></a>semaphore</h1><p>services:</p>
<h1 id="uncomment-this-section-and-comment-out-the-mysql-section-to-use-postgres-instead-of-mysql"><a href="#uncomment-this-section-and-comment-out-the-mysql-section-to-use-postgres-instead-of-mysql" class="headerlink" title="uncomment this section and comment out the mysql section to use postgres instead of mysql"></a>uncomment this section and comment out the mysql section to use postgres instead of mysql</h1><p>  #postgres:<br>    #restart: unless-stopped<br>    #image: postgres:14<br>    #hostname: postgres<br>    #volumes:<br>    #  - semaphore-postgres:&#x2F;var&#x2F;lib&#x2F;postgresql&#x2F;data<br>    #environment:<br>    #  POSTGRES_USER: semaphore<br>    #  POSTGRES_PASSWORD: semaphore<br>    #  POSTGRES_DB: semaphore</p>
<h1 id="if-you-wish-to-use-postgres-comment-the-mysql-service-section-below"><a href="#if-you-wish-to-use-postgres-comment-the-mysql-service-section-below" class="headerlink" title="if you wish to use postgres, comment the mysql service section below"></a>if you wish to use postgres, comment the mysql service section below</h1><p>  mysql:<br>    restart: unless-stopped<br>    image: mysql:8.0<br>    hostname: mysql<br>    volumes:<br>      - semaphore-mysql:&#x2F;var&#x2F;lib&#x2F;mysql<br>    environment:<br>      MYSQL_RANDOM_ROOT_PASSWORD: ‘yes’<br>      MYSQL_DATABASE: semaphore<br>      MYSQL_USER: semaphore<br>      MYSQL_PASSWORD: semaphore<br>  semaphore:<br>    restart: unless-stopped<br>    ports:<br>      - 3000:3000<br>    image: semaphoreui&#x2F;semaphore:latest<br>    environment:<br>      SEMAPHORE_DB_USER: semaphore<br>      SEMAPHORE_DB_PASS: semaphore<br>      SEMAPHORE_DB_HOST: mysql # for postgres, change to: postgres<br>      SEMAPHORE_DB_PORT: 3306 # change to 5432 for postgres<br>      SEMAPHORE_DB_DIALECT: mysql # for postgres, change to: postgres<br>      SEMAPHORE_DB: semaphore<br>      SEMAPHORE_PLAYBOOK_PATH: &#x2F;tmp&#x2F;semaphore&#x2F;<br>      SEMAPHORE_ADMIN_PASSWORD: changeme<br>      SEMAPHORE_ADMIN_NAME: admin<br>      SEMAPHORE_ADMIN_EMAIL: admin@localhost<br>      SEMAPHORE_ADMIN: admin<br>      SEMAPHORE_ACCESS_KEY_ENCRYPTION: gs72mPntFATGJs9qK0pQ0rKtfidlexiMjYCH9gWKhTU&#x3D;<br>      SEMAPHORE_LDAP_ACTIVATED: ‘no’ # if you wish to use ldap, set to: ‘yes’<br>      SEMAPHORE_LDAP_HOST: dc01.local.example.com<br>      SEMAPHORE_LDAP_PORT: ‘636’<br>      SEMAPHORE_LDAP_NEEDTLS: ‘yes’<br>      SEMAPHORE_LDAP_DN_BIND: ‘uid&#x3D;bind_user,cn&#x3D;users,cn&#x3D;accounts,dc&#x3D;local,dc&#x3D;shiftsystems,dc&#x3D;net’<br>      SEMAPHORE_LDAP_PASSWORD: ‘ldap_bind_account_password’<br>      SEMAPHORE_LDAP_DN_SEARCH: ‘dc&#x3D;local,dc&#x3D;example,dc&#x3D;com’<br>      SEMAPHORE_LDAP_SEARCH_FILTER: “(\u0026(uid&#x3D;%s)(memberOf&#x3D;cn&#x3D;ipausers,cn&#x3D;groups,cn&#x3D;accounts,dc&#x3D;local,dc&#x3D;example,dc&#x3D;com))”<br>    depends_on:<br>      - mysql # for postgres, change to: postgres<br>volumes:<br>  semaphore-mysql: # to use postgres, switch to: semaphore-postgres</p>
<p>how to deal “sh: .ssh&#x2F;authorized_keys: Permission denied” when doing ssh-copy-id on remote server?<br>~&#x2F;.ssh&#x2F;authorized_keys</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/linux/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/linux/" class="post-title-link" itemprop="url">linux</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 21:04:09" itemprop="dateCreated datePublished" datetime="2024-06-15T21:04:09+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:20" itemprop="dateModified" datetime="2024-07-30T00:45:20+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="install-deb-package"><a href="#install-deb-package" class="headerlink" title="install deb package"></a>install deb package</h1><p>GitHub Copilot: You can install a <code>.deb</code> package on Ubuntu using the <code>dpkg</code> command. Here are the steps:</p>
<ol>
<li><p>Open a terminal window.</p>
</li>
<li><p>Navigate to the directory where the <code>.deb</code> package is located.</p>
</li>
<li><p>Run the following command to install the package:</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i package_name.deb</span><br></pre></td></tr></table></figure>

<p>Replace <code>package_name.deb</code> with the name of the <code>.deb</code> package you want to install.</p>
<ol start="4">
<li>If the installation is successful, you can run the following command to check the installed package:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg -l | grep package_name</span><br></pre></td></tr></table></figure>

<p>Replace <code>package_name</code> with the name of the package you just installed.</p>
<p>This will display information about the installed package, including the version number.</p>
<p>Note that you may need to have root privileges to install a <code>.deb</code> package.</p>
<h1 id="tee"><a href="#tee" class="headerlink" title="tee"></a>tee</h1><p>在 Unix&#x2F;Linux shell 中，你可以使用 <code>tee</code> 命令将输出同时发送到屏幕和文件。以下是一个示例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello, World!&quot;</span> | <span class="built_in">tee</span> output.txt</span><br></pre></td></tr></table></figure>

<p>在这个示例中，<code>echo &quot;Hello, World!&quot;</code> 会产生一个消息，然后 <code>|</code> 将这个消息传递给 <code>tee output.txt</code>。<code>tee</code> 命令会将接收到的输入同时显示在屏幕上，并写入到 <code>output.txt</code> 文件中。</p>
<p>如果你想在已有的文件后面追加消息，而不是覆盖文件，你可以使用 <code>-a</code> 选项：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello, World!&quot;</span> | <span class="built_in">tee</span> -a output.txt</span><br></pre></td></tr></table></figure>

<p>在这个示例中，<code>tee -a output.txt</code> 会将接收到的输入追加到 <code>output.txt</code> 文件的末尾，而不是覆盖文件。</p>
<p>在 Linux 系统中，你可以使用 <code>tail -f</code> 命令来查看一个正在写入的文件。这个命令会显示文件的最后几行，并且当文件被更新时，新的内容会被立即显示出来。</p>
<p>以下是基本的使用方法：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">tail</span> -f &lt;filename&gt;</span><br></pre></td></tr></table></figure>

<p>在这个命令中，<code>&lt;filename&gt;</code> 是你想要查看的文件的名称。</p>
<p>例如，如果你想要查看一个名为 <code>logfile.log</code> 的正在写入的文件，你可以运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">tail</span> -f logfile.log</span><br></pre></td></tr></table></figure>

<p>这个命令会显示 <code>logfile.log</code> 文件的最后几行，当 <code>logfile.log</code> 文件被更新时，新的内容会被立即显示出来。</p>
<p>请注意，<code>tail -f</code> 命令会一直运行，直到你按下 <code>Ctrl + C</code> 来停止它。</p>
<h1 id="install-miniconda-on-linux"><a href="#install-miniconda-on-linux" class="headerlink" title="install miniconda on linux"></a>install miniconda on linux</h1><p>These four commands quickly and quietly install the latest 64-bit version of the installer and then clean up after themselves. To install a different version or architecture of Miniconda for Linux, change the name of the .sh installer in the wget command.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/miniconda3</span><br><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh</span><br><span class="line">bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3</span><br><span class="line">rm -rf ~/miniconda3/miniconda.sh</span><br></pre></td></tr></table></figure>

<p>After installing, initialize your newly-installed Miniconda. The following commands initialize for bash and zsh shells:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~/miniconda3/bin/conda init bash</span><br><span class="line">~/miniconda3/bin/conda init zsh</span><br></pre></td></tr></table></figure>

<h1 id="nvidia-smi"><a href="#nvidia-smi" class="headerlink" title="nvidia-smi"></a>nvidia-smi</h1><p>System Management Interface<br>Sun Oct  1 07:44:46 2023<br>+—————————————————————————————+<br>| NVIDIA-SMI 535.104.07             Driver Version: 537.34       CUDA Version: 12.2     |<br>|—————————————–+———————-+———————-+<br>| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>| Fan  Temp   Perf          Pwr:Usage&#x2F;Cap |         Memory-Usage | GPU-Util  Compute M. |<br>|                                         |                      |               MIG M. |<br>|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|<br>|   0  NVIDIA GeForce RTX 3060 …    On  | 00000000:07:00.0  On |                  N&#x2F;A |<br>| N&#x2F;A   47C    P8              15W &#x2F; 115W |    548MiB &#x2F;  6144MiB |      5%      Default |<br>|                                         |                      |                  N&#x2F;A |<br>+—————————————–+———————-+———————-+</p>
<p>+—————————————————————————————+<br>| Processes:                                                                            |<br>|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |<br>|        ID   ID                                                             Usage      |<br>|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|<br>|    0   N&#x2F;A  N&#x2F;A        23      G   &#x2F;Xwayland                                 N&#x2F;A      |<br>+—————————————————————————————+</p>
<h1 id="scp"><a href="#scp" class="headerlink" title="scp"></a>scp</h1><p>scp -P 22 -r source_directory username@destination:&#x2F;path&#x2F;to&#x2F;destination</p>
<p>在两台服务器之间设置 SSH 公钥认证，你需要按照以下步骤操作：</p>
<ol>
<li>在源服务器上生成 SSH 密钥对。如果你已经有一个密钥对，你可以跳过这一步。在终端中输入以下命令：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure>

<p>按照提示进行操作。这将在你的 <code>~/.ssh</code> 目录下生成两个文件：<code>id_rsa</code>（私钥）和 <code>id_rsa.pub</code>（公钥）。</p>
<ol start="2">
<li>将你的公钥复制到目标服务器。你可以使用 <code>ssh-copy-id</code> 命令来完成这一步。在终端中输入以下命令：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id username@destination</span><br></pre></td></tr></table></figure>
<p>ssh-copy-id <a href="mailto:&#x71;&#x69;&#102;&#64;&#x32;&#49;&#x31;&#x2e;&#x38;&#x36;&#46;&#49;&#x35;&#49;&#46;&#x31;&#48;&#54;">&#x71;&#x69;&#102;&#64;&#x32;&#49;&#x31;&#x2e;&#x38;&#x36;&#46;&#49;&#x35;&#49;&#46;&#x31;&#48;&#54;</a></p>
<p>ssh-copy-id <a href="mailto:&#99;&#x6b;&#100;&#x75;&#97;&#110;&#x31;&#64;&#x32;&#x31;&#49;&#46;&#56;&#54;&#x2e;&#x31;&#53;&#x31;&#46;&#x31;&#x30;&#x36;">&#99;&#x6b;&#100;&#x75;&#97;&#110;&#x31;&#64;&#x32;&#x31;&#49;&#46;&#56;&#54;&#x2e;&#x31;&#53;&#x31;&#46;&#x31;&#x30;&#x36;</a><br>在这个命令中，<code>username@destination</code> 是目标服务器的用户名和地址。这个命令会提示你输入目标服务器的密码。</p>
<p>完成以上步骤后，你就可以在不输入密码的情况下从源服务器 SSH 到目标服务器了。这也意味着你可以使用 <code>scp</code> 命令在两台服务器之间复制文件或目录，而不需要输入密码。</p>
<h1 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a>ssh</h1><p>在 Ubuntu 上配置 SSH 首次使用，你可以按照以下步骤进行：</p>
<ol>
<li>首先，你需要安装 OpenSSH 服务器。在终端中输入以下命令：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>安装完成后，SSH 服务应该会自动启动。你可以使用以下命令来检查 SSH 服务的状态：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status ssh</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>如果你需要在启动时自动启动 SSH 服务，你可以使用以下命令：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl <span class="built_in">enable</span> ssh</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>默认情况下，你应该已经可以通过 SSH 连接到你的机器了。如果你想修改 SSH 的配置（例如更改默认的端口号或禁用密码认证），你可以编辑 <code>/etc/ssh/sshd_config</code> 文件。编辑完成后，你需要重启 SSH 服务以使更改生效：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart ssh</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>在客户端机器上，你可以使用 <code>ssh</code> 命令和你的用户名以及服务器的 IP 地址来连接到服务器：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh username@server_ip</span><br></pre></td></tr></table></figure>

<p>请注意，以上步骤可能需要管理员权限。</p>
<h1 id="wget"><a href="#wget" class="headerlink" title="wget"></a>wget</h1><p>wget：这是一个自由的网络下载工具，可以从网络上下载文件。<br>-q：这是 wget 的一个选项，表示 “quiet”（安静）。当这个选项被使用时，wget 不会输出任何下载进度信息。<br>O -：这是 wget 的一个选项，表示将下载的文件输出到标准输出（stdout）。- 表示标准输出。<br><a target="_blank" rel="noopener" href="https://apt.v2raya.mzz.pub/key/public-key.asc%EF%BC%9A%E8%BF%99%E6%98%AF%E4%BD%A0%E6%83%B3%E8%A6%81%E4%B8%8B%E8%BD%BD%E7%9A%84%E6%96%87%E4%BB%B6%E7%9A%84">https://apt.v2raya.mzz.pub/key/public-key.asc：这是你想要下载的文件的</a> URL。<br>因此，wget -qO - <a target="_blank" rel="noopener" href="https://apt.v2raya.mzz.pub/key/public-key.asc">https://apt.v2raya.mzz.pub/key/public-key.asc</a> 命令会安静地从指定的 URL 下载文件，并将其输出到标准输出。这个命令通常与其他命令一起使用，例如 apt-key add - 或 gpg –import -，来添加 GPG 密钥。</p>
<h1 id="ubuntu-install-conda"><a href="#ubuntu-install-conda" class="headerlink" title="ubuntu install conda"></a>ubuntu install conda</h1><h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><p>sudo apt update &amp;&amp; sudo apt upgrade &amp;&amp; sudo apt install curl gpg &amp;&amp; curl <a target="_blank" rel="noopener" href="https://repo.anaconda.com/pkgs/misc/gpgkeys/anaconda.asc">https://repo.anaconda.com/pkgs/misc/gpgkeys/anaconda.asc</a> | gpg –dearmor &gt; conda.gpg &amp;&amp; sudo install -o root -g root -m 644 conda.gpg &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;conda-archive-keyring.gpg &amp;&amp; gpg –keyring &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;conda-archive-keyring.gpg –no-default-keyring –fingerprint 34161F5BF5EB1D4BFBBB8F0A8AEB4F8B29D82806 &amp;&amp; sudo echo “deb [arch&#x3D;amd64 signed-by&#x3D;&#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;conda-archive-keyring.gpg] <a target="_blank" rel="noopener" href="https://repo.anaconda.com/pkgs/misc/debrepo/conda">https://repo.anaconda.com/pkgs/misc/debrepo/conda</a> stable main” | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;conda.list &amp;&amp; sudo apt update &amp;&amp; sudo apt install conda;</p>
<h2 id="config"><a href="#config" class="headerlink" title="config"></a>config</h2><p>source &#x2F;opt&#x2F;conda&#x2F;etc&#x2F;profile.d&#x2F;conda.sh &amp;&amp; conda init;</p>
<p>sudo apt update &amp;&amp; sudo apt upgrade &amp;&amp; sudo apt install curl gpg &amp;&amp; curl <a target="_blank" rel="noopener" href="https://repo.anaconda.com/pkgs/misc/gpgkeys/anaconda.asc">https://repo.anaconda.com/pkgs/misc/gpgkeys/anaconda.asc</a> | gpg –dearmor &gt; conda.gpg &amp;&amp; sudo install -o root -g root -m 644 conda.gpg &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;conda-archive-keyring.gpg &amp;&amp; gpg –keyring &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;conda-archive-keyring.gpg –no-default-keyring –fingerprint 34161F5BF5EB1D4BFBBB8F0A8AEB4F8B29D82806 &amp;&amp; sudo echo “deb [arch&#x3D;amd64 signed-by&#x3D;&#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;conda-archive-keyring.gpg] <a target="_blank" rel="noopener" href="https://repo.anaconda.com/pkgs/misc/debrepo/conda">https://repo.anaconda.com/pkgs/misc/debrepo/conda</a> stable main” | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;conda.list &amp;&amp; sudo apt update &amp;&amp; sudo apt install conda &amp;&amp; source &#x2F;opt&#x2F;conda&#x2F;etc&#x2F;profile.d&#x2F;conda.sh &amp;&amp; conda init;</p>
<p>conda create -n zfs -y &amp;&amp; conda activate zfs &amp;&amp; conda install -c conda-forge -y mpi4py &amp;&amp; conda install -c anaconda -y numpy scipy</p>
<h1 id="install-oneapi"><a href="#install-oneapi" class="headerlink" title="install oneapi"></a>install oneapi</h1><p>apt install gpg wget</p>
<p>wget -O- <a target="_blank" rel="noopener" href="https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB">https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB</a> | gpg –dearmor | tee &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;oneapi-archive-keyring.gpg &gt; &#x2F;dev&#x2F;null;</p>
<p>echo “deb [signed-by&#x3D;&#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;oneapi-archive-keyring.gpg] <a target="_blank" rel="noopener" href="https://apt.repos.intel.com/oneapi">https://apt.repos.intel.com/oneapi</a> all main” | tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;oneAPI.list;</p>
<p>apt update;<br>apt install -y intel-basekit intel-hpckit;</p>
<p>–report-bindings：这是一个选项，表示报告每个 MPI 进程的绑定信息。绑定信息是指每个 MPI 进程被绑定到哪些 CPU 核心上。</p>
<p>-np $NUM_MPI_RANKS：这是一个选项，表示启动的 MPI 进程数。$NUM_MPI_RANKS 是一个环境变量，表示 MPI 进程数。</p>
<p>${2}：这是一个 shell 变量，表示命令行的第二个参数。</p>
<p>–map-by ppr:${MPI_RANK_L3}:l3cache:pe&#x3D;$OMP_NUM_THREADS：这是一个选项，表示如何将 MPI 进程映射到 CPU 核心上。ppr:${MPI_RANK_L3}:l3cache 表示每个 L3 缓存区域有 ${MPI_RANK_L3} 个 MPI 进程，pe&#x3D;$OMP_NUM_THREADS 表示每个 MPI 进程有 $OMP_NUM_THREADS 个并行执行的线程。</p>
<p>-x UCX_TLS&#x3D;self,sm,rc_x：这是一个选项，表示设置环境变量 UCX_TLS 的值为 self,sm,rc_x。UCX_TLS 是 UCX（Unified Communication X）的一个环境变量，用于指定通信的传输层。</p>
<h1 id="xrdp-connect-to-ubuntu"><a href="#xrdp-connect-to-ubuntu" class="headerlink" title="xrdp connect to ubuntu"></a>xrdp connect to ubuntu</h1><p>need logout locally and login remotely</p>
<h1 id="apt-intall-openmpi"><a href="#apt-intall-openmpi" class="headerlink" title="apt intall openmpi"></a>apt intall openmpi</h1><p>sudo apt install libopenmpi-dev</p>
<h1 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h1><p>在 sed 命令中，你可以使用任何字符作为分隔符，只要它不出现在模式或替换字符串中。所以，如果你想要替换 &#x2F; 字符，你可以选择一个不会出现在你的模式或替换字符串中的字符作为分隔符。</p>
<p>例如，你可以使用 # 作为分隔符，将 &#x2F; 替换为空格：</p>
<p>在这个命令中，s 是 sed 的替换命令，# 是分隔符，&#x2F; 是你要替换的模式， （空格）是你要替换成的字符串，g 是一个选项，表示全局替换（替换每一行中的所有匹配）。</p>
<h1 id="ZFS文件系统挂载硬盘"><a href="#ZFS文件系统挂载硬盘" class="headerlink" title="ZFS文件系统挂载硬盘"></a>ZFS文件系统挂载硬盘</h1><p>lsblk -f<br>df -h<br>zpool list rpool<br>sudo zpool add rpool &#x2F;dev&#x2F;sdc<br>zpool status rpool</p>
<h1 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h1><p>docker run -it –gpus&#x3D;all –rm nvcr.io&#x2F;nvidia&#x2F;k8s&#x2F;cuda-sample:nbody nbody -benchmark</p>
<p>Run “nbody -benchmark [-numbodies&#x3D;<numBodies>]” to measure performance.<br>        -fullscreen       (run n-body simulation in fullscreen mode)<br>        -fp64             (use double precision floating point values for simulation)<br>        -hostmem          (stores simulation data in host memory)<br>        -benchmark        (run benchmark to measure performance)<br>        -numbodies&#x3D;<N>    (number of bodies (&gt;&#x3D; 1) to run in simulation)<br>        -device&#x3D;<d>       (where d&#x3D;0,1,2…. for the CUDA device to use)<br>        -numdevices&#x3D;<i>   (where i&#x3D;(number of CUDA devices &gt; 0) to use for simulation)<br>        -compare          (compares simulation results running once on the default GPU and once on the CPU)<br>        -cpu              (run n-body simulation on the CPU)<br>        -tipsy&#x3D;&lt;file.bin&gt; (load a tipsy model file for simulation)</p>
<blockquote>
<p>Compute 8.6 CUDA device: [NVIDIA GeForce RTX 3060 Laptop GPU]<br>30720 bodies, total time for 10 iterations: 26.021 ms<br>&#x3D; 362.678 billion interactions per second<br>&#x3D; 7253.551 single-precision GFLOP&#x2F;s at 20 flops per interaction</p>
</blockquote>
<p><img src="/image-12.png" alt="docker and cuda"></p>
<h1 id="NVIDIA-Container-Toolkit"><a href="#NVIDIA-Container-Toolkit" class="headerlink" title="NVIDIA Container Toolkit"></a>NVIDIA Container Toolkit</h1><p><a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/NVIDIA/nvidia-docker/master/LICENSE"><img src="https://img.shields.io/github/license/NVIDIA/nvidia-docker?style=flat-square" alt="GitHub license"></a><br><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/nvidia-docker/wiki"><img src="https://img.shields.io/badge/documentation-wiki-blue.svg?style=flat-square" alt="Documentation"></a><br><a target="_blank" rel="noopener" href="https://nvidia.github.io/nvidia-docker"><img src="https://img.shields.io/badge/packages-repository-b956e8.svg?style=flat-square" alt="Package repository"></a></p>
<p><img src="https://cloud.githubusercontent.com/assets/3028125/12213714/5b208976-b632-11e5-8406-38d379ec46aa.png" alt="nvidia-gpu-docker"></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>The NVIDIA Container Toolkit allows users to build and run GPU accelerated Docker containers. The toolkit includes a container runtime <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/libnvidia-container">library</a> and utilities to automatically configure containers to leverage NVIDIA GPUs. </p>
<p>Product documentation including an architecture overview, platform support, installation and usage guides can be found in the <a target="_blank" rel="noopener" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html">documentation repository</a>. </p>
<p>Frequently asked questions are available on the <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/nvidia-docker/wiki">wiki</a>.</p>
<h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-with-apt">https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-with-apt</a></p>
<p><strong>Make sure you have installed the <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/nvidia-docker/wiki/Frequently-Asked-Questions#how-do-i-install-the-nvidia-driver">NVIDIA driver</a> and Docker engine for your Linux distribution</strong><br><strong>Note that you do not need to install the CUDA Toolkit on the host system, but the NVIDIA driver needs to be installed</strong></p>
<p>For instructions on getting started with the NVIDIA Container Toolkit, refer to the <a target="_blank" rel="noopener" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker">installation guide</a>. </p>
<p>Installing with Apt<br>Configure the repository:</p>
<p>curl -fsSL <a target="_blank" rel="noopener" href="https://nvidia.github.io/libnvidia-container/gpgkey">https://nvidia.github.io/libnvidia-container/gpgkey</a> | sudo gpg –dearmor -o &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;nvidia-container-toolkit-keyring.gpg <br>  &amp;&amp; curl -s -L <a target="_blank" rel="noopener" href="https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list">https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list</a> | <br>    sed ‘s#deb https:&#x2F;&#x2F;#deb [signed-by&#x3D;&#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;nvidia-container-toolkit-keyring.gpg] https:&#x2F;&#x2F;#g’ | <br>    sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;nvidia-container-toolkit.list</p>
<p>sudo apt-get update<br>sudo apt-get install -y nvidia-container-toolkit</p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>The <a target="_blank" rel="noopener" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html">user guide</a> provides information on the configuration and command line options available when running GPU containers with Docker. </p>
<p>Docker 使用容器创建虚拟环境，以便将 TensorFlow 安装结果与系统的其余部分隔离开来。TensorFlow 程序在此虚拟环境中运行，该环境能够与其主机共享资源（访问目录、使用 GPU、连接到互联网等）。我们会针对每个版本测试 TensorFlow Docker 映像。</p>
<p>Docker 是在 Linux 上启用 TensorFlow GPU 支持的最简单方法，因为只需在主机上安装 NVIDIA® GPU 驱动程序，而不必安装 NVIDIA® CUDA® 工具包。</p>
<p>TensorFlow Docker 要求<br>在本地主机上安装 Docker。<br>如需在 Linux 上启用 GPU 支持，请安装 NVIDIA Docker 支持。<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/nvidia-docker">https://github.com/NVIDIA/nvidia-docker</a><br>请通过 docker -v 检查 Docker 版本。对于 19.03 之前的版本，您需要使用 nvidia-docker2 和 –runtime&#x3D;nvidia 标记；对于 19.03 及之后的版本，您将需要使用 nvidia-container-toolkit 软件包和 –gpus all 标记。这两个选项都记录在上面链接的网页上。</p>
<p>sudo docker run –gpus all –rm nvidia&#x2F;cuda nvidia-smi</p>
<h1 id="remove-删除docker-push-registry的镜像"><a href="#remove-删除docker-push-registry的镜像" class="headerlink" title="remove 删除docker push registry的镜像"></a>remove 删除docker push registry的镜像</h1><p>直接删除仓库容器&#x2F;var&#x2F;lib&#x2F;registry&#x2F;docker&#x2F;registry&#x2F;v2&#x2F;repositories&#x2F;下面的镜像目录。<br>sudo docker exec -it registry sh<br>docker exec registry rm -rf &#x2F;var&#x2F;lib&#x2F;registry&#x2F;docker&#x2F;registry&#x2F;v2&#x2F;repositories&#x2F;centos<br>or<br>或者可以将这个目录通过volume映射到宿主机上面来，这样便于管理。<br>rm -rf &#x2F;data&#x2F;docker.registry&#x2F;var&#x2F;lib&#x2F;registry&#x2F;docker&#x2F;registry&#x2F;v2&#x2F;repositories&#x2F;centos</p>
<p>垃圾回收<br>docker exec registry &#x2F;bin&#x2F;registry garbage-collect &#x2F;etc&#x2F;docker&#x2F;registry&#x2F;config.yml<br>&#x2F;bin&#x2F;registry garbage-collect &#x2F;etc&#x2F;docker&#x2F;registry&#x2F;config.yml<br>sudo docker restart registry<br>curl ‘<a target="_blank" rel="noopener" href="https://registry.tongfu.net:5000/v2/_catalog">https://registry.tongfu.net:5000/v2/_catalog</a>‘</p>
<h1 id="Start-a-docker-registry"><a href="#Start-a-docker-registry" class="headerlink" title="Start a docker registry"></a>Start a docker registry</h1><p>$ docker run -d -p 5000:5000 –restart&#x3D;always –name registry registry:2</p>
<h1 id="Push-local-docker-container-to-it"><a href="#Push-local-docker-container-to-it" class="headerlink" title="Push local docker container to it"></a>Push local docker container to it</h1><p>$ docker tag alpine localhost:5000&#x2F;alpine<br>$ docker push localhost:5000&#x2F;alpine</p>
<h1 id="Create-def-file-for-singularity-like-this"><a href="#Create-def-file-for-singularity-like-this" class="headerlink" title="Create def file for singularity like this.."></a>Create def file for singularity like this..</h1><h1 id="add-your-modifications"><a href="#add-your-modifications" class="headerlink" title="(add your modifications)"></a>(add your modifications)</h1><p>Bootstrap: docker<br>Registry: <a target="_blank" rel="noopener" href="http://localhost:5000/">http://localhost:5000</a><br>Namespace:<br>From: alpine:latest</p>
<h1 id="Build-singularity-container"><a href="#Build-singularity-container" class="headerlink" title="Build singularity container"></a>Build singularity container</h1><p>$ sudo SINGULARITY_NOHTTPS&#x3D;1 singularity build alpine.simg def</p>
<p><a target="_blank" rel="noopener" href="https://github.com/apptainer/singularity/issues/1537">build a singularity image from a local docker image</a></p>
<h2 id="install-docker-on-ubuntu"><a href="#install-docker-on-ubuntu" class="headerlink" title="install docker on ubuntu"></a>install docker on ubuntu</h2><p><a target="_blank" rel="noopener" href="https://docs.docker.com/engine/install/ubuntu/">https://docs.docker.com/engine/install/ubuntu/</a></p>
<p>for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done</p>
<p>sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-ce-rootless-extras</p>
<p>sudo rm -rf &#x2F;var&#x2F;lib&#x2F;docker<br>sudo rm -rf &#x2F;var&#x2F;lib&#x2F;containerd</p>
<p>Images, containers, volumes, and networks stored in &#x2F;var&#x2F;lib&#x2F;docker&#x2F; aren’t automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the uninstall Docker Engine section.</p>
<h1 id="Add-Docker’s-official-GPG-key"><a href="#Add-Docker’s-official-GPG-key" class="headerlink" title="Add Docker’s official GPG key:"></a>Add Docker’s official GPG key:</h1><p>docker 被墙后安装使用aliyun镜像<br><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000044973692">https://segmentfault.com/a/1190000044973692</a></p>
<p>curl -fsSL <a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg">http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg</a> | sudo gpg –dearmor -o &#x2F;etc&#x2F;apt&#x2F;keyrings&#x2F;docker.gpg</p>
<p>sudo add-apt-repository “deb [arch&#x3D;amd64] <a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/docker-ce/linux/ubuntu">http://mirrors.aliyun.com/docker-ce/linux/ubuntu</a> $(lsb_release -cs) stable”</p>
<p>sudo apt-get update;<br>sudo apt-get install ca-certificates curl gnupg;<br>sudo install -m 0755 -d &#x2F;etc&#x2F;apt&#x2F;keyrings<br>curl -fsSL <a target="_blank" rel="noopener" href="https://download.docker.com/linux/ubuntu/gpg">https://download.docker.com/linux/ubuntu/gpg</a> | sudo gpg –dearmor -o &#x2F;etc&#x2F;apt&#x2F;keyrings&#x2F;docker.gpg<br>sudo chmod a+r &#x2F;etc&#x2F;apt&#x2F;keyrings&#x2F;docker.gpg</p>
<h1 id="Add-the-repository-to-Apt-sources"><a href="#Add-the-repository-to-Apt-sources" class="headerlink" title="Add the repository to Apt sources:"></a>Add the repository to Apt sources:</h1><p>echo <br>  “deb [arch&#x3D;$(dpkg –print-architecture) signed-by&#x3D;&#x2F;etc&#x2F;apt&#x2F;keyrings&#x2F;docker.gpg] <a target="_blank" rel="noopener" href="https://download.docker.com/linux/ubuntu">https://download.docker.com/linux/ubuntu</a> <br>  $(. &#x2F;etc&#x2F;os-release &amp;&amp; echo “$VERSION_CODENAME”) stable” | <br>  sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;docker.list &gt; &#x2F;dev&#x2F;null<br>sudo apt-get update</p>
<p>sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</p>
<p>sudo docker run hello-world</p>
<p>sudo apt-get install docker-compose-plugin</p>
<p>sudo apt-get update<br>sudo apt-get install docker-compose-plugin</p>
<h1 id="On-the-host-where-you-run-docker-find-the-image-ID-of-the-docker-image-you-want-to-convert"><a href="#On-the-host-where-you-run-docker-find-the-image-ID-of-the-docker-image-you-want-to-convert" class="headerlink" title="On the host where you run docker, find the image ID of the docker image you want to convert"></a>On the host where you run docker, find the image ID of the docker image you want to convert</h1><p>docker images</p>
<h1 id="Save-the-docker-image-as-a-tarball-e-g-lolcow-tar"><a href="#Save-the-docker-image-as-a-tarball-e-g-lolcow-tar" class="headerlink" title="Save the docker image as a tarball, e.g. lolcow.tar"></a>Save the docker image as a tarball, e.g. lolcow.tar</h1><p>docker save image_id -o lolcow.tar</p>
<h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>docker-compose pull &amp;&amp; docker-compose restart<br>port &#x3D; 8088</p>
<p>如果你有一个本地的 Docker 镜像，你想要将它分享给其他的计算机，你可以按照以下的步骤操作：</p>
<ol>
<li>首先，你需要将你的 Docker 镜像保存为一个 tar 文件。你可以使用 <code>docker save</code> 命令来做这个：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker save -o &lt;path <span class="keyword">for</span> generated tar file&gt; &lt;image name&gt;</span><br></pre></td></tr></table></figure>

<p>例如，如果你的镜像名为 <code>my_image</code>，你可以运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker save -o my_image.tar my_image</span><br></pre></td></tr></table></figure>

<p>这个命令将会创建一个名为 <code>my_image.tar</code> 的文件，这个文件包含了 <code>my_image</code> 镜像的所有层和元数据。</p>
<ol start="2">
<li><p>然后，你可以将这个 tar 文件复制到其他的计算机上。你可以使用任何你喜欢的方法来做这个，例如，使用 USB 驱动器，或者通过网络传输。</p>
</li>
<li><p>在其他的计算机上，你可以使用 <code>docker load</code> 命令来从 tar 文件中加载 Docker 镜像：</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker load -i &lt;path to tar file&gt;</span><br></pre></td></tr></table></figure>

<p>例如，你可以运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker load -i my_image.tar</span><br></pre></td></tr></table></figure>

<p>这个命令将会从 <code>my_image.tar</code> 文件中加载 Docker 镜像。</p>
<p>现在，你应该可以在其他的计算机上使用你的 Docker 镜像了。你可以使用 <code>docker images</code> 命令来确认镜像已经被正确地加载。</p>
<h1 id="http-server-gave-HTTP-response-to-HTTPS-client"><a href="#http-server-gave-HTTP-response-to-HTTPS-client" class="headerlink" title="http: server gave HTTP response to HTTPS client"></a>http: server gave HTTP response to HTTPS client</h1><p>这个错误通常发生在尝试将 Docker 镜像推送到没有配置 HTTPS 的 Docker registry 时。默认情况下，Docker 客户端需要使用 HTTPS 来与 Docker registry 通信。如果 Docker registry 没有配置 HTTPS，Docker 客户端会拒绝与它通信，并显示这个错误。</p>
<p>要解决这个问题，你有两个选择：</p>
<ol>
<li><p><strong>配置 Docker registry 使用 HTTPS</strong>：这是推荐的解决方案，因为 HTTPS 可以保护你的 Docker 镜像在传输过程中的安全。</p>
</li>
<li><p><strong>配置 Docker 客户端允许使用 HTTP 与 Docker registry 通信</strong>：这个解决方案的安全性较低，因为 HTTP 不是一个安全的协议。然而，如果你只是在本地网络中使用 Docker registry，或者你的 Docker 镜像不包含敏感信息，你可能会选择这个解决方案。要配置 Docker 客户端允许使用 HTTP，你需要编辑 Docker 守护进程的配置文件（通常是 <code>/etc/docker/daemon.json</code>），并添加以下内容：</p>
</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;registry-mirrors&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;https://docker.m.daocloud.io&quot;</span><span class="punctuation">,</span><span class="string">&quot;https://docker.1panel.live&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;insecure-registries&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;myregistry:5000&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<p>在这个配置中，<code>myregistry:5000</code> 是你的 Docker registry 的地址。你应该将它替换为你的 Docker registry 的实际地址。添加完成后，你需要重启 Docker 守护进程以使这个配置生效。</p>
<h1 id="install-singularity"><a href="#install-singularity" class="headerlink" title="install singularity"></a>install singularity</h1><p>sudo apt-get update &amp;&amp; sudo apt-get install -y autoconf automake cryptsetup git libfuse-dev libglib2.0-dev libseccomp-dev libtool pkg-config runc squashfs-tools squashfs-tools-ng uidmap wget zlib1g-dev make;</p>
<p><code>make</code> 和 <code>make-guile</code> 都是 GNU Make 的版本，但它们的功能有所不同。</p>
<p><code>make</code> 是一个工具，它可以自动决定哪些部分的大型程序需要被重新编译，并发出命令来重新编译它们。它使用名为 <code>Makefile</code> 的文件来确定哪些文件需要被重新编译。</p>
<p><code>make-guile</code> 是 GNU Make 的一个版本，它包含了对 GNU Guile 的支持。GNU Guile 是一个嵌入式的 Scheme 编程语言，它可以用来扩展支持 Guile 的程序。在 <code>make-guile</code> 中，你可以使用 Guile 作为一个替代 Makefile 的传统语法的脚本语言。这可以让你编写更复杂的构建规则，并利用 Guile 提供的高级编程特性。</p>
<p>总的来说，如果你只需要基本的构建功能，你可能只需要 <code>make</code>。如果你需要更复杂的构建规则，或者你想要使用 Scheme 语言来编写你的构建规则，你可能需要 <code>make-guile</code>。</p>
<p>export VERSION&#x3D;1.21.4 OS&#x3D;linux ARCH&#x3D;amd64 &amp;&amp; wget <a target="_blank" rel="noopener" href="https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz">https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz</a> &amp;&amp; sudo tar -C &#x2F;usr&#x2F;local -xzvf go$VERSION.$OS-$ARCH.tar.gz &amp;&amp; rm go$VERSION.$OS-$ARCH.tar.gz;</p>
<p>export VERSION&#x3D;1.21.6 OS&#x3D;linux ARCH&#x3D;amd64 &amp;&amp; wget <a target="_blank" rel="noopener" href="https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz">https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz</a> &amp;&amp; sudo tar -C &#x2F;usr&#x2F;local -xzvf go$VERSION.$OS-$ARCH.tar.gz &amp;&amp; rm go$VERSION.$OS-$ARCH.tar.gz</p>
<p>echo ‘export PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;go&#x2F;bin:$PATH’ &gt;&gt; ~&#x2F;.bashrc &amp;&amp; source ~&#x2F;.bashrc;</p>
<p>export VERSION&#x3D;4.0.2 &amp;&amp; wget <a target="_blank" rel="noopener" href="https://github.com/sylabs/singularity/releases/download/v$%7BVERSION%7D/singularity-ce-$%7BVERSION%7D.tar.gz">https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-ce-${VERSION}.tar.gz</a> &amp;&amp; tar -xzf singularity-ce-${VERSION}.tar.gz &amp;&amp; cd singularity-ce-${VERSION};</p>
<p>export VERSION&#x3D;4.1.0 &amp;&amp; wget <a target="_blank" rel="noopener" href="https://github.com/sylabs/singularity/releases/download/v$%7BVERSION%7D/singularity-ce-$%7BVERSION%7D.tar.gz">https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-ce-${VERSION}.tar.gz</a> &amp;&amp; tar -xzf singularity-ce-${VERSION}.tar.gz &amp;&amp; cd singularity-ce-${VERSION}</p>
<p> .&#x2F;mconfig &amp;&amp; make -C builddir &amp;&amp; sudo make -C builddir install;</p>
<h1 id="singularity-with-nvidia-–nv"><a href="#singularity-with-nvidia-–nv" class="headerlink" title="singularity with nvidia –nv"></a>singularity with nvidia –nv</h1><p>singularity build lolcow.sif docker:&#x2F;&#x2F;godlovedc&#x2F;lolcow<br>singularity build -s –nv vasp_gpu docker:&#x2F;&#x2F;127.0.0.1:5000&#x2F;vasp_gpu:12.3.86</p>
<h1 id="清理-singularity-缓存"><a href="#清理-singularity-缓存" class="headerlink" title="清理 singularity 缓存"></a>清理 singularity 缓存</h1><p>singularity cache clean –dry-run<br>singularity cache clean</p>
<h1 id="将新硬盘内容移到Linux机器"><a href="#将新硬盘内容移到Linux机器" class="headerlink" title="将新硬盘内容移到Linux机器"></a>将新硬盘内容移到Linux机器</h1><p>在 Linux 中，将一个硬盘接入并将其内容移到其他硬盘的步骤如下：<br>sudo fdisk -l<br>sudo mkdir &#x2F;mnt&#x2F;mydisk<br>sudo mount &#x2F;dev&#x2F;sda2 &#x2F;mnt&#x2F;mydisk<br>sudo cp -R &#x2F;mnt&#x2F;mydisk&#x2F;* &#x2F;path&#x2F;to&#x2F;other&#x2F;disk<br>sudo umount &#x2F;mnt&#x2F;mydisk</p>
<p>how to deal with “Failed to initialize NVML: Driver&#x2F;library version mismatch NVML library version: 535.146” in ubuntu?</p>
<p>这个错误表示你的NVIDIA驱动和NVML库版本不匹配。你可以尝试以下步骤来解决这个问题：</p>
<ol>
<li>首先，卸载当前的NVIDIA驱动：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia-*</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>然后，更新你的系统：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get upgrade</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>重新安装NVIDIA驱动。你可以从NVIDIA官网下载最新的驱动，或者使用<code>ubuntu-drivers</code>命令自动安装推荐的驱动：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ubuntu-drivers autoinstall</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>重启你的系统：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>

<p>这些步骤应该可以解决驱动和库版本不匹配的问题。如果问题仍然存在，你可能需要检查你的硬件是否与新的驱动版本兼容，或者尝试安装不同版本的驱动。</p>
<h1 id="adduser和deluser命令"><a href="#adduser和deluser命令" class="headerlink" title="adduser和deluser命令"></a>adduser和deluser命令</h1><p>在Ubuntu中，你可以使用<code>adduser</code>和<code>deluser</code>命令来添加和删除用户账户。</p>
<p>添加用户账户：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser newusername</span><br><span class="line">sudo adduser jjcainew</span><br><span class="line">jjcai*18623716021</span><br></pre></td></tr></table></figure>

<p>在 Ubuntu 中创建用户账户通常涉及使用 <code>adduser</code> 或 <code>useradd</code> 命令。<code>adduser</code> 是更为友好的前端，它在 <code>useradd</code> 的基础上提供了更多的交互式选项，包括为新用户设置密码和创建家目录等。以下是使用 <code>adduser</code> 命令创建新用户账户的步骤：</p>
<ol>
<li><p>打开终端。</p>
</li>
<li><p>输入以下命令来创建一个新的用户账户（将 <code>username</code> 替换为你想要的用户名）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser username</span><br><span class="line">sudo adduser jjcainew</span><br></pre></td></tr></table></figure>
<p>这个命令会提示你输入新用户的密码以及一些额外的信息（如全名、电话号码等），这些信息是可选的，可以直接按回车跳过。</p>
</li>
<li><p>如果需要，你还可以将新用户添加到额外的用户组中。例如，要将用户添加到 <code>sudo</code> 组以允许其执行 <code>sudo</code> 命令，可以使用：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo usermod -aG sudo username</span><br></pre></td></tr></table></figure>
<p>这里 <code>-aG</code> 选项表示将用户添加到一个或多个额外的组中。</p>
</li>
</ol>
<p>完成这些步骤后，就成功创建了一个新的用户账户，并且根据需要，该用户可以使用 <code>sudo</code> 命令来执行需要超级用户权限的操作。</p>
<p>请注意，根据你的系统配置和安全策略，可能需要管理员权限来创建新用户。此外，确保选择一个强密码来增加账户的安全性。</p>
<p>这个命令会创建一个新的用户<code>newusername</code>，并且会创建一个同名的用户主目录。系统会提示你输入新用户的密码和一些其他信息。</p>
<p>删除用户账户：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo deluser username</span><br></pre></td></tr></table></figure>

<p>这个命令会删除用户<code>username</code>。请注意，这个命令不会删除用户的主目录。如果你想删除用户的主目录，你可以使用<code>--remove-home</code>选项：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo deluser --remove-home username</span><br></pre></td></tr></table></figure>

<p>请注意，添加和删除用户账户需要管理员权限。</p>
<h1 id="bash-shell的执行顺序如下："><a href="#bash-shell的执行顺序如下：" class="headerlink" title="bash shell的执行顺序如下："></a>bash shell的执行顺序如下：</h1><ol>
<li><p><code>/etc/profile</code>: 这个文件是系统级别的配置文件，对所有用户有效。通常在这个文件中设置全局环境变量。</p>
</li>
<li><p><code>/etc/profile.d/</code>: 这个目录下的所有.sh文件都会被执行。这些文件通常由各种软件包提供，用于设置环境变量。</p>
</li>
<li><p><code>~/.bash_profile</code> 或 <code>~/.profile</code>：这两个文件只对当前用户有效。如果<code>~/.bash_profile</code>存在，那么它会被执行。否则，<code>~/.profile</code>会被执行。通常在这个文件中设置用户级别的环境变量和启动程序。</p>
</li>
<li><p><code>~/.bashrc</code>: 这个文件也只对当前用户有效。它在每个非登录shell（例如新开的终端窗口）中都会被执行。通常在这个文件中设置别名和函数。</p>
</li>
<li><p><code>/etc/bash.bashrc</code>: 这个文件是系统级别的配置文件，对所有用户有效。它在每个非登录shell中都会被执行。通常在这个文件中设置全局别名和函数。</p>
</li>
</ol>
<p>请注意，这个顺序可能会根据具体的系统配置有所不同。</p>
<h1 id="is-enabled"><a href="#is-enabled" class="headerlink" title="is-enabled"></a>is-enabled</h1><p>在Linux中，你可以使用<code>systemctl</code>命令来检查一个服务是否在启动时运行。以下是具体步骤：</p>
<ol>
<li><p>打开一个终端。</p>
</li>
<li><p>输入以下命令，其中<code>your_service</code>是你要检查的服务的名称：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl is-enabled your_service</span><br></pre></td></tr></table></figure></li>
</ol>
<p>这个命令会返回<code>enabled</code>或<code>disabled</code>。如果返回<code>enabled</code>，那么这个服务会在启动时运行。如果返回<code>disabled</code>，那么这个服务不会在启动时运行。</p>
<p>注意，这个命令需要root权限，所以你可能需要使用<code>sudo</code>，如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl is-enabled your_service</span><br></pre></td></tr></table></figure>

<h1 id="shell-中单引号和双引号的区别"><a href="#shell-中单引号和双引号的区别" class="headerlink" title="shell 中单引号和双引号的区别"></a>shell 中单引号和双引号的区别</h1><p>在 Shell 脚本中，单引号（’）和双引号（”）有着不同的行为：</p>
<ul>
<li><strong>单引号</strong>：在单引号中的内容会被视为纯文本字符串，不会进行任何变量替换或命令执行。例如：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var=<span class="string">&#x27;world&#x27;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;Hello, $var&#x27;</span></span><br></pre></td></tr></table></figure>

<p>上述代码将输出 <code>Hello, $var</code>，而不是 <code>Hello, world</code>。</p>
<ul>
<li><strong>双引号</strong>：在双引号中的内容会进行变量替换和命令执行。例如：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var=<span class="string">&#x27;world&#x27;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello, <span class="variable">$var</span>&quot;</span></span><br></pre></td></tr></table></figure>

<p>上述代码将输出 <code>Hello, world</code>。</p>
<p>总结一下，如果你想要在字符串中包含变量或命令，你应该使用双引号。如果你想要字符串被视为纯文本，你应该使用单引号。</p>
<h1 id="如何知道服务器cpu是否开启了超线程？"><a href="#如何知道服务器cpu是否开启了超线程？" class="headerlink" title="如何知道服务器cpu是否开启了超线程？"></a>如何知道服务器cpu是否开启了超线程？</h1><p>在 Linux 系统中，你可以通过查看 <code>/proc/cpuinfo</code> 文件来确定是否启用了超线程。你可以使用 <code>grep</code> 命令来查找相关信息。</p>
<p>以下是一个简单的命令，它计算物理 CPU 核心的数量和逻辑 CPU 核心的数量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">&#x27;cpu cores&#x27;</span> /proc/cpuinfo | <span class="built_in">uniq</span></span><br><span class="line">grep <span class="string">&#x27;processor&#x27;</span> /proc/cpuinfo | <span class="built_in">wc</span> -l</span><br></pre></td></tr></table></figure>

<p>第一个命令会显示每个物理 CPU 的核心数量，第二个命令会显示逻辑 CPU 的数量（包括超线程）。</p>
<p>如果逻辑 CPU 的数量大于物理 CPU 核心的数量，那么超线程可能已经启用。如果两者相等，那么超线程可能已经禁用。</p>
<p>请注意，这只是一个简单的检查，它可能不适用于所有系统。如果你需要更准确的信息，你应该查看你的系统文档，或者联系你的系统管理员。</p>
<h1 id="sudo-apt-update-error"><a href="#sudo-apt-update-error" class="headerlink" title="sudo apt update error"></a>sudo apt update error</h1><p>Reading package lists… Done<br>E: Could not get lock &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;lock. It is held by process 245016 (apt-get)<br>N: Be aware that removing the lock file is not a solution and may break your system.<br>E: Unable to lock directory &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;</p>
<p>这个错误表明另一个进程正在使用 apt 包管理器。这可能是因为另一个 apt-get 命令正在运行，或者系统正在进行自动更新。</p>
<p>首先，你可以尝试等待一段时间，看看是否有其他进程正在使用 apt。如果等待一段时间后问题仍然存在，你可以尝试以下步骤：</p>
<ol>
<li>查找正在使用 apt 的进程：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep apt</span><br></pre></td></tr></table></figure>

<p>这将列出所有正在运行的与 apt 相关的进程。你可以查找进程 ID 为 245016 的进程，看看它是什么。</p>
<ol start="2">
<li>如果你确定这个进程已经不再需要，或者它已经卡住不动了，你可以使用以下命令杀掉它：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">kill</span> -9 245016</span><br></pre></td></tr></table></figure>

<p>然后你应该能够再次运行 apt-get 命令。</p>
<p>注意：强制杀掉 apt 进程可能会导致包管理器处于不一致的状态。在大多数情况下，这不会造成问题，但在某些情况下，可能需要手动修复。</p>
<h1 id="mpirun-v-s-mpiexec"><a href="#mpirun-v-s-mpiexec" class="headerlink" title="mpirun v.s. mpiexec"></a>mpirun v.s. mpiexec</h1><p><code>mpirun</code>和<code>mpiexec</code>都是用于启动MPI（Message Passing Interface）程序的命令。它们的主要区别在于它们遵循的标准和一些特性。</p>
<ol>
<li><p><code>mpirun</code>：这是一个传统的命令，用于启动MPI程序。它是Open MPI和一些其他MPI实现的一部分。<code>mpirun</code>提供了一些有用的特性，如动态进程管理和资源发现。然而，<code>mpirun</code>并不遵循任何特定的标准，因此它的行为可能会因不同的MPI实现而异。</p>
</li>
<li><p><code>mpiexec</code>：这是一个遵循MPI-2和MPI-3标准的命令，用于启动MPI程序。<code>mpiexec</code>的行为和参数在所有遵循这些标准的MPI实现中都是一致的。然而，<code>mpiexec</code>可能不支持<code>mpirun</code>的一些特性，如动态进程管理。</p>
</li>
</ol>
<p>总的来说，如果你的MPI程序需要特定的<code>mpirun</code>特性，或者你正在使用的MPI实现推荐使用<code>mpirun</code>，那么你应该使用<code>mpirun</code>。否则，为了保证可移植性，你应该使用<code>mpiexec</code>。</p>
<h1 id="neofetch"><a href="#neofetch" class="headerlink" title="neofetch"></a>neofetch</h1><p>Neofetch 是一个命令行工具，它可以显示关于你的系统的信息，包括操作系统、主机名、内核、Uptime、窗口管理器、Shell、分辨率、主题、图标、CPU、GPU 和 RAM 等。它还可以显示你的电脑的 logo。</p>
<p>Neofetch 非常灵活，你可以配置它显示哪些信息，以及如何显示这些信息。它支持多种操作系统，包括 Linux、OS X、iOS、BSD 和 Windows 等。</p>
<p>要在 Ubuntu 中安装 Neofetch，你可以使用以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install neofetch</span><br></pre></td></tr></table></figure>

<p>安装完成后，你可以通过在终端中输入 <code>neofetch</code> 来运行它：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">neofetch</span><br></pre></td></tr></table></figure>

<p><img src="/image.png" alt="alt text"></p>
<h1 id="linux-service-daemon"><a href="#linux-service-daemon" class="headerlink" title="linux service daemon"></a>linux service daemon</h1><p>[Unit]<br>Description&#x3D;My Daemon</p>
<p>[Service]<br>ExecStart&#x3D;&#x2F;path&#x2F;to&#x2F;your&#x2F;daemon<br>Restart&#x3D;always<br>User&#x3D;root<br>Group&#x3D;root<br>Environment&#x3D;PATH&#x3D;&#x2F;usr&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;bin<br>EnvironmentFile&#x3D;-&#x2F;etc&#x2F;default&#x2F;mydaemon</p>
<p>EnvironmentFile&#x3D;-&#x2F;etc&#x2F;default&#x2F;ssh<br>ExecStartPre&#x3D;&#x2F;usr&#x2F;sbin&#x2F;sshd -t<br>ExecStart&#x3D;&#x2F;usr&#x2F;sbin&#x2F;sshd -D $SSHD_OPTS<br>ExecReload&#x3D;&#x2F;usr&#x2F;sbin&#x2F;sshd -t<br>ExecReload&#x3D;&#x2F;bin&#x2F;kill -HUP $MAINPID<br>KillMode&#x3D;process<br>Restart&#x3D;on-failure<br>RestartPreventExitStatus&#x3D;255<br>Type&#x3D;notify<br>RuntimeDirectory&#x3D;sshd<br>RuntimeDirectoryMode&#x3D;0755</p>
<p>[Install]<br>WantedBy&#x3D;multi-user.target</p>
<p>在Linux系统中，systemctl是Systemd的主命令行工具，用于控制Systemd系统和服务管理器。通过使用systemctl，您可以添加、删除、启用和禁用自定义系统服务。下面是如何使用systemctl添加自定义系统服务的步骤：</p>
<p>创建服务文件：首先，您需要创建一个服务文件，用于描述自定义服务的配置。服务文件的扩展名为.service，并放置在&#x2F;etc&#x2F;systemd&#x2F;system目录下。例如，如果您要添加名为mycustomservice的自定义服务，可以创建一个名为mycustomservice.service的文件。<br>使用文本编辑器打开mycustomservice.service文件，并添加以下内容作为示例：</p>
<p>在上述示例中，您需要将ExecStart选项的值替换为您实际要执行的脚本或可执行文件的路径。<br>编写脚本：在创建服务文件之前，您需要编写一个启动脚本，该脚本将在启动服务时执行。在示例中，您需要创建一个名为script.sh的脚本文件，并将其放置在&#x2F;path&#x2F;to&#x2F;your&#x2F;目录下。确保该脚本具有可执行权限。<br>启动服务：完成服务文件和启动脚本的创建后，您可以使用以下命令启动自定义服务：<br>sudo systemctl start mycustomservice<br>如果您希望在系统启动时自动启动该服务，请使用以下命令启用服务：<br>sudo systemctl enable mycustomservice<br>查看服务状态：要检查自定义服务的状态，请使用以下命令：<br>sudo systemctl status mycustomservice<br>这将显示有关服务当前状态的信息，包括是否正在运行以及任何相关的日志输出。<br>管理服务：您可以使用systemctl命令进行各种服务管理操作，例如停止、重新启动和重新加载服务。例如：<br>sudo systemctl stop mycustomservice  # 停止服务<br>sudo systemctl restart mycustomservice  # 重新启动服务<br>sudo systemctl reload mycustomservice  # 重新加载服务配置<br>这些是使用systemctl添加自定义系统服务的基本步骤。通过创建自定义服务文件并编写适当的启动脚本，您可以灵活地控制和管理您的Linux系统中的服务。请记住，在使用systemctl之前，您需要具有适当的系统权限（通常为root用户或使用sudo命令）。</p>
<h2 id="第一节-简介"><a href="#第一节-简介" class="headerlink" title="第一节:简介"></a>第一节:简介</h2><p>开机第一个程序从init完全换成了systemd这种启动方式。systemd是靠管理unit的方式来控制开机服务，开机级别等功能。在&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system目录下包含了各种unit文件，有service后缀的服务unit，有target后缀的开机级别unit等，这里介绍关于service后缀的文件。因为systemd在开机要想执行自启动，都是通过这些.service 的unit控制的，服务又分为系统服务 (system) 和用户服务 (user)。系统服务: 开机不登陆就能运行的程序(常用于开机自启)。用户服务:需要登陆以后才能运行的程序</p>
<h2 id="第二节-serivces配置文件说明"><a href="#第二节-serivces配置文件说明" class="headerlink" title="第二节: serivces配置文件说明:"></a>第二节: serivces配置文件说明:</h2><p>[Unit] 区块: 启动顺序与依赖关系<br>Description字段: 给出当前服务的简单描述。<br>Documentation字段: 给出文档位置。<br>After字段: 如果network.target或sshd-keygen.service需要启动，那么sshd.service应该在它们之后启动。<br>Before字段: 定义sshd.service应该在哪些服务之前启动<br>注: After和Before字段只涉及启动顺序，不涉及依赖关系<br>举例来说，某 Web 应用需要 postgresql 数据库储存数据。在配置文件中，它只定义要在postgresql 之后启动，而没有定义依赖 postgresql 。上线后，由于某种原因，postgresgl 需要重新启动，在停止服务期间，该 Web 应用就会无法建立数据库连接设置依赖关系，重要使用Wants字段和Requires字段。<br>Wants字段: 表示sshd.service与sshd-keygen.service之间存在”弱依赖”关系，即如果”sshd.keygen.service”启动失败或停止运行，不影响sshd.service继续执行。<br>Requires字段则表示”强依赖”关系，即如果该服务启动失败或异常退出，那么sshd.service也必须退出。<br>注意，Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的。<br>[Service] 区块: 启动行为</p>
<h3 id="启动命令"><a href="#启动命令" class="headerlink" title="启动命令"></a>启动命令</h3><p>ExecStart字段: 定义启动进程时执行的命令<br>ExecReload字段: 重启服务时执行的命令<br>ExecStop字段: 停止服务时执行的命令<br>ExecStartPre字段: 启动服务之前执行的命令<br>ExecStartPost字段: 启动服务之后执行的命令<br>ExecstopPost字段: 停止服务之后执行的命念<br>注: 所有的启动设置之前，都可以加上一个连词号 ()，表示”抑制错误”，即发生错误的时候，不影响其他命令的执行。比如EnvironmentFile&#x3D;-&#x2F;etc&#x2F;sysconfig&#x2F;sshd (注意等号后面的那个连词号)，就表示即使&#x2F;etc&#x2F;sysconfig&#x2F;sshd文件不存在，也不会抛出错误。<br>注意:[Service]中的启动、重启、停止命令全部要求使用绝对路径!</p>
<h3 id="启动类型"><a href="#启动类型" class="headerlink" title="启动类型"></a>启动类型</h3><p>Type字段定义启动类型。它可以设置的值如下:<br>simple (默认值): ExecStart字段启动的进程为主进程<br>forking: ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程(后台运行)<br>oneshot: 类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务<br>dbus: 类似于simple，但会等待 D-Bus 信号后启动<br>notify: 类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务<br>idle: 类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合</p>
<h3 id="重启行为"><a href="#重启行为" class="headerlink" title="重启行为"></a>重启行为</h3><p>Service区块有一些字段，定义了重启行为:<br>KillMode字段: 定义 Systemd 如何停止 sshd 服务:<br>control-group (默认值) : 当前控制组里面的所有子进程，都会被杀掉<br>process: 只杀主讲程<br>mixed: 主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号<br>none: 没有进程会被杀掉，只是执行服务的 stop 命令。<br>Restart字段: 定义了 sshd 退出后，Systemd 的重启方式<br>上面的例子中，Restart设为on-failure，表示任何意外的失败，就将重启sshd。如果 sshd正常停止(比如执行systemctl stop命令)，它就不会重启。<br>Restart字段可以设置的值如下。<br>no (默认值) : 退出后不会重启<br>on-success: 只有正常退出时 (退出状态码为0)，才会重启<br>on-failure: 非正常退出时(退出状态码非0)，包括被信号终止和超时，才会重启<br>on-abnormal: 只有被信号终止和超时，才会重启<br>on-abort: 只有在收到没有捕捉到的信号终止时，才会重启<br>on-watchdog: 超时退出，才会重启<br>always: 不管是什么退出原因，总是重启<br>注: 对于守护进程，推荐设为on-failure。对于那些允许发生错误退出的服务，可以设为on-abnormal.<br>RestartSec字段: 表示 Svstemd 重启服务之前，需要等待的秒数<br>上面的例子设为等待42秒</p>
<p>[Install] 区块<br>install区块，定义如何安装这个配置文件，即怎样做到开机启动<br>WantedBy字段: 表示该服务所在的 Target。<br>Target的含义是服务组，表示一组服务。<br>WantedBy&#x3D;multi-user.target指的是: sshd 所在的 Target 是multi-user.target。<br>这个设置非常重要，因为执行systemctl enable sshd.service命令时，sshd.service的一个符号链接，就会放在&#x2F;etc&#x2F;systemd&#x2F;system目录下面的multi-user.target.wants子目录之中。<br>Systemd 有默认的启动 Target.</p>
<p>systemctl get-default<br>#输出multi-user.target<br>上面的结果表示，默认的启动 Target 是multi-user.target。在这个组里的所有服务，都将开机启<br>动。这就是为什么systemctl enable命令能设置开机启动的原因。<br>使用 Target 的时候，systemctl list-dependencies命令和systemctl isolate命令也很有用.</p>
<p>#查看 multi-user.taraet 包含的所有服务<br>systemctl list-dependencies multi-user.target</p>
<p>#切换到另一个 target</p>
<p>#shutdown.target 就是关机状态<br>systemctl isolate shutdown .target</p>
<p>一般来说，常用的 Target 有两个:<br>multi-user.target: 表示多用户命令行状态;<br>graphical.target: 表示图形用户状态，它依赖于multi-user.target</p>
<h2 id="第三节-注册服务实例介绍"><a href="#第三节-注册服务实例介绍" class="headerlink" title="第三节: 注册服务实例介绍"></a>第三节: 注册服务实例介绍</h2><p>配置文件目录<br>systemctl脚本目录: &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;<br>系统服务目录: &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system<br>用户服务目录: &#x2F;usr&#x2F;1ib&#x2F;systemd&#x2F;user&#x2F;<br>在&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system目录下新建service-name.service文件:</p>
<p>[UNIT]<br>#服务描述<br>Description&#x3D;Media wanager Service<br>#指定了在systemd在执行完那些target之后再启动该服务<br>After&#x3D;network.target</p>
<p>[Service]<br>#定义Service的运行类型，一般是forking(后台运行)<br>Type&#x3D;forking</p>
<p>#定义systemctl startlstoplreload *.service 的执行方法(具体命令需要写绝对路径)<br>#注: ExecStartPre为启动前执行的命令<br>ExecStartPre&#x3D;&#x2F;usr&#x2F;bin&#x2F;test “x$[NETWORKMANAGER]”&#x3D; xyes<br>ExecStart&#x3D;&#x2F;home&#x2F;mobileoa&#x2F;apps&#x2F;shMediaManager.sh -start<br>ExecReload&#x3D;<br>ExecStop&#x3D;&#x2F;home&#x2F;mobileoa&#x2F;apps&#x2F;shMediaManager.sh -stop</p>
<p>#创建私有的内存临时空间<br>PrivateTmp&#x3D;True</p>
<p>[Install]<br>#多用户<br>WantedBy&#x3D;multi-user.target</p>
<p>重载系统服务: systemctl daemon-reload<br>设置开机启动: systemctl enable *.service<br>启动服务: systemctl start *.service<br>停止服务: systemctl stop *.service<br>重户服务: systemctl reload *.service<br>注: 修改完配置文件要重载配置文件。</p>
<h2 id="第四节-使用svstemd管理Altas"><a href="#第四节-使用svstemd管理Altas" class="headerlink" title="第四节: 使用svstemd管理Altas"></a>第四节: 使用svstemd管理Altas</h2><p>atlas的service配置文件:<br>[Unit]<br>Description&#x3D;Atlas - high performance mysql-proxy server<br>After&#x3D;network-online.target remote-fs.target nss-lookup.target<br>Wants&#x3D;network-online.target</p>
<p>[Service]<br>Type&#x3D;forking<br>PIDFile&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-proxy&#x2F;log&#x2F;test.pid<br>ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-proxy&#x2F;bin&#x2F;mysql-proxyd test start<br>ExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-proxy&#x2F;bin&#x2F;mysql-proxyd test stop<br>ExecReload&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-proxy&#x2F;bin&#x2F;mysql-proxyd test restart<br>PrivateTmp&#x3D;true</p>
<p>[Install]<br>WantedBy&#x3D;multi-user.target</p>
<p>systemctl daemon-reload #重载系统服务，即可使用systemd来管理服务</p>
<h2 id="第五节-启动分析"><a href="#第五节-启动分析" class="headerlink" title="第五节 启动分析"></a>第五节 启动分析</h2><p>分析关键耗时<br>systemd-analyze critical-chain</p>
<p>分析每个服务的耗时<br>systemd-analyze blame</p>
<p>将每个服务的耗时输出到图片<br>systemd-analyze plot &gt; boot.svg<br>列出所有开机自动启动的服务<br>systemctl list-unit-files –type&#x3D;servicegrep enabled</p>
<h1 id="jq"><a href="#jq" class="headerlink" title="jq"></a>jq</h1><p>sudo apt install jq</p>
<p><code>jq</code> 是一个轻量级且灵活的命令行 JSON 处理器。它允许你在命令行中解析、过滤、查询和操作 JSON 数据。</p>
<p>以下是一些基本的 <code>jq</code> 用法：</p>
<ol>
<li><p><strong>输出整个 JSON</strong>：<code>jq . file.json</code>。这将会把整个 JSON 数据以美化的形式输出。</p>
</li>
<li><p><strong>读取特定字段</strong>：<code>jq .field file.json</code>。这将会输出 JSON 数据中名为 “field” 的字段的值。</p>
</li>
<li><p><strong>过滤数组元素</strong>：<code>jq &#39;.array[]&#39; file.json</code>。这将会输出 JSON 数据中名为 “array” 的数组的所有元素。</p>
</li>
<li><p><strong>查询嵌套字段</strong>：<code>jq &#39;.field1.field2&#39; file.json</code>。这将会输出 JSON 数据中名为 “field1” 的字段中名为 “field2” 的子字段的值。</p>
</li>
<li><p><strong>管道操作</strong>：<code>jq &#39;.array[] | .field&#39; file.json</code>。这将会输出 JSON 数据中名为 “array” 的数组的所有元素中名为 “field” 的字段的值。</p>
</li>
<li><p><strong>创建新的 JSON</strong>：<code>jq &#39;&#123;field1: .field1, field2: .field2&#125;&#39; file.json</code>。这将会创建一个新的 JSON 对象，包含原 JSON 数据中名为 “field1” 和 “field2” 的字段的值。</p>
</li>
</ol>
<p><code>jq</code> 的功能非常强大，以上只是一些基本的用法。如果你需要进行更复杂的 JSON 处理，我建议查阅 <code>jq</code> 的官方文档或相关教程。</p>
<p>要使用 <code>jq</code> 从头开始创建一个 JSON 文件，你可以使用 <code>-n</code> 选项（表示不从输入读取任何数据），然后提供你想要在新 JSON 文件中包含的数据。例如，如果你想创建一个包含 <code>&#123;&quot;name&quot;: &quot;John&quot;, &quot;age&quot;: 30&#125;</code> 的 JSON 文件，你可以运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jq -n <span class="string">&#x27;&#123;&quot;name&quot;: &quot;John&quot;, &quot;age&quot;: 30&#125;&#x27;</span> &gt; output.json</span><br></pre></td></tr></table></figure>

<p>这将会创建一个名为 <code>output.json</code> 的新文件，其中包含你指定的 JSON 数据。</p>
<p>如果你想要使用 Bash 变量创建 JSON 文件，你可以使用 <code>--arg</code> 选项将 Bash 变量传递给 <code>jq</code>。例如：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">name=<span class="string">&quot;John&quot;</span></span><br><span class="line">age=30</span><br><span class="line"></span><br><span class="line">jq -n --arg name <span class="string">&quot;<span class="variable">$name</span>&quot;</span> --argjson age <span class="string">&quot;<span class="variable">$age</span>&quot;</span> <span class="string">&#x27;&#123;&quot;name&quot;: $name, &quot;age&quot;: $age&#125;&#x27;</span> &gt; output.json</span><br></pre></td></tr></table></figure>

<p>jq -n –argjson cpu_temperature “$cpu_temperature” –argjson gpu_temperature “$gpu_temperature” ‘{“cpu”: $cpu_temperature, “gpu”: $gpu_temperature}’ &gt; output.json</p>
<p>这将会创建一个名为 <code>output.json</code> 的新文件，其中包含 <code>&#123;&quot;name&quot;: &quot;John&quot;, &quot;age&quot;: 30&#125;</code>。注意，我们使用 <code>--argjson</code> 选项传递了一个整数变量 <code>age</code>，因为 JSON 中的数字不应被引号包围。</p>
<h1 id="linux-notebook-ban-suspend"><a href="#linux-notebook-ban-suspend" class="headerlink" title="linux notebook ban suspend"></a>linux notebook ban suspend</h1><p>sudo nano &#x2F;etc&#x2F;systemd&#x2F;logind.conf<br>HandleLidSwitch&#x3D;ignore</p>
<p>HandleLidSwitch&#x3D;ignore<br>HandleLidSwitchExternalPower&#x3D;ignore<br>HandleLidSwitchDocked&#x3D;ignore<br>LidSwitchIgnoreInhibited&#x3D;no</p>
<p>reboot needed</p>
<h1 id="uninstall-cuda"><a href="#uninstall-cuda" class="headerlink" title="uninstall cuda"></a>uninstall cuda</h1><p>sudo apt-get –purge remove “<em>cuda</em>“ “<em>cublas</em>“ “<em>cufft</em>“ “<em>cufile</em>“ “<em>curand</em>“ <br> “<em>cusolver</em>“ “<em>cusparse</em>“ “<em>gds-tools</em>“ “<em>npp</em>“ “<em>nvjpeg</em>“ “nsight*” “<em>nvvm</em>“</p>
<p>sudo apt-get –purge remove “<em>nvidia</em>“ “libxnvctrl*”</p>
<p>sudo apt-get autoremove</p>
<p>sudo apt-get –purge remove “<em>cuda</em>“ “<em>cublas</em>“ “<em>cufft</em>“ “<em>cufile</em>“ “<em>curand</em>“ “<em>cusolver</em>“ “<em>cusparse</em>“ “<em>gds-tools</em>“ “<em>npp</em>“ “<em>nvjpeg</em>“ “nsight*” “<em>nvvm</em>“ “<em>nvidia</em>“ “libxnvctrl*” &amp;&amp; sudo apt-get autoremove &amp;&amp; sudo reboot</p>
<h1 id="remove-docker-from-apt-update"><a href="#remove-docker-from-apt-update" class="headerlink" title="remove docker from apt update"></a>remove docker from apt update</h1><p>&#x2F;etc&#x2F;apt&#x2F;keyrings&#x2F;docker.gpg<br>&#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;docker.list</p>
<p>如果你想在运行 <code>apt update</code> 时跳过 Docker 的更新，你可以将 Docker 的软件源从 APT 的源列表中移除，或者将其禁用。</p>
<p>以下是如何禁用特定的 APT 源的步骤：</p>
<ol>
<li><p>打开 APT 源列表文件。这个文件通常位于 <code>/etc/apt/sources.list</code>，或者 <code>/etc/apt/sources.list.d/</code> 目录下的某个文件。你需要使用 root 权限来编辑这个文件，例如使用 <code>sudo nano /etc/apt/sources.list</code> 命令。</p>
</li>
<li><p>在文件中找到 Docker 的源。这个源的地址通常会包含 <code>https://download.docker.com/</code>。</p>
</li>
<li><p>在源的行前面加上 <code>#</code> 符号，这会将这一行变成注释，从而禁用这个源。例如，将</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deb [<span class="built_in">arch</span>=amd64] https://download.docker.com/linux/ubuntu bionic stable</span><br></pre></td></tr></table></figure>

<p> 改为</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>保存并关闭文件。</p>
</li>
<li><p>运行 <code>sudo apt update</code>。这次更新应该会跳过 Docker 的更新。</p>
</li>
</ol>
<p>如果你之后想要更新 Docker，你可以去掉那一行前面的 <code>#</code> 符号，然后再运行 <code>sudo apt update</code>。</p>
<h1 id="shebang"><a href="#shebang" class="headerlink" title="shebang"></a>shebang</h1><p>在 Linux 和 Unix 系统中，<code>shebang</code> 是一个特殊的注释，用于指定一个脚本文件的解释器。<code>shebang</code> 通常出现在脚本文件的第一行，并以 <code>#!</code> 开头，后面跟着解释器的路径。</p>
<p>#!&#x2F;usr&#x2F;bin&#x2F;env python3</p>
<p>nvitop</p>
<h1 id="nvidia-smi-ecc-报错"><a href="#nvidia-smi-ecc-报错" class="headerlink" title="nvidia-smi ecc 报错"></a>nvidia-smi ecc 报错</h1><p>nvidia-smi -q -d ECC</p>
<p>for i in <code>seq 3 644</code>; do if [ -f a_”$i”<em>1&#x2F;zfs.json ] &amp;&amp; [ -f a</em>“$i”<em>1.5&#x2F;zfs.json ] &amp;&amp; [ -f a</em>“$i”<em>-1&#x2F;zfs.json ] &amp;&amp; [ -f a</em>“$i”_-1.5&#x2F;zfs.json ]; then echo $i; fi; done</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/wsl/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/wsl/" class="post-title-link" itemprop="url">wsl</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 19:50:56" itemprop="dateCreated datePublished" datetime="2024-06-15T19:50:56+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:21" itemprop="dateModified" datetime="2024-07-30T00:45:21+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在 Windows 11 上使用 WSL 2（Windows Subsystem for Linux 2），你需要启用以下 Windows 功能：</p>
<ol>
<li>虚拟机平台（Virtual Machine Platform）</li>
<li>Windows Subsystem for Linux（WSL）</li>
</ol>
<p>以下是启用这些功能的步骤：</p>
<ol>
<li>打开 “控制面板”（Control Panel）。</li>
<li>点击 “程序”（Programs）。</li>
<li>点击 “启用或关闭 Windows 功能”（Turn Windows features on or off）。</li>
<li>在弹出的窗口中，找到并勾选 “虚拟机平台”（Virtual Machine Platform）和 “Windows Subsystem for Linux”（WSL）。</li>
<li>点击 “确定”（OK）按钮。</li>
<li>重启你的电脑。</li>
</ol>
<p>此外，你还需要从 Microsoft Store 安装一个 Linux 发行版，例如 Ubuntu、Debian 或 Fedora。安装完成后，你可以在 “开始” 菜单中找到并打开你的 Linux 发行版，然后按照提示设置你的用户名和密码。</p>
<p>最后，你可能需要将 WSL 的默认版本设置为 2。你可以打开一个 PowerShell 窗口，然后运行以下命令：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl <span class="literal">--set-default-version</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>这个命令将会将 WSL 的默认版本设置为 2。如果你在运行这个命令时遇到问题，你可能需要更新你的 WSL 2 Linux 内核。你可以从 Microsoft 的官方网站下载并安装最新的 WSL 2 Linux 内核更新包。</p>
<p>wsl –update<br>wsl –set-default-version 2<br>wsl -l -o</p>
<p>Open PowerShell.<br>Type wsl -l -v to list all installed WSL distributions.<br>Type wsl –unregister <distro_name> to unregister the distribution. Replace <distro_name> with the name of the distribution you want to remove.</p>
<p>The following is a list of valid distributions that can be installed.<br>Install using ‘wsl.exe –install <Distro>‘.</p>
<p>NAME                                   FRIENDLY NAME<br>Ubuntu                                 Ubuntu<br>Debian                                 Debian GNU&#x2F;Linux<br>kali-linux                             Kali Linux Rolling<br>Ubuntu-18.04                           Ubuntu 18.04 LTS<br>Ubuntu-20.04                           Ubuntu 20.04 LTS<br>Ubuntu-22.04                           Ubuntu 22.04 LTS<br>OracleLinux_7_9                        Oracle Linux 7.9<br>OracleLinux_8_7                        Oracle Linux 8.7<br>OracleLinux_9_1                        Oracle Linux 9.1<br>openSUSE-Leap-15.5                     openSUSE Leap 15.5<br>SUSE-Linux-Enterprise-Server-15-SP4    SUSE Linux Enterprise Server 15 SP4<br>SUSE-Linux-Enterprise-15-SP5           SUSE Linux Enterprise 15 SP5<br>openSUSE-Tumbleweed                    openSUSE Tumbleweed</p>
<p>wsl –install Ubuntu-22.04</p>
<p>sudo apt update<br>sudo apt install xfce4<br>export DISPLAY&#x3D;172.18.64.1:0<br>sudo startxfce4<br>vcxsrv -ac</p>
<p>export DISPLAY&#x3D;$windows_host:0</p>
<h1 id="rdp绝杀"><a href="#rdp绝杀" class="headerlink" title="rdp绝杀"></a>rdp绝杀</h1><p>sudo apt install xrdp</p>
<h1 id="Basic-commands-for-WSL"><a href="#Basic-commands-for-WSL" class="headerlink" title="Basic commands for WSL"></a>Basic commands for WSL</h1><p>The WSL commands below are listed in a format supported by PowerShell or Windows Command Prompt. To run these commands from a Bash &#x2F; Linux distribution command line, you must replace wsl with wsl.exe. For a full list of commands, run wsl –help.</p>
<p>Install<br>PowerShell</p>
<p>Copy<br>wsl –install<br>Install WSL and the default Ubuntu distribution of Linux. Learn more. You can also use this command to install additional Linux distributions by running wsl –install <Distribution Name>. For a valid list of distribution names, run wsl –list –online.</p>
<p>Options include:</p>
<p>–distribution: Specify the Linux distribution to install. You can find available distributions by running wsl –list –online.<br>–no-launch: Install the Linux distribution but do not launch it automatically.<br>–web-download: Install from an online source rather than using the Microsoft Store.<br>When WSL is not installed options include:</p>
<p>–inbox: Installs WSL using the Windows component instead of using the Microsoft Store. (WSL updates will be received via Windows updates, rather than pushed out as-available via the store).<br>–enable-wsl1: Enables WSL 1 during the install of the Microsoft Store version of WSL by also enabling the “Windows Subsystem for Linux” optional component.<br>–no-distribution: Do not install a distribution when installing WSL.<br> Note</p>
<p>If you running WSL on Windows 10 or an older version, you may need to include the -d flag with the –install command to specify a distribution: wsl –install -d <distribution name>.</p>
<p>List available Linux distributions<br>PowerShell</p>
<p>Copy<br>wsl –list –online<br>See a list of the Linux distributions available through the online store. This command can also be entered as: wsl -l -o.</p>
<p>List installed Linux distributions<br>PowerShell</p>
<p>Copy<br>wsl –list –verbose<br>See a list of the Linux distributions installed on your Windows machine, including the state (whether the distribution is running or stopped) and the version of WSL running the distribution (WSL 1 or WSL 2). Comparing WSL 1 and WSL 2. This command can also be entered as: wsl -l -v. Additional options that can be used with the list command include: –all to list all distributions, –running to list only distributions that are currently running, or –quiet to only show distribution names.</p>
<p>Set WSL version to 1 or 2<br>PowerShell</p>
<p>Copy<br>wsl –set-version <distribution name> <versionNumber><br>To designate the version of WSL (1 or 2) that a Linux distribution is running on, replace <distribution name> with the name of the distribution and replace <versionNumber> with 1 or 2. Comparing WSL 1 and WSL 2. WSL 2 is only available in Windows 11 or Windows 10, Version 1903, Build 18362 or later.</p>
<p>Set default WSL version<br>PowerShell</p>
<p>Copy<br>wsl –set-default-version <Version><br>To set a default version of WSL 1 or WSL 2, replacing <Version> with either the number 1 or 2 to represent which version of WSL you would like the installation to default on for new Linux distribution installations. For example, wsl –set-default-version 2. Comparing WSL 1 and WSL 2. WSL 2 is only available in Windows 11 or Windows 10, Version 1903, Build 18362 or later.</p>
<p>Set default Linux distribution<br>PowerShell</p>
<p>Copy<br>wsl –set-default <Distribution Name><br>To set the default Linux distribution that WSL commands will use to run, replace <Distribution Name> with the name of your preferred Linux distribution.</p>
<p>Change directory to home<br>PowerShell</p>
<p>Copy<br>wsl ~<br>The ~ can be used with wsl to start in the user’s home directory. To jump from any directory back to home from within a WSL command prompt, you can use the command: cd ~.</p>
<p>Run a specific Linux distribution from PowerShell or CMD<br>PowerShell</p>
<p>Copy<br>wsl –distribution <Distribution Name> –user <User Name><br>To run a specific Linux distribution with a specific user, replace <Distribution Name> with the name of your preferred Linux distribution (ie. Debian) and <User Name> with the name of an existing user (ie. root). If the user doesn’t exist in the WSL distribution, you will receive an error. To print the current user name, use the command whoami.</p>
<p>Update WSL<br>PowerShell</p>
<p>Copy<br>wsl –update<br>Update your WSL version to the latest version. Options include:</p>
<p>–web-download: Download the latest update from the GitHub rather than the Microsoft Store.<br>Check WSL status<br>PowerShell</p>
<p>Copy<br>wsl –status<br>See general information about your WSL configuration, such as default distribution type, default distribution, and kernel version.</p>
<p>Check WSL version<br>PowerShell</p>
<p>Copy<br>wsl –version<br>Check the version information about WSL and its components.</p>
<p>Help command<br>PowerShell</p>
<p>Copy<br>wsl –help<br>See a list of options and commands available with WSL.</p>
<p>Run as a specific user<br>PowerShell</p>
<p>Copy<br>wsl -u <Username><code>, </code>wsl –user <Username><br>To run WSL as a specified user, replace <Username> with the name of a user that exists in the WSL distribution.</p>
<p>Change the default user for a distribution<br>PowerShell</p>
<p>Copy<br><DistributionName> config –default-user <Username><br>Change the default user for your distribution log-in. The user has to already exist inside the distribution in order to become the default user.</p>
<p>For example: ubuntu config –default-user johndoe would change the default user for the Ubuntu distribution to the “johndoe” user.</p>
<p> Note</p>
<p>If you are having trouble figuring out the name of your distribution, use the command wsl -l.</p>
<p> Warning</p>
<p>This command will not work for imported distributions, because these distributions do not have an executable launcher. You can instead change the default user for imported distributions using the &#x2F;etc&#x2F;wsl.conf file. See the Automount options in the Advanced Settings Configuration doc.</p>
<p>Shutdown<br>PowerShell</p>
<p>Copy<br>wsl –shutdown<br>Immediately terminates all running distributions and the WSL 2 lightweight utility virtual machine. This command may be necessary in instances that require you to restart the WSL 2 virtual machine environment, such as changing memory usage limits or making a change to your .wslconfig file.</p>
<p>Terminate<br>PowerShell</p>
<p>Copy<br>wsl –terminate <Distribution Name><br>To terminate the specified distribution, or stop it from running, replace <Distribution Name> with the name of the targeted distribution.</p>
<p>Identify IP address<br>wsl hostname -i for the IP address of your Linux distribution installed via WSL 2 (the WSL 2 VM address)<br>cat &#x2F;etc&#x2F;resolv.conf for the IP address of the Windows machine as seen from WSL 2 (the WSL 2 VM)<br>Import and export a distribution<br>PowerShell</p>
<p>Copy<br>wsl –export <Distribution Name> <FileName><br>PowerShell</p>
<p>Copy<br>wsl –import <Distribution Name> <InstallLocation> <FileName><br>Imports and exports the specified tar file as a new distribution. The filename can be - for standard input. Options include:</p>
<p>–vhd: Specifies the import&#x2F;export distribution should be a .vhdx file instead of a tar file<br>–version: For import only, specifies whether to import the distribution as a WSL 1 or WSL 2 distribution<br>Import a distribution in place<br>PowerShell</p>
<p>Copy<br>wsl –import-in-place <Distribution Name> <FileName><br>Imports the specified .vhdx file as a new distribution. The virtual hard disk must be formatted in the ext4 filesystem type.</p>
<p>Unregister or uninstall a Linux distribution<br>While Linux distributions can be installed through the Microsoft Store, they can’t be uninstalled through the store.</p>
<p>To unregister and uninstall a WSL distribution:</p>
<p>PowerShell</p>
<p>Copy<br>wsl –unregister <DistributionName><br>Replacing <DistributionName> with the name of your targeted Linux distribution will unregister that distribution from WSL so it can be reinstalled or cleaned up. Caution: Once unregistered, all data, settings, and software associated with that distribution will be permanently lost. Reinstalling from the store will install a clean copy of the distribution. For example, wsl –unregister Ubuntu would remove Ubuntu from the distributions available in WSL. Running wsl –list will reveal that it is no longer listed.</p>
<p>You can also uninstall the Linux distribution app on your Windows machine just like any other store application. To reinstall, find the distribution in the Microsoft Store and select “Launch”.</p>
<p>Mount a disk or device<br>PowerShell</p>
<p>Copy<br>wsl –mount <DiskPath><br>Attach and mount a physical disk in all WSL2 distributions by replacing <DiskPath> with the directory\file path where the disk is located. See Mount a Linux disk in WSL 2. Options include:</p>
<p>–vhd: Specifies that <Disk> refers to a virtual hard disk.<br>–name: Mount the disk using a custom name for the mountpoint<br>–bare: Attach the disk to WSL2, but don’t mount it.<br>–type <Filesystem>: Filesystem type to use when mounting a disk, if not specified defaults to ext4. This command can also be entered as: wsl –mount -t <Filesystem>.You can detect the filesystem type using the command: blkid <BlockDevice>, for example: blkid &lt;dev&#x2F;sdb1&gt;.<br>–partition <Partition Number>: Index number of the partition to mount, if not specified defaults to the whole disk.<br>–options <MountOptions>: There are some filesystem-specific options that can be included when mounting a disk. For example, ext4 mount options like: wsl –mount -o “data-ordered” or wsl –mount -o “data&#x3D;writeback. However, only filesystem-specific options are supported at this time. Generic options, such as ro, rw, or noatime, are not supported.<br> Note</p>
<p>If you’re running a 32-bit process in order to access wsl.exe (a 64-bit tool), you may need to run the command in the following manner: C:\Windows\Sysnative\wsl.exe –command.</p>
<p>Unmount disks<br>PowerShell</p>
<p>Copy<br>wsl –unmount <DiskPath><br>Unmount a disk given at the disk path, if no disk path is given then this command will unmount and detach ALL mounted disks.</p>
<p>Deprecated WSL commands<br>PowerShell</p>
<p>Copy<br>wslconfig.exe [Argument] [Options]<br>PowerShell</p>
<p>Copy<br>bash [Options]<br>PowerShell</p>
<p>Copy<br>lxrun &#x2F;[Argument]<br>These commands were the original wsl syntax for configuring Linux distributions installed with WSL, but have been replaced with the wsl or wsl.exe command syntax.</p>
<h1 id="wsl2-v2ray"><a href="#wsl2-v2ray" class="headerlink" title="wsl2 v2ray"></a>wsl2 v2ray</h1><p>wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。</p>
<p>允许来自局域网的连接<br>多路复用</p>
<p>局域网默认端口socks:10808 http:10809</p>
<p>如果说Win10去访问WSL2可以直接通过Localhost访问的，但是WSL2去访问WIN10就不能再用Localhost了，而WSL2在WIN10中是被单独的分配了一个IP。 想查WIN10当中WSL2的IP，只需要通过下方这条命令来获取WSL2的地址即可。在WSL2中敲入下面命令<br>cat &#x2F;etc&#x2F;resolv.conf<br>得到如下反馈信息</p>
<p>#This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to &#x2F;etc&#x2F;wsl.conf:<br>#[network]<br>#generateResolvConf &#x3D; false<br>nameserver 172.18.64.1</p>
<p>我们知道了WSL2的IP后可以使用填写固定IP的方法来配置代理，但是每次启动WSL2会重新再次分配IP，这样就很麻烦。上面让大家记的局域网socks端口10808就是填入到下方端口位置的，下面我设置这些环境变量写入到的~&#x2F;.bashrc中，这样每次启动WSL2就会自动生效</p>
<p>也可以用在其他linux机器上</p>
<p>export windows_host&#x3D;<code>cat /etc/resolv.conf|grep nameserver|awk &#39;&#123;print $2&#125;&#39;</code><br>export windows_host&#x3D;192.168.1.104<br>export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;$windows_host:10808<br>export HTTP_PROXY&#x3D;$ALL_PROXY<br>export http_proxy&#x3D;$ALL_PROXY<br>export HTTPS_PROXY&#x3D;$ALL_PROXY<br>export https_proxy&#x3D;$ALL_PROXY</p>
<p>if [ “<code>git config --global --get proxy.https</code>“ !&#x3D; “socks5:&#x2F;&#x2F;$windows_host:10808” ]; then<br>  git config –global proxy.https socks5:&#x2F;&#x2F;$windows_host:10808<br>fi</p>
<h1 id="for-windows-powershell"><a href="#for-windows-powershell" class="headerlink" title="for windows powershell"></a>for windows powershell</h1><p>Invoke-WebRequest -Uri <a target="_blank" rel="noopener" href="https://www.google.com/">https://www.google.com</a><br>curl -vv <a target="_blank" rel="noopener" href="http://www.google.com/">www.google.com</a><br>HTTP&#x2F;2 200</p>
<p>Invoke-WebRequest -Uri <a target="_blank" rel="noopener" href="https://www.youtube.com/">https://www.youtube.com</a><br>curl -vv <a target="_blank" rel="noopener" href="https://www.youtube.com/">https://www.youtube.com</a></p>
<h1 id="wsl-和-VT-x-应用-模拟器-冲突-可切换"><a href="#wsl-和-VT-x-应用-模拟器-冲突-可切换" class="headerlink" title="wsl 和 VT-x 应用(模拟器)冲突, 可切换"></a>wsl 和 VT-x 应用(模拟器)冲突, 可切换</h1><p>Disable-WindowsOptionalFeature -Online -FeatureName VirtualMachinePlatform<br>Enable-WindowsOptionalFeature -Online -FeatureName VirtualMachinePlatform<br>(dism.exe &#x2F;online &#x2F;enable-feature &#x2F;featurename:VirtualMachinePlatform &#x2F;all &#x2F;norestart)</p>
<h2 id="在wsl2中查看IP地址"><a href="#在wsl2中查看IP地址" class="headerlink" title="在wsl2中查看IP地址"></a>在wsl2中查看IP地址</h2><p>ip addr show eth0 | grep inet | awk ‘{ print $2; }’ | sed ‘s&#x2F;/.*$&#x2F;&#x2F;‘<br>172.29.10.87</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/spin-spin/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/spin-spin/" class="post-title-link" itemprop="url">spin-spin</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 19:48:25" itemprop="dateCreated datePublished" datetime="2024-06-15T19:48:25+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:21" itemprop="dateModified" datetime="2024-07-30T00:45:21+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>read_yaml.py</p>
<p>之前的工作通过hyperfine parameters的计算指认了不同13C格位的EPR谱<br>\cite{Smeltzer_2011}<br>hyperfine interaction在应力下的响应<br>\cite{PhysRevApplied.18.064042}<br>\cite{PhysRevB.98.075201}</p>
<p>实验 14N 15N 在室温下的温度响应<br><a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2212.12169">https://doi.org/10.48550/arXiv.2212.12169</a></p>
<p>state of art 实验给出了精确的hyperfine 随温度的变化<br>通过初步计算验证了通过计算确定hyperfine精细变化的可行性\cite{prb2023}</p>
<h1 id="Spin-contamination"><a href="#Spin-contamination" class="headerlink" title="Spin contamination"></a>Spin contamination</h1><p>FERWE&#x3D;380<em>1 2000</em>0<br>FERDO&#x3D;379<em>1 0 1 2000</em>0</p>
<p><a target="_blank" rel="noopener" href="https://www.wikiwand.com/en/Spin_contamination">https://www.wikiwand.com/en/Spin_contamination</a><br><a target="_blank" rel="noopener" href="https://www.annualreviews.org/doi/pdf/10.1146/annurev-matsci-070218-121825">https://www.annualreviews.org/doi/pdf/10.1146/annurev-matsci-070218-121825</a></p>
<p><img src="/image-17.png" alt="Alt text"></p>
<h1 id="pycce"><a href="#pycce" class="headerlink" title="pycce"></a>pycce</h1><p>PyCCE: A Python Package for Cluster Correlation Expansion Simulations of Spin Qubit Dynamics</p>
<h1 id="ZFS"><a href="#ZFS" class="headerlink" title="ZFS"></a>ZFS</h1><p>First principles method for the calculation of zero-field splitting tensors in periodic systems<br><a target="_blank" rel="noopener" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.77.035119">https://journals.aps.org/prb/abstract/10.1103/PhysRevB.77.035119</a></p>
<p>The spin–spin zero-field splitting tensor in the projector-augmented-wave method<br><a target="_blank" rel="noopener" href="https://iopscience.iop.org/article/10.1088/0953-8984/26/1/015305">https://iopscience.iop.org/article/10.1088/0953-8984/26/1/015305</a></p>
<p>Phonon Induced Spin Dephasing Time of Nitrogen Vacancy Centers in Diamond from First Principles<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2209.11412">https://arxiv.org/abs/2209.11412</a></p>
<p>Martijn Marsman vasp zero field splitting</p>
<p>Gali Maze Temperature-Dependent Spin-Lattice Relaxation of the Nitrogen-Vacancy Spin Triplet in Diamond<br><a target="_blank" rel="noopener" href="https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.130.256903">https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.130.256903</a><br><a target="_blank" rel="noopener" href="https://journals.aps.org/prl/supplemental/10.1103/PhysRevLett.130.256903/Temperature_dependent_relaxation_rates-supp.pdf">https://journals.aps.org/prl/supplemental/10.1103/PhysRevLett.130.256903/Temperature_dependent_relaxation_rates-supp.pdf</a></p>
<p>Nuclear spin relaxation in solid state defect quantum bits via electron-phonon coupling in their optical excited state<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.19418">https://arxiv.org/abs/2402.19418</a></p>
<p>Ab initio calculation of the spin lattice relaxation time 𝑇1 for nitrogen-vacancy centers in diamond<br><a target="_blank" rel="noopener" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.98.214442">https://journals.aps.org/prb/abstract/10.1103/PhysRevB.98.214442</a></p>
<p>Vibrational modes and lattice distortion of a nitrogen-vacancy center in diamond from first-principles calculations<br><a target="_blank" rel="noopener" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.84.035211">https://journals.aps.org/prb/abstract/10.1103/PhysRevB.84.035211</a></p>
<h1 id="hyperfine"><a href="#hyperfine" class="headerlink" title="hyperfine"></a>hyperfine</h1><p>Hyperfine coupling of point defects in semiconductors by hybrid density functional calculations: The role of core spin polarization</p>
<p><a target="_blank" rel="noopener" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.88.075202">https://journals.aps.org/prb/abstract/10.1103/PhysRevB.88.075202</a></p>
<p><a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41524-023-01082-9">Spin-phonon decoherence in solid-state paramagnetic defects from first principles</a></p>
<p>Here we consider the modulation of the zero-field splitting D as the source of spin-phonon coupling and numerically compute its first and second-order derivatives. In order to reduce the computational overheads associated with a second-order numerical differentiation, we trained a neural network on a set of D values computed with DFT over 1600 random distortions of the considered cluster20,29. The neural network is tested over 400 residual distortions not used during the training and shows a remarkable ability to predict the values of D for unseen geometries with a root-mean-squared error of only 1.8 × 10−4 cm−1 for NV− and 2.6 × 10−4 cm−1 for VB-, see Supplementary Figures 9–11. The net is then used to perform a 6- and 36-point numerical differentiation of D for first- and second-order, respectively. Differentiation is carried out with respect to atomic Cartesian coordinates and then mapped to the representation of normal modes by means of Eqs. (13) and (14), as detailed in the Methods section. </p>
<p>The training sets for the neural network have been generated by calculating the D-tensor for over 2000 distorted structures. The distorted structures were obtained by displacing all the Cartesian coordinates of all the atoms from the optimized geometry. The displacement was given by a random value in the range from − 0.05 Å to 0.05 Å. Among the total of 2000 distorted geometries, 1600 were used for training the ML models, while 400 were used for validation. The neural network we used has 3 hidden layers consisting of 128, 64, and 16 nodes, respectively. The input layer has 3N nodes, where N is the number of atoms present in the cluster, and the output layer has 9 nodes. Each hidden layer has a sigmoid as the activation function and L2-regularization.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/bmc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/bmc/" class="post-title-link" itemprop="url">bmc</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 19:44:17" itemprop="dateCreated datePublished" datetime="2024-06-15T19:44:17+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:20" itemprop="dateModified" datetime="2024-07-30T00:45:20+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="华硕-KRPA-U16-bmc-网线连接"><a href="#华硕-KRPA-U16-bmc-网线连接" class="headerlink" title="华硕 KRPA-U16 bmc 网线连接"></a>华硕 KRPA-U16 bmc 网线连接</h1><h2 id="修改BIOS设置"><a href="#修改BIOS设置" class="headerlink" title="修改BIOS设置"></a>修改BIOS设置</h2><p>del 进BIOS Server Mgmt菜单<br>设置DM_LAN1(管理口) 为 Static<br>设置Station IP为192.168.0.100 (共用 192.168.1.103)<br>子关掩码设置为255.255.255.0<br>Router IP address即网关&#x2F;路由器的IP地址, 指定为192.168.0.1 (192.168.1.1)<br>sudo 726622</p>
<h2 id="本地设置"><a href="#本地设置" class="headerlink" title="本地设置"></a>本地设置</h2><p>手动指定本地电脑的IP地址&#x2F;子关掩码&#x2F;网关<br>在出现的机器里的网络设备中找到以太网的设备, 右键点击, 选择“属性”<br>在网卡属性连的TCP&#x2F;IPV4协议的属性里, 选择“使用下面的IP地址”, 即手动设置IP地址方式, 将IP地址设置为与被测试对象同一网段下的某个地址, 比如设置为192.168.0.101,子关掩码设置255.255.255.0, 默认网关设置为与服务器BMC设置中一样的192.168.0.1</p>
<p>将网线一头插入到被测试服务器的管理网口（DMLan端口）, 一头插入到笔记本的网卡接口上, 查看连接属性, 显示为未识别的网络, 这很正常, 毕竟是双机互联没有外网. 打开浏览器, 在浏览器的地址栏里输入被测试对象服务器里设置过的BMC的IP地址, 即192.168.0.100, 就出现了BMC的登录界面</p>
<h1 id="重置-华硕-KRPA-U16-bmc-账户密码"><a href="#重置-华硕-KRPA-U16-bmc-账户密码" class="headerlink" title="重置 华硕 KRPA-U16 bmc 账户密码"></a>重置 华硕 KRPA-U16 bmc 账户密码</h1><p>超微&#x2F;华硕等服务器主板的远程管理 IPMI BMC 基本都基于AMI提供的标准底层来进行开发的, 经常遇到二手主板被之前用家设置了BMC密码以后无法登录, 下面内容在超微 H11SSL-I, 华硕 KRPA-U16 (ASMB9-iKVM)上测试成功. </p>
<p>下载超微官网的IPMICFG软件, 包含了 DOS UEFI WINDOWS LINUX等版本, 下载需要注册一个Supermicro的账号 <a target="_blank" rel="noopener" href="https://www.supermicro.com/en/support/resources/downloadcenter/smsdownload?category=IPMI">https://www.supermicro.com/en/support/resources/downloadcenter/smsdownload?category=IPMI</a></p>
<p>cmd命令行进入该目录, 使用 IPMICFG-Win.exe -user list列出所有用户, 查看一下需要修改密码的用户名对应的 user ID, 本例用户名为 admin,  user ID 为 2, 使用 IPMICFG-Win.exe -user setpwd 2 administrator来把 user ID 为 2 的密码更改为 administrator</p>
<h1 id="浪潮5588M3-超微7047GR-IPMI默认密码"><a href="#浪潮5588M3-超微7047GR-IPMI默认密码" class="headerlink" title="浪潮5588M3&#x2F;超微7047GR IPMI默认密码"></a>浪潮5588M3&#x2F;超微7047GR IPMI默认密码</h1><p>用户名：ADMIN<br>密码：ADMIN</p>
<p>epyc ipmi</p>
<p>用户名: admin<br>密码: Zaqwsx1995</p>
<p>x299 ipmi<br>用户名: ADMIN<br>密码: Zaqwsx1995</p>
<h1 id="fan-speed-control-raw"><a href="#fan-speed-control-raw" class="headerlink" title="fan speed control raw"></a>fan speed control raw</h1><h1 id="阈值调节"><a href="#阈值调节" class="headerlink" title="阈值调节"></a>阈值调节</h1><p>ipmitool sensor thresh FAN3 lower 150 225 300 #non-recoverable critical non-critcal</p>
<p>有些Homelab用户追求静音，猫扇一装，直接报警，或者经常出现间歇性满载停转满载停转的事情。猫扇的转速很低，一般远低于主板的警告范围，所以需要手动修正。</p>
<p>以12025的猫扇为例，一般低负载的时候是300RPM，满转才不到2000RPM，所以需要修改ipmi的报警阈值。</p>
<p>报警阈值修改方法</p>
<p>登录服务器实体机的ssh（windows宿主请下载安装ipmitool）</p>
<p>随后输入命令 sudo ipmitool sensor thresh “FANC” lower 432 648 864</p>
<p>sudo ipmitool sensor thresh “FANC” lower 432 4000 4200</p>
<p>ipmitool sensor thresh是指令，红色部分是要修改的风扇接口，根据自己风扇确定，lower是代表低于某数值该如何处理（upper是高于某数值）。粉色是致命故障阈值，绿色是严重故障阈值，天蓝色是需要警惕的阈值（Non Recoverable, Critical, Non Critical）</p>
<p>执行后立即生效。不推荐都设为0，也不推荐设置太低，因为有时候风扇真的故障了可能自己都不知道。建议Non Critical设置为正常最低速度运行值的-25%（风扇测速误差）， Critical设为-45%，Non Recoverable设为-60%。比如猫扇低负载300，则可设置为120 165 225。</p>
<h1 id="模式介绍"><a href="#模式介绍" class="headerlink" title="模式介绍"></a>模式介绍</h1><p>The Standard Speed profile is temperature controlled, with a base fan speed at 50% PWM duty cycle. This means that fan speeds will be between 50-100%, depending on system temperature.</p>
<p>The Optimal Speed profile is also temperature controlled, but with a base fan speed at 30% PWM duty cycle, broadening the span to 30-100% to allow the system to save energy while idle.</p>
<p>The Heavy IO profile sets 75% PWM duty cycle for fans attached to fan headers FAN A and FAN B, which typically blow on the PCI slots. This mode also uses the Standard mode to manage fans that cool the CPU&#x2F;RAM.</p>
<p>The PUE Optimal profile is a power saving mode for select motherboards that lowers the fan speeds and power consumption as often as possible, similar to the Optimal profile, but prioritizes low power consumption over performance.</p>
<p>The Full Speed profile sets the fans to run constantly at full speed.</p>
<p>To set with IPMICFG, get the current status of the fan mode:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipmicfg -fan</span><br></pre></td></tr></table></figure>


<p>This should display the current fan mode, and will also list the available modes to choose from. Once you’ve decided on the desired fan speed mode, set it with the following command:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipmicfg -fan &lt;n&gt;</span><br></pre></td></tr></table></figure>
<p>Where n is the integer that corresponds to your desired fan speed mode.</p>
<p>When using ipmitool to set fan speeds, you can send it in the form of a raw command instead. IPMICFG will still be able to display available fan modes, if you are not sure which modes your board supports. Example raw command:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipmitool raw 0x30 0x45 1 &lt;n&gt;</span><br></pre></td></tr></table></figure>
<p>To send this command remotely to a system, add the necessary options for a remote login:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipmitool -I lanplus -H &lt;hostname or IP&gt; -U &lt;user name&gt; -P &lt;password&gt; raw 0x30 0x45 1 &lt;n&gt;</span><br></pre></td></tr></table></figure>
<p>To set from the IPMI web interface, connect to the system by entering its IP address into the web browser on a client system.</p>
<h1 id="转速调节"><a href="#转速调节" class="headerlink" title="转速调节"></a>转速调节</h1><p>首先将风扇调成【Full】：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo /home/duguex/ipmicfg -fan 1</span><br><span class="line"></span><br><span class="line">0:Standard</span><br><span class="line">1:Full</span><br><span class="line">2:Optimal</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>也可以用raw指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ipmicfg -raw 0x30 0x45 0x01 0x01</span><br></pre></td></tr></table></figure>
<p>最后的16进制数字0x01代表【Full】模式，同时还有其他模式分别是0x00的【Standard】，0x02的【Optimal】，最后是0x03的【Heavy IO】</p>
<p>之所以先设置成全速模式是因为假如不设置全速模式，我们自定义的转速马上就会被自动转速刷新，从而没有实际效果。</p>
<p>接下来设置转速百分比：</p>
<p>.&#x2F;ipmicfg -raw 0x30 0x70 0x66 0x01 0x00 0x20<br>.&#x2F;ipmicfg -raw 0x30 0x70 0x66 0x01 0x01 0x20</p>
<p>最后一位16进制代表转速百分比。范围为0x01-0x64,0x20就代表转速为32%。<br>倒数第二位16进制代表的是区域范围。0x00代表系统区域，这个区域一般为负责CPU的风扇，对应风扇编号为FAN1,2,3,4,5,6。0x00代表周边设备区域，对应风扇编号为FANA,B,C,D之类</p>
<p>查看当前风扇模式和支持的风扇模式</p>
<p>sudo .&#x2F;ipmicfg -fan<br>sudo .&#x2F;ipmicfg -raw 0x30 0x45 0x01 0x01<br>sudo .&#x2F;ipmicfg -raw 0x30 0x70 0x66 0x01 0x00 0x20<br>sudo .&#x2F;ipmicfg -raw 0x30 0x70 0x66 0x01 0x01 0x20</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IPMICFG-Win.exe -fan</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./IPMICFG-Linux.x86_64 -fan</span><br></pre></td></tr></table></figure>
<p>Current Fan Speed Mode is [ Optimal Mode ]<br>Supported Fan modes: 0:Standard 1:Full 2:Optimal 4:Heavy IO</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IPMICFG-Win.exe -fan 4</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./IPMICFG-Linux.x86_64 -fan 4</span><br></pre></td></tr></table></figure>
<p>Done.<br>[root@bogon 64bit]# .&#x2F;IPMICFG-Linux.x86_64 -fan Current Fan Speed Mode is [ Heavy IO speed Mode ]</p>
<p>ipmitool -H 192.168.137.2 -U ADMIN -P ADMIN raw 0x30 0x70 0x66 0x01 0x00 0x24<br>ipmitool -H 192.168.137.2 -U ADMIN -P ADMIN raw 0x30 0x70 0x66 0x01 0x01 0x24<br>后面的0x24 代表 转速 从 0 到 0X64，</p>
<p>In order to force the fans at a particular speed all the time, you need to do the following on a Supermicro X9 board:</p>
<p>Set IPMI fan mode to “Full”<br>Set fan speed for the particular zone to the percentage fan speed you desire, expressed as a hexadecimal number. On the X9 boards, the possible speed range is 0-255, which is 0-100% expressed as hex, but on a scale where 0% &#x3D; 0x00 and 100% &#x3D; 0xff.<br>In your case, with 14k fans, you want their speed at 8k, so the ratio is 57% (8000 &#x2F; 14000 &#x3D; .57142…)</p>
<p>Take 255 * .57 &#x3D; 145.35 &#x3D; 0x91 would be your speed value. Now plug that in.</p>
<p>Step 1: Set “fan mode” to “Full”</p>
<p>{ipmitool command syntax} raw 0x30 0x45 0x01 0x01<br>Step 2: Set “fan speed” to 57%</p>
<p>For Zone 0 (normally CPU fans or FAN_ where _ &#x3D; a number, e.g. FAN1):</p>
<p>{ipmitool command syntax} raw 0x30 0x91 0x5A 0x03 0x00 0x91<br>For Zone 1 (normally peripheral fans or FAN_ where _ &#x3D; a letter, e.g. FANA):</p>
<p>{ipmitool command syntax} raw 0x30 0x91 0x5A 0x03 0x01 0x91<br>NOTE1: Verified on a Supermicro X9DRi-F with Nuvoton WPCM450 BMC.<br>X9DRG-QF<br>NOTE2: X10 boards operate differently. Some raw commands are different, and their %age fan speed is 0-100, not 0-255.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sudo ./ipmicfg -raw 0x30 0x45 0x01 0x01</span><br><span class="line"></span><br><span class="line">0-255</span><br><span class="line">sudo ./ipmicfg -raw 0x30 0x45 0x01 0x01;</span><br><span class="line">sudo ./ipmicfg -raw 0x30 0x91 0x5A 0x03 0x00 0xFF;</span><br><span class="line">sudo ./ipmicfg -raw 0x30 0x91 0x5A 0x03 0x01 0xFF;</span><br><span class="line"></span><br><span class="line">sudo ipmitool raw 0x30 0x45 0x01 0x01;</span><br><span class="line">sudo ipmitool raw 0x30 0x91 0x5A 0x03 0x00 0xBF;</span><br><span class="line">sudo ipmitool raw 0x30 0x91 0x5A 0x03 0x01 0xFF;</span><br><span class="line"></span><br><span class="line">sudo ./ipmicfg -raw 0x30 0x45 0x01 0x01</span><br><span class="line">sudo ipmitool raw 0x30 0x70 0x66 0x01 0x00 0x32</span><br><span class="line">sudo ipmitool raw 0x30 0x70 0x66 0x01 0x01 0x64</span><br><span class="line"></span><br><span class="line">0-100</span><br><span class="line">sudo ./ipmicfg -raw 0x30 0x45 0x01 0x01</span><br><span class="line">sudo ./ipmicfg -raw 0x30 0x70 0x66 0x01 0x00 0x32</span><br><span class="line">sudo ./ipmicfg -raw 0x30 0x70 0x66 0x01 0x01 0x64</span><br></pre></td></tr></table></figure>

<p>ipmitool -U <user name> -P <password> -H <hostname or IP> raw 0x30 0x70 0x66 0x01 0x00 0x&lt;01 - 64&gt;<br>If your fans spin at a max of 14000 RPM and you wanted them to spin at 8000 RPM then you’d set the duty to 0x37<br>ipmitool -U <user name> -P <password> -H <hostname or IP> raw 0x30 0x70 0x66 0x01 0x00 0x37</p>
<p>+1 as this worked for me on a Supermicro 4028GR-TR (X9-Board)! To get the current values use ipmitool raw 0x30 0x70 0x66 0x00 0x0[0|1] with the last value specifying the region (0&#x3D;&#x3D;CPU-zone, 1&#x3D;peripheral-zone) </p>
<h1 id="fan-control-supermicro"><a href="#fan-control-supermicro" class="headerlink" title="fan control supermicro"></a>fan control supermicro</h1><p>sudo apt install lm-sensors<br>cpu_temperature&#x3D;<code>sensors | grep &quot;Package&quot; | awk &#39;&#123;print $4&#125;&#39; | cut -d &#39;+&#39; -f 2 | cut -d &#39;.&#39; -f 1</code><br>gpu_temperature&#x3D;<code>nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader | sort -rn | head -n 1</code></p>
<p>#!&#x2F;bin&#x2F;bash<br>cpu_temperature&#x3D;<code>jq .cpu /tmp/temperature.json</code><br>gpu_temperature&#x3D;<code>jq .gpu /tmp/temperature.json</code><br>fan_mode&#x3D;<code>/home/duguex/ipmicfg -fan | grep &quot;Current Fan Speed Mode&quot; | awk &#39;&#123;print $7&#125;&#39;</code></p>
<p>#initiate fan speed mode to Full, then set fan speed to 50%<br>if [ “$fan_mode” !&#x3D; “Full” ]; then<br>    &#x2F;home&#x2F;duguex&#x2F;ipmicfg -fan 1<br>    cpu_fan&#x3D;0x32<br>    gpu_fan&#x3D;0x32<br>fi</p>
<p>if [ -z “$cpu_temperature” ] || [ -z “$gpu_temperature” ]; then<br>    <!-- /home/duguex/ipmicfg -raw 0x30 0x70 0x66 0x01 0x00 0x64
    /home/duguex/ipmicfg -raw 0x30 0x70 0x66 0x01 0x01 0x64 --><br>    cpu_fan&#x3D;0x64<br>    gpu_fan&#x3D;0x64<br>else<br>    if [ “$cpu_temperature” -ge 70 ]; then<br>        cpu_fan&#x3D;0x64<br>    elif [ “$cpu_temperature” -ge 50 ]; then<br>        cpu_fan&#x3D;0x48<br>    else<br>        cpu_fan&#x3D;0x32<br>    fi</p>
<pre><code>if [ &quot;$gpu_temperature&quot; -ge 60 ]; then
    gpu_fan=0x64
elif [ &quot;$gpu_temperature&quot; -ge 50 ]; then
    gpu_fan=0x48
else
    gpu_fan=0x32
fi
</code></pre>
<p>fi</p>
<p>echo “CPU temperature: $cpu_temperature”<br>echo “GPU temperature: $gpu_temperature”<br>echo “CPU fan speed: $cpu_fan”<br>echo “GPU fan speed: $gpu_fan”</p>
<!-- /home/duguex/ipmicfg -raw 0x30 0x70 0x66 0x01 0x00 $cpu_fan
/home/duguex/ipmicfg -raw 0x30 0x70 0x66 0x01 0x01 $gpu_fan -->


<p>set-fan-speed.sh<br>temperature-monitor.service</p>
<h1 id="get-temperature-sh"><a href="#get-temperature-sh" class="headerlink" title="get-temperature.sh"></a>get-temperature.sh</h1><p>#!&#x2F;bin&#x2F;bash</p>
<h1 id="install-sensors-by-sudo-apt-install-lm-sensors"><a href="#install-sensors-by-sudo-apt-install-lm-sensors" class="headerlink" title="install sensors by sudo apt install lm-sensors"></a>install sensors by sudo apt install lm-sensors</h1><p>cpu_temperature&#x3D;<code>sensors | grep &quot;Package&quot; | awk &#39;&#123;print $4&#125;&#39; | cut -d &#39;+&#39; -f 2 | cut -d &#39;.&#39; -f 1</code><br>gpu_temperature&#x3D;<code>nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader | sort -rn | head -n 1</code></p>
<p>jq -n –argjson cpu_temperature “$cpu_temperature” –argjson gpu_temperature “$gpu_temperature” ‘{“cpu”: $cpu_temperature, “gpu”: $gpu_temperature}’ &gt; &#x2F;tmp&#x2F;temperature.json</p>
<h1 id="set-fan-speed-sh"><a href="#set-fan-speed-sh" class="headerlink" title="set-fan-speed.sh"></a>set-fan-speed.sh</h1><p>#!&#x2F;bin&#x2F;bash<br>cpu_temperature&#x3D;<code>jq .cpu /tmp/temperature.json</code><br>gpu_temperature&#x3D;<code>jq .gpu /tmp/temperature.json</code><br>fan_mode&#x3D;<code>/home/duguex/ipmicfg -fan | grep &quot;Current Fan Speed Mode&quot; | awk &#39;&#123;print $7&#125;&#39;</code><br>#initiate fan speed mode to Full, then set fan speed to 50%<br>if [ “$fan_mode” !&#x3D; “Full” ]; then<br>    echo “init fan”<br>    &#x2F;home&#x2F;duguex&#x2F;ipmicfg -fan 1<br>    cpu_fan&#x3D;0x32<br>    gpu_fan&#x3D;0x32<br>fi</p>
<p>if [ -z “$cpu_temperature” ] || [ -z “$gpu_temperature” ]; then<br>    cpu_fan&#x3D;0x48<br>    gpu_fan&#x3D;0x48<br>else<br>    if [ “$cpu_temperature” -ge 70 ]; then<br>        cpu_fan&#x3D;0x64<br>    elif [ “$cpu_temperature” -ge 50 ]; then<br>        cpu_fan&#x3D;0x4b<br>    else<br>        cpu_fan&#x3D;0x32<br>    fi</p>
<pre><code>if [ &quot;$gpu_temperature&quot; -ge 70 ]; then
    gpu_fan=0x64
elif [ &quot;$gpu_temperature&quot; -ge 60 ]; then
    gpu_fan=0x58
elif [ &quot;$gpu_temperature&quot; -ge 50 ]; then
    gpu_fan=0x4b
else
    gpu_fan=0x32
fi
</code></pre>
<p>fi</p>
<p>&#x2F;home&#x2F;duguex&#x2F;ipmicfg -raw 0x30 0x70 0x66 0x01 0x00 $cpu_fan<br>&#x2F;home&#x2F;duguex&#x2F;ipmicfg -raw 0x30 0x70 0x66 0x01 0x01 $gpu_fan</p>
<h1 id="temperature-monitor-service"><a href="#temperature-monitor-service" class="headerlink" title="temperature-monitor.service"></a>temperature-monitor.service</h1><p>[Unit]<br>Description&#x3D;cpu and gpu temperature monitor<br>After&#x3D;lm-sensors.service<br>[Service]<br>User&#x3D;duguex<br>ExecStart&#x3D;&#x2F;home&#x2F;duguex&#x2F;get-temperature.sh<br>Restart&#x3D;always<br>RestartSec&#x3D;10s<br>[Install]<br>WantedBy&#x3D;multi-user.target</p>
<h1 id="fan-control-service"><a href="#fan-control-service" class="headerlink" title="fan-control.service"></a>fan-control.service</h1><p>[Unit]<br>Description&#x3D;control fan speed according to temperature<br>After&#x3D;temperature-monitor.service<br>[Service]<br>User&#x3D;root<br>ExecStart&#x3D;&#x2F;home&#x2F;duguex&#x2F;set-fan-speed.sh<br>Restart&#x3D;always<br>RestartSec&#x3D;10s<br>[Install]<br>WantedBy&#x3D;multi-user.target</p>
<p>sudo systemctl enable temperature-monitor<br>sudo systemctl enable fan-control</p>
<p>sudo systemctl status temperature-monitor<br>sudo systemctl status fan-control</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/vasp-compile/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/vasp-compile/" class="post-title-link" itemprop="url">vasp_compile</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 17:10:19" itemprop="dateCreated datePublished" datetime="2024-06-15T17:10:19+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:21" itemprop="dateModified" datetime="2024-07-30T00:45:21+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Building-VASP-6-3-X-to-6-4-X-on-Ubuntu-22-04"><a href="#Building-VASP-6-3-X-to-6-4-X-on-Ubuntu-22-04" class="headerlink" title="Building VASP 6.3.X to 6.4.X on Ubuntu 22.04"></a>Building VASP 6.3.X to 6.4.X on Ubuntu 22.04</h1><p>from <a target="_blank" rel="noopener" href="https://www.vasp.at/wiki/index.php/Personal_computer_installation">https://www.vasp.at/wiki/index.php/Personal_computer_installation</a></p>
<p>First, we need to make sure that the prerequisites for building VASP are met. Here, we install the following compiler and libraries from the system’s package manager:</p>
<table>
<thead>
<tr>
<th>Compiler</th>
<th>MPI</th>
<th>FFT</th>
<th>BLAS</th>
<th>LAPACK</th>
<th>ScaLAPACK</th>
<th>HDF5</th>
<th>Known issues</th>
</tr>
</thead>
<tbody><tr>
<td>gcc-11.2.0</td>
<td>openmpi-4.1.2</td>
<td>fftw-3.3.8</td>
<td>openblas-0.3.20</td>
<td>netlib-scalapack-2.1.0</td>
<td>hdf5-1.10.7</td>
<td>-</td>
<td></td>
</tr>
</tbody></table>
<p>These packages can be installed directly from the command line like this:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update &amp;&amp; sudo apt upgrade &amp;&amp; sudo apt install rsync make build-essential g++ gfortran libopenblas-dev libopenmpi-dev libscalapack-openmpi-dev libfftw3-dev libhdf5-openmpi-dev lrzsz nano</span><br><span class="line"></span><br><span class="line">apt update &amp;&amp; apt upgrade &amp;&amp; apt install rsync make build-essential g++ gfortran libopenblas-dev libopenmpi-dev libscalapack-openmpi-dev libfftw3-dev libhdf5-openmpi-dev lrzsz nano</span><br></pre></td></tr></table></figure>

<p>Next, unpack the VASP source code to a location of your choice. Then change into the VASP base directory and use the arch&#x2F;makefile.include.gnu_omp template as basis for the makefile.include:</p>
<p>cp arch&#x2F;makefile.include.gnu_omp makefile.include</p>
<p>Search for the paragraph in makefile.include starting with ## Customize as of this point! and apply the following changes below:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Comment out the OPENBLAS_ROOT variable (not needed) and set BLASPACK:</span><br><span class="line"></span><br><span class="line">#BLAS and LAPACK (mandatory)</span><br><span class="line">#OPENBLAS_ROOT ?= /path/to/your/openblas/installation</span><br><span class="line">BLASPACK = -lopenblas</span><br><span class="line"></span><br><span class="line">Comment out the SCALAPACK_ROOT variable (not needed) and set SCALAPACK:</span><br><span class="line"></span><br><span class="line">#scaLAPACK (mandatory)</span><br><span class="line">#SCALAPACK_ROOT ?= /path/to/your/scalapack/installation</span><br><span class="line">SCALAPACK = -lscalapack-openmpi</span><br><span class="line"></span><br><span class="line">Comment out the FFTW_ROOT variable (not needed). Set LLIBS and INCS in the FFTW section:</span><br><span class="line"></span><br><span class="line">#FFTW (mandatory)</span><br><span class="line">#FFTW_ROOT ?= /path/to/your/fftw/installation</span><br><span class="line">LLIBS += -lfftw3 -lfftw3_omp</span><br><span class="line">INCS += -I/usr/include</span><br><span class="line"></span><br><span class="line">Enable HDF5 support by adding -DVASP_HDF5 to the CPP_OPTIONS variable. Leave HDF5_ROOT variable commented out (not needed). Set LLIBS and INCS in the HDF5 section:</span><br><span class="line"></span><br><span class="line">#HDF5-support (optional but strongly recommended)</span><br><span class="line">CPP_OPTIONS+= -DVASP_HDF5</span><br><span class="line">#HDF5_ROOT ?= /path/to/your/hdf5/installation</span><br><span class="line">LLIBS += -L/usr/lib/x86_64-linux-gnu/hdf5/openmpi/ -lhdf5_fortran</span><br><span class="line">INCS += -I/usr/include/hdf5/openmpi/</span><br><span class="line"></span><br><span class="line"># For the fftlib library (recommended)</span><br><span class="line">CPP_OPTIONS+= -Dsysv</span><br><span class="line">FCL        += fftlib.o</span><br><span class="line">CXX_FFTLIB  = g++ -fopenmp -std=c++11 -DFFTLIB_THREADSAFE</span><br><span class="line">INCS_FFTLIB = -I./include -I/usr/include</span><br><span class="line">LIBS       += fftlib</span><br><span class="line">LLIBS      += -ldl</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Save your makefile.include and compile VASP:</p>
<p>make DEPS&#x3D;1 -j</p>
<p>Once the build process is complete the binaries are located in the VASP bin subfolder. They were compiled with OpenMP-threading support. Before running VASP please always check if the OMP_NUM_THREADS environment variable is set according to your needs. For example, if you require only pure MPI parallelization without OpenMP threading add</p>
<p>export OMP_NUM_THREADS&#x3D;1<br>export OMPI_ALLOW_RUN_AS_ROOT&#x3D;1<br>export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM&#x3D;1<br>PATH&#x3D;$PATH:&#x2F;opt&#x2F;vasp.6.4.2&#x2F;bin_gnu_default<br>export PATH</p>
<h1 id="singlarity-container-for-vasp"><a href="#singlarity-container-for-vasp" class="headerlink" title="singlarity container for vasp"></a>singlarity container for vasp</h1><p>.singularity.d&#x2F;env&#x2F;90-environment.sh<br>export OMPI_ALLOW_RUN_AS_ROOT&#x3D;1<br>export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM&#x3D;1</p>
<p>PATH&#x3D;$PATH:&#x2F;opt&#x2F;vasp.6.4.2&#x2F;bin<br>export PATH</p>
<h2 id="in-makefile-include"><a href="#in-makefile-include" class="headerlink" title="in makefile.include"></a>in makefile.include</h2><p>OFLAG &#x3D; -O2 -march&#x3D;core-avx2 #使用amd的avx2指令集<br>…<br>OBJECTS &#x3D; fftmpiw.o fftmpi_map.o fft3dlib.o fftw3d.o $(MKLROOT)&#x2F;interfaces&#x2F;fftw3xf&#x2F;libfftw3xf_intel.a<br>…</p>
<h2 id="in-bashrc"><a href="#in-bashrc" class="headerlink" title="in .bashrc"></a>in .bashrc</h2><p>export MKL_DEBUG_CPU_TYPE&#x3D;5<br>export MKL_CBWR&#x3D;AVX2<br>export I_MPI_PIN_DOMAIN&#x3D;numa</p>
<p>in your ~&#x2F;.bashrc file.</p>
<p>就目前而言，采用intel2019以及intel oneAPI在AMD平台上编译vasp具有可行性，按照和intel平台一样的编译方式，随后在bashrc里面加入export参数export MKL_DEBUG_CPU_TYPE&#x3D;5 和export MKL_CBWR&#x3D;AVX2即可。随后，对于第四代AMD EPYC（微型计算机2022 <a target="_blank" rel="noopener" href="http://www.bbs.cniti.combbs.cniti.com/index.php/article/index/id/16397%EF%BC%89%E6%8F%90%E5%88%B0%EF%BC%8C%E2%80%9CEPYC">http://www.bbs.cniti.combbs.cniti.com/index.php/article/index/id/16397）提到，“EPYC</a> 9554与EPYC 7763在双路配置性能上的对比。测试成绩显示尽管两款双路系统的核心数、线程数都为128核心、256线程配置，但使用新架构、DDR5内存，工作频率也更高的EPYC 9554在测试成绩上有非常显著的提升，其浮点运算性能较上一代产品提升了高达90.2%，整数运算性能也提升了多达62.2%。同时更为惊人的是，即便核心、线程数更少的EPYC 9374F双路系统（64核心、128线程）也战胜了核心、线程数翻倍的AMD EPYC 7763双路系统。”</p>
<p>#Mapping of process to hardware resources<br>#For AMD EPYC processors it is recommended to use a single rank per L3 cache and set OMP_NUM_THREADS to the number of cores per L3 cache. Below is the example for 4th Gen EPYC processors with 8 cores per L3 cache, hence using OMP_NUM_THREADS&#x3D;8</p>
<p>export NUM_CORES&#x3D;$(nproc)<br>export OMP_NUM_THREADS&#x3D;4<br>NUM_MPI_RANKS&#x3D;$(( $NUM_CORES &#x2F; $OMP_NUM_THREADS ))</p>
<h1 id="Running-VASP"><a href="#Running-VASP" class="headerlink" title="Running VASP"></a>Running VASP</h1><p>mpirun -np $NUM_MPI_RANKS –map-by ppr:1:l3cache:pe&#x3D;$OMP_NUM_THREADS vasp_gam</p>
<p>VASP AOCC</p>
<h1 id="vasp-test"><a href="#vasp-test" class="headerlink" title="vasp test"></a>vasp test</h1><p>After building the <code>vasp_std</code>, <code>vasp_gam</code>, and <code>vasp_ncl</code><br>executables (e.g. by means of <code>make all</code>), you can test your<br>build by means of:</p>
<pre><code>make test
</code></pre>
<p>(either in <code>root</code> or <code>root/testsuite</code>).</p>
<p>The above will run a subset of tests from the testsuite (the so-called<br><code>FAST CATEGORY</code> of tests) that will take roughly 1.5 hours to complete<br>on 4 cores.</p>
<p>The full testsuite may be executed by means of:</p>
<pre><code>make test_all
</code></pre>
<p>The output of the tests (<code>stdout+stderr</code>) is written to<br><code>root/testsuite/testsuite.log</code>.</p>
<p>Tests that fail write an <code>ERROR</code> to <code>root/testsuite/testsuite.log</code> and<br>the tests that were not passed successfully will be listed at the end of<br>this file (and <code>make</code> will exit in error).</p>
<p>To clean up after running the testsuite, execute:</p>
<pre><code>make cleantest
</code></pre>
<p>in <code>root/testsuite</code>.</p>
<ul>
<li><p><code>VASP_TESTSUITE_EXE_STD</code>:</p>
<p> The command that runs the standard version of VASP.<br> Default:<br>VASP_TESTSUITE_EXE_STD&#x3D;”mpirun -np 12 &#x2F;home&#x2F;duguex&#x2F;vasp.6.4.2&#x2F;bin&#x2F;vasp_std”;VASP_TESTSUITE_EXE_GAM&#x3D;”mpirun -np 12 &#x2F;home&#x2F;duguex&#x2F;vasp.6.4.2&#x2F;bin&#x2F;vasp_gam”;VASP_TESTSUITE_EXE_NCL&#x3D;”mpirun -np 12 &#x2F;home&#x2F;duguex&#x2F;vasp.6.4.2&#x2F;bin&#x2F;vasp_ncl”<br><strong>N.B.</strong>: Specify the absolute path your <em>standard</em> executable<br>  (e.g. <code>vasp_std</code> or <code>vasp_gpu</code>).</p>
</li>
<li><p><code>VASP_TESTSUITE_EXE_GAM</code>:</p>
<p>The command that runs the gamma-only version of VASP.<br>Default:<br>VASP_TESTSUITE_EXE_GAM&#x3D;”mpirun -np 12 &#x2F;home&#x2F;duguex&#x2F;vasp.6.4.2&#x2F;bin&#x2F;vasp_gam”<br><strong>N.B.</strong>: Specify the absolute path to your <em>gamma-only</em> executable<br>  (e.g. <code>vasp_gam</code>).</p>
</li>
<li><p><code>VASP_TESTSUITE_EXE_NCL</code>:</p>
<p>The command that runs the non-collinear version of VASP.<br>Default:<br>VASP_TESTSUITE_EXE_NCL&#x3D;”mpirun -np 12 &#x2F;home&#x2F;duguex&#x2F;vasp.6.4.2&#x2F;bin&#x2F;vasp_ncl”<br><strong>N.B.</strong>: Specify the absolute path to your <em>non-collinear</em> executable<br>  (e.g. <code>vasp_ncl</code> or <code>vasp_gpu_ncl</code>).</p>
</li>
</ul>
<h1 id="AMD-tricks"><a href="#AMD-tricks" class="headerlink" title="AMD tricks"></a>AMD tricks</h1><p>from <a target="_blank" rel="noopener" href="http://bbs.keinsci.com/thread-25445-1-1.html">http://bbs.keinsci.com/thread-25445-1-1.html</a></p>
<h2 id="in-makefile-include-1"><a href="#in-makefile-include-1" class="headerlink" title="in makefile.include"></a>in makefile.include</h2><p>OFLAG &#x3D; -O2 -march&#x3D;core-avx2 #使用amd的avx2指令集<br>…<br>OBJECTS &#x3D; fftmpiw.o fftmpi_map.o fft3dlib.o fftw3d.o $(MKLROOT)&#x2F;interfaces&#x2F;fftw3xf&#x2F;libfftw3xf_intel.a<br>…</p>
<h2 id="in-bashrc-1"><a href="#in-bashrc-1" class="headerlink" title="in .bashrc"></a>in .bashrc</h2><p>export MKL_DEBUG_CPU_TYPE&#x3D;5<br>export MKL_CBWR&#x3D;AVX2<br>export I_MPI_PIN_DOMAIN&#x3D;numa</p>
<h1 id="VASP-segmentation-fault"><a href="#VASP-segmentation-fault" class="headerlink" title="VASP segmentation fault"></a>VASP segmentation fault</h1><p>如果有开发经验，可以回过去把makefile.include以及src&#x2F;makefile里面所有的编译器优化选项改成-O0 -g，然后重新编译，用gdb调试，不难定位到出问题的数组，然后控制变量法排除各种其他因素，最终找到可能的原因。这里就直接写结论了：这是一个编译器bug，github上的相关页面在这里：1、Flang runtime uses uninitialized value, causing memory leak and segfault 和 2、F08: Polymorphic assignment segfaults with empty abstract base type</p>
<p>也就是说，flang编译器中的flang存在bug，AMD自家修改定制的AOCC自然也继承了这个bug，用它构建VASP 6.1，能成功编译，但不能成功运行，只能等之后flang的更新，看有没有修复这个bug了。AMD no！</p>
<p>ldd <full_path>&#x2F;vasp_std</p>
<p>Flang is a Fortran language front-end for LLVM, which is an open-source compiler infrastructure project. Flang is designed to support modern Fortran standards and provide a high-performance Fortran compiler. It is developed by the Flang community, which includes members from various organizations such as AMD, NVIDIA, and Cray. Flang is released under the LLVM license, which is a permissive open-source license.</p>
<h1 id="solving-“Error-EDDDAV-Call-to-ZHEGV-failed-Returncode-xx”"><a href="#solving-“Error-EDDDAV-Call-to-ZHEGV-failed-Returncode-xx”" class="headerlink" title="solving “Error EDDDAV: Call to ZHEGV failed. Returncode &#x3D; xx”"></a>solving “Error EDDDAV: Call to ZHEGV failed. Returncode &#x3D; xx”</h1><p>I’ve tried several solutions proposed earlier in the forum:</p>
<p>commenting out the line #define USE_ZHEEVX in rmm-diis.F, davidson.F, subrot.F, and wavpre_noio.F and recompiling</p>
<p>using IALGO &#x3D; 48 (this just changes the error)</p>
<p>using a different lapack</p>
<p>adding “LSCALAPACK &#x3D; .FALSE.” in INCAR</p>
<p>all of them unsuccessful.<br>Then I found something surprising: with exactly the same input files, I find the problem when using 32 cores (i.e. 4 nodes having each two quad-core Opterons) but not if using 24 cores (i.e. three nodes of the said type). The problem (in my case) seems thus to be related with the way in which the work is distributed among nodes. Then I found that the problem is also avoided if I suppress the line<br>LPLANE &#x3D; .FALSE.<br>which I had in my INCAR.<br>Hopefully this information can help others. Maybe there is also something to change in the code for future versions.</p>
<h1 id="VASP-on-7402P"><a href="#VASP-on-7402P" class="headerlink" title="VASP on 7402P"></a>VASP on 7402P</h1><p>arch&#x2F;makefile.include.linux_gnu_omp</p>
<p>I could compile the CPU version with gfortran 9.3 and the system libraries. You may need to install some packages:<br>sudo apt install libscalapack-openmpi-dev libfftw3-dev libopenblas-dev</p>
<h1 id="Precompiler-options"><a href="#Precompiler-options" class="headerlink" title="Precompiler options"></a>Precompiler options</h1><p>CPP_OPTIONS&#x3D; -DHOST&#x3D;&quot;LinuxGNU&quot; <br>             -DMPI -DMPI_BLOCK&#x3D;8000 -Duse_collective <br>             -DscaLAPACK <br>             -DCACHE_SIZE&#x3D;4000 <br>             -Davoidalloc <br>             -Dvasp6 <br>             -Duse_bse_te <br>             -Dtbdyn <br>             -Dfock_dblbuf <br>             -D_OPENMP</p>
<p>CPP        &#x3D; gcc -E -P -C -w $<em>$(FUFFIX) &gt;$</em>$(SUFFIX) $(CPP_OPTIONS)</p>
<p>FC         &#x3D; mpif90 -fopenmp<br>FCL        &#x3D; mpif90 -fopenmp</p>
<p>FREE       &#x3D; -ffree-form -ffree-line-length-none</p>
<p>FFLAGS     &#x3D; -w -march&#x3D;native<br>OFLAG      &#x3D; -O2<br>OFLAG_IN   &#x3D; $(OFLAG)<br>DEBUG      &#x3D; -O0</p>
<p>BLAS       &#x3D; -lopenblas<br>LAPACK     &#x3D;<br>BLACS      &#x3D;<br>SCALAPACK  &#x3D; -lscalapack-openmpi $(BLACS)</p>
<p>LLIBS      &#x3D; $(SCALAPACK) $(LAPACK) $(BLAS)</p>
<p>FFTW       ?&#x3D;<br>LLIBS      +&#x3D; -lfftw3 -lfftw3_omp<br>INCS       &#x3D; -I&#x2F;usr&#x2F;include</p>
<p>OBJECTS    &#x3D; fftmpiw.o fftmpi_map.o  fftw3d.o  fft3dlib.o</p>
<p>OBJECTS_O1 +&#x3D; fftw3d.o fftmpi.o fftmpiw.o<br>OBJECTS_O2 +&#x3D; fft3dlib.o</p>
<h1 id="For-what-used-to-be-vasp-5-lib"><a href="#For-what-used-to-be-vasp-5-lib" class="headerlink" title="For what used to be vasp.5.lib"></a>For what used to be vasp.5.lib</h1><p>CPP_LIB    &#x3D; $(CPP)<br>FC_LIB     &#x3D; $(FC)<br>CC_LIB     &#x3D; gcc<br>CFLAGS_LIB &#x3D; -O<br>FFLAGS_LIB &#x3D; -O1<br>FREE_LIB   &#x3D; $(FREE)</p>
<p>OBJECTS_LIB&#x3D; linpack_double.o getshmem.o</p>
<h1 id="For-the-parser-library"><a href="#For-the-parser-library" class="headerlink" title="For the parser library"></a>For the parser library</h1><p>CXX_PARS   &#x3D; g++<br>LLIBS      +&#x3D; -lstdc++</p>
<h3 id="For-the-fft-library"><a href="#For-the-fft-library" class="headerlink" title="For the fft library"></a>For the fft library</h3><p>##CXX_FFTLIB &#x3D; g++ -fopenmp -std&#x3D;c++11 -DFFTLIB_THREADSAFE<br>##INCS_FFTLIB&#x3D; -I.&#x2F;include -I$(FFTW)&#x2F;include<br>##LIBS       +&#x3D; fftlib<br>##LLIBS      +&#x3D; -ldl</p>
<h1 id="Normally-no-need-to-change-this"><a href="#Normally-no-need-to-change-this" class="headerlink" title="Normally no need to change this"></a>Normally no need to change this</h1><p>SRCDIR     &#x3D; ..&#x2F;..&#x2F;src<br>BINDIR     &#x3D; ..&#x2F;..&#x2F;bin</p>
<h1 id="run-VASP-on-EPYC"><a href="#run-VASP-on-EPYC" class="headerlink" title="run VASP on EPYC"></a>run VASP on EPYC</h1><p>mpirun -np 4 –map-by ppr:2:socket:PE&#x3D;12 –bind-to core <br>              -x OMP_NUM_THREADS&#x3D;12 -x OMP_STACKSIZE&#x3D;512m <br>              -x OMP_PLACES&#x3D;cores -x OMP_PROC_BIND&#x3D;close <br>              –report-bindings vasp_std</p>
<p>export OMP_NUM_THREADS&#x3D;1</p>
<p>I’m trying to compile VASP 6.3.2 using Intel oneAPI compiler and library suite on AMD Epyc 7713 64-core processors, as others have already mentioned that Intel compilers produce better performance than AMD’s own compiler (AOCC&#x2F;AOCL; I already used it and the executable works without issues). However, I’m having some issues using the included makefiles, and even after modifying some flags, the executable fails on some tests, and even crashes with Segmentation fault without further details. I understand that using Intel compilers on AMD processors is not entirely supported, but perhaps you could help me to identify the issue.</p>
<p>Following suggestions in the Intel community forum and others, I tried setting the variable VASP_TARGET_CPU to either “-xHOST -msoft-float -msse -msse2 -msse3 -msse4” or “-march&#x3D;core-avx2”. Compilation succeeded with both flag sets, but the executable failed to pass the testsuite, and even crashed with Segmentation fault in several cases. I’ve attached the testsuite.log and compilation output.</p>
<h1 id="VASP-on-ARM"><a href="#VASP-on-ARM" class="headerlink" title="VASP on ARM"></a>VASP on ARM</h1><p>I have installed VASP on my Macbook Pro 2021 (M1 Pro chip) and ran it without any issues. All external libraries were installed with macports, but I am sure that it will also work if these are compiled by hand.</p>
<p>The following libraries were linked during the installation:</p>
<ol>
<li>HDF5</li>
<li>FFTW3</li>
<li>OPENBlas</li>
<li>SCALAPACK</li>
<li>Wannier90</li>
</ol>
<p>For compilers I used gcc10 and mpich, and libraries had openmp support. I include the makefile.include that I used.</p>
<p>Cheers,<br>Pedro Melo</p>
<p><a target="_blank" rel="noopener" href="https://gist.github.com/janosh/a484f3842b600b60cd575440e99455c0">https://gist.github.com/janosh/a484f3842b600b60cd575440e99455c0</a></p>
<p><a target="_blank" rel="noopener" href="https://gist.github.com/duguex/60f382f8ac027f6c3007854ef895575d">https://gist.github.com/duguex/60f382f8ac027f6c3007854ef895575d</a></p>
<h1 id="Optimizing-on-the-AMD-EPYC"><a href="#Optimizing-on-the-AMD-EPYC" class="headerlink" title="Optimizing on the AMD EPYC"></a>Optimizing on the AMD EPYC</h1><p>内存插满</p>
<p>EPYC是大胶水CPU，每个CCX只有4C8T，靠I&#x2F;O die互联，所以高度NUMA，可以去BIOS里把这个原始的NUMA拓扑暴露出来，如果代码是NUMA-aware的性能应该会好不少</p>
<p>第一，超微GEN11的板子对zen2 zen3支持多少有点问题，检查最新的bios更新<br>第二，最关键的一点，AMD的跨插槽性能下降比intel的厉害。如果有单路64C的选择，绝不要双路32C。4核心每通道的比例带来的性能增幅很有可能比不上跨插槽带来的性能下降。第三，ZEN2不是ZEN3，依然是每CCD 2个CCX，每个CCX4个zen 2 core，每个CCX共享8MB L3,到第五个核的时候涉及到跨CCX访问，延迟会明显加大 因此分配核心的基本单位是4核<br>第三，每个CPU你只分配了4条内存，7452只有128MB L3，而且还分了60核，跨CCX，跨插槽访问两个巨大的性能debuff你都遇上了，难看是必然的</p>
<p>1，bios更新到最新，即把AGESA RomePI更到1.0.0.5，bios设置使用默认不要改动。<br>2，内存换16g*16（成本最低），或预算充足且512g内存也不会浪费的话再加8条同样的内存，即保证每路都开启8通道，你现在双路只插了8条，带宽只有标准的一半，这个损失还是很严重的。<br>3，fluent试用最新版（2021r1），去rhel&#x2F;centos下跑，-mpi&#x3D;intel试试，另外带上-platform&#x3D;intel参数开启avx2加速。</p>
<ol start="3">
<li><p>内存要用2R或者更多rank的，指令率1t的。指令率有多重要不用多说了。单一rank和多个rank的内存三级时序，也就是所谓的小时序不一样，虽然大时序也许都是23-23-23-28 1t，小时序的差别可以让内存带宽相差百分之十几。</p>
</li>
<li><p>BIOS设置里面把NUMA设置到NPS4。多核计算机NUMA的设置很重要。原则上按照机器结构有几层NUMA就设置到几，让CPU尽量就近访问内存。NPS1和NPS4的内存带宽可以差一倍。</p>
</li>
<li><p>关闭EPYC的内存加密功能。计算效率可以再提升3%～5%的样子。</p>
</li>
<li><p>考虑把内存降频到2933。EPYC 二代的IFOP不足，满血支持最大频率是2933，内存设置到3200会失去同步，延迟上升大概 35%的样子。自我测试给出来的结果是2933是计算快一点。软件设置繁杂，只拣着重要的说了。</p>
</li>
<li><p>关于其他软件设置细节，可以参考AMD官方文档HPC Tuning Guide，除了内存频率官推3200之外，别的都照着调试过确认是会快一点的。</p>
</li>
</ol>
<p><img src="/image.png" alt="由于用在PowerEdge R6525服务器上的AMD EPYC 7742是顶配的64核，所以在每CPU配置8或8的倍数条内存时，双路带宽最高达到330 GB/s以上"></p>
<p><img src="/image-1.png" alt="AMD EPYC2凭借将8个小的CCD（Core Die）和I/O Die分开的设计，再加上CCD使用7nm先进工艺，在核心数量上做到了64，超出Intel Xeon"><br>同时代价也是有的，那就是和第一代EPYC服务器CPU类似的片上NUMA（非一致性内存访问），尽管内存控制器都在中间那颗大的I&#x2F;O Die上<br><img src="/image-2.png" alt="如上图，ROME（EPYC2）的8个内存通道分别属于4个内存控制器，每2个CCD Die能够就近优化访问其中的一组，而跨越“四象限”的内存访问就不是最佳性能（延时/带宽）了"></p>
<p><img src="/image-3.png" alt="上图出自一位发烧友兄弟之手，我不保证其中每一处细节都完全准确，不过这个用来辅助说明EPYC2的片上NUMA设计还是比较形象的"></p>
<ul>
<li><p>NPS 0——双CPU系统设置为1个NUMA节点（相当于Intel Xeon系统关闭NUMA），所有内存通道使用interleave交错访问模式；</p>
</li>
<li><p>NPS 1——每个CPU插槽1个NUMA节点（相当于Intel Xeon系统打开NUMA），连接到同一插槽的所有内存通道使用交错访问；</p>
</li>
<li><p>NPS 2——每个CPU插槽2个NUMA节点，划分为2个4内存通道的interleave集；</p>
</li>
<li><p>NPS 4——每插槽4个NUMA节点，在“四象限”各自的2通道内存间交错访问，相当于CPU to内存的亲和优化到每个内存控制器；</p>
</li>
</ul>
<p><img src="/image-4.png" alt="引用Dell白皮书《Balanced Memory with 2nd Generation AMD EPYC Processors for PowerEdge Servers》中的一个表格"></p>
<p>最右边一列应该都算非Balanced内存配置，不能做到4个内存控制器的DIMM配置完全对等。我看到过有的朋友建议，在AMDEPYC2服务器上应尽量少用达不到Balanced的插法——也就是说最好按照每颗CPU 4、8、12、16条内存来配。</p>
<p>而在内存达到4和8的倍数时，为什么反而要建议NPS设为1或者0呢？我觉得这里是为了保守起见。毕竟许多传统应用没有NUMA优化、或者习惯于针对Intel Xeon每插槽一个NUMA节点来优化，这时AMD的片上NUMA如果打开有可能带来负面结果。</p>
<p><img src="/image-5.png" alt="不是每一款AMD EPYC2 CPU都支持NPS 4"></p>
<p>总的原则是，如果EPYC2的8个CCD都激活，那么一般就会支持到NPS 4；而如果只有8-16个核心并且都位于四象限的1-2组内存控制器附近，那么就可能不支持NPS 2和4。</p>
<p>特别一点的是，像7552这样48核没有在四象限完全对称分布，所以也只支持到NPS2；而7262的8个核心反而均等处于四个象限，所以支持NPS4</p>
<p><img src="/image-6.png" alt="来自Dell文档《NUMA Configuration settings on AMD EPYC 2nd Generation》的图表，是我认为本文中最有价值的"></p>
<p>其中总结了4大类型的应用工作负载：</p>
<p>通用工作负载建议NPS&#x3D;1。其中SPEC CPU测试和I&#x2F;O密集型应用是这方面的代表；SPEC的另外2套BenchMarkjbb2015和power ssj2008则适合NPS设为4&#x2F;2。</p>
<p>虚拟化类应用可以设为NPS 1&#x2F;4。除了我以前介绍过的VDI，容器类应用也属于资源隔离比较好的，所以NPS建议也是4；但像VMmark 3这样测试虚机资源开销不等的复杂环境，NPS还是建议为1。</p>
<p>数据库和分析类应用NPS1&#x2F;4。这里HammerDB对应的是OLTP交易型数据库，NPS建议设为1，其实按照Oracle用户的习惯，Intel CPU插槽间的NUMA通常也要关掉，否则一旦内存利用不均衡触发swap对性能影响较严重。Hadoop应该属于适合水平扩展的分析型应用，建议NPS设置4。</p>
<p>高性能计算和电信类应用建议NPS 2&#x2F;4。HPC和EDA（电子设计自动化）可以把NPS设为4，基于OpenStack的NFV（网络功能虚拟化）又分细出一项实时Kernel的，都建议设置NPS 2</p>
<p>引用AMD文档《RDBMS Tuning Guide for AMD EPYC 7002 Series Processors》侧面验证下上述观点：<br>对于通用（常规的）Oracle数据库，建议BIOS中每插槽的NUMA节点设为1，也就是NPS 1<br>对于微软SQL Server 2019，如果是OLTP也是建议NPS 1；DW数据挖掘（分析型）应用则可以根据情况来选择是否设置为2或者4</p>
<p><img src="/image-7.png" alt="上图引用自Dell文档《The Value of Using Four-Channel Optimized AMD EPYC CPUs in PowerEdge Servers》"><br>左边CPU核心所在的CCD临近2组内存控制器，所以为4通道优化型；而右边CPU核心的CCD则分布于4组内存控制器附近，就是8通道优化型。那么在同样插4条内存的情况下，哪个性能更好？</p>
<p><img src="/image-8.png" alt="Alt text"><br>上图用同为16核的EPYC 7282和7302进行对比（都配置4通道内存），CPU核心分布在更多CCD Die上的7302在主频、功耗和内存带宽指标上全面领先，但一些应用中性能反而落后。像Web Server、基于Web的Java应用以及内容创建（视频编辑、图像处理），此处就推荐使用AMD7282、7252一类4通道优化型的CPU。</p>
<p>这应该就是核心相对集中的好处，7282每8个Core之间的内存数据能够享受就近访问的待遇；而7302的内存访问路径在I&#x2F;O Die上就相对复杂了。</p>
<h1 id="zen2-zen3-微架构"><a href="#zen2-zen3-微架构" class="headerlink" title="zen2 zen3 微架构"></a>zen2 zen3 微架构</h1><p><img src="/image-9.png" alt="zen2 3900x"><br><img src="/image-11.png" alt="L3合并"><br><img src="/image-10.png" alt="zen3 5900x"></p>
<h1 id="use-NCORE-8-for-ARM-CPU-96-core-TAISHAN-node"><a href="#use-NCORE-8-for-ARM-CPU-96-core-TAISHAN-node" class="headerlink" title="use NCORE&#x3D;8 for ARM-CPU 96-core TAISHAN node"></a>use NCORE&#x3D;8 for ARM-CPU 96-core TAISHAN node</h1><h1 id="cpu-优化"><a href="#cpu-优化" class="headerlink" title="cpu 优化"></a>cpu 优化</h1><p>这些都是编译器选项，用于指定生成的代码应该针对哪种类型的 CPU 进行优化。</p>
<ul>
<li><p><code>-march=native</code> 是 GCC 和 Clang 的一个选项，它指示编译器生成针对运行编译命令的机器的 CPU 的优化代码。这意味着编译出的程序将针对当前机器的 CPU 进行优化，可能无法在其他类型的 CPU 上运行。</p>
</li>
<li><p><code>-xHOST</code> 是 Intel 编译器的一个选项，它的作用和 <code>-march=native</code> 类似，也是指示编译器生成针对运行编译命令的机器的 CPU 的优化代码。</p>
</li>
<li><p><code>-tp host</code> 是 PGI 编译器的一个选项，它的作用和上面两个选项类似，也是指示编译器生成针对运行编译命令的机器的 CPU 的优化代码。</p>
</li>
</ul>
<p>这三个选项的主要区别在于它们适用于不同的编译器。你应该根据你使用的编译器来选择合适的选项。</p>
<h1 id="在软件开发中，”devel”（开发）和-“runtime”（运行时）通常指的是两种不同类型的软件包。"><a href="#在软件开发中，”devel”（开发）和-“runtime”（运行时）通常指的是两种不同类型的软件包。" class="headerlink" title="在软件开发中，”devel”（开发）和 “runtime”（运行时）通常指的是两种不同类型的软件包。"></a>在软件开发中，”devel”（开发）和 “runtime”（运行时）通常指的是两种不同类型的软件包。</h1><p>“devel” 软件包通常包含用于开发软件的文件，例如头文件（.h 文件）、源代码文件、链接库等。这些文件通常用于编译和链接程序。例如，如果你想要开发一个使用某个库的程序，你可能需要安装这个库的 “devel” 软件包。</p>
<p>“runtime” 软件包通常包含用于运行软件的文件，例如二进制可执行文件、动态链接库、配置文件、数据文件等。这些文件通常在程序运行时被加载和使用。例如，如果你想要运行一个使用某个库的程序，你可能需要安装这个库的 “runtime” 软件包。</p>
<p>在你的上下文中，<code>mpiexec -n 8 pytest --pyargs gpaw -v</code> 这个命令是在运行时环境中执行的，它使用 <code>mpiexec</code> 来并行运行 <code>pytest</code> 测试，测试的目标是 <code>gpaw</code> 包。</p>
<p><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/install/pip?hl=zh-cn#virtual-environment-install">https://tensorflow.google.cn/install/pip?hl=zh-cn#virtual-environment-install</a></p>
<p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/hpc-sdk-downloads">https://developer.nvidia.com/hpc-sdk-downloads</a><br><a target="_blank" rel="noopener" href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a><br><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=deb_local">https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=22.04&amp;target_type=deb_local</a></p>
<p>get key<br>wget <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb">https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb</a></p>
<p>wget <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin">https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin</a><br>sudo mv cuda-ubuntu2204.pin<br>cuda-repository-pin-600<br>wget <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/compute/cuda/12.2.2/local_installers/cuda-repo-ubuntu2204-12-2-local_12.2.2-535.104.05-1_amd64.deb">https://developer.download.nvidia.com/compute/cuda/12.2.2/local_installers/cuda-repo-ubuntu2204-12-2-local_12.2.2-535.104.05-1_amd64.deb</a><br>sudo dpkg -i cuda-repo-ubuntu2204-12-2-local_12.2.2-535.104.05-1_amd64.deb<br>sudo cp &#x2F;var&#x2F;cuda-repo-ubuntu2204-12-2-local&#x2F;cuda-*-keyring.gpg &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;<br>sudo apt-get update<br>sudo apt-get -y install cuda</p>
<p>wget <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/hpc-sdk/23.7/nvhpc_2023_237_Linux_x86_64_cuda_12.2.tar.gz">https://developer.download.nvidia.com/hpc-sdk/23.7/nvhpc_2023_237_Linux_x86_64_cuda_12.2.tar.gz</a><br>tar xpzf nvhpc_2023_237_Linux_x86_64_cuda_12.2.tar.gz<br>nvhpc_2023_237_Linux_x86_64_cuda_12.2&#x2F;install</p>
<p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html">https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html</a></p>
<p>your CUDA directory path is referred to as &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;<br>your cuDNN download path is referred to as <cudnnpath></p>
<p>Making symbolic link in &#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64</p>
<p>generating environment modules for NV HPC SDK 23.7 … done.<br>Installation complete.<br>HPC SDK successfully installed into &#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk</p>
<p>If you use the Environment Modules package, that is, the module load<br>command, the NVIDIA HPC SDK includes a script to set up the<br>appropriate module files.</p>
<p>% module load &#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;modulefiles&#x2F;nvhpc&#x2F;23.7<br>% module load nvhpc&#x2F;23.7</p>
<p>Alternatively, the shell environment may be initialized to use the HPC SDK.</p>
<p>In csh, use these commands:</p>
<p>% setenv MANPATH “$MANPATH”:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;compilers&#x2F;man<br>% set path &#x3D; (&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;compilers&#x2F;bin $path)</p>
<p>In bash, sh, or ksh, use these commands:</p>
<p>MANPATH&#x3D;$MANPATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;compilers&#x2F;man; export MANPATH<br>PATH&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;compilers&#x2F;bin:$PATH; export PATH</p>
<p>Once the 64-bit compilers are available, you can make the OpenMPI<br>commands and man pages accessible using these commands.</p>
<p>% set path &#x3D; (&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;comm_libs&#x2F;mpi&#x2F;bin $path)<br>% setenv MANPATH “$MANPATH”:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;comm_libs&#x2F;mpi&#x2F;man<br>In bash, sh, or ksh, use these commands:</p>
<p>MANPATH&#x3D;$MANPATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;compilers&#x2F;man; export MANPATH<br>PATH&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;compilers&#x2F;bin:$PATH; export PATH</p>
<p>Once the 64-bit compilers are available, you can make the OpenMPI<br>commands and man pages accessible using these commands.</p>
<p>% set path &#x3D; (&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;comm_libs&#x2F;mpi&#x2F;bin $path)<br>% setenv MANPATH “$MANPATH”:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;comm_libs&#x2F;mpi&#x2F;man</p>
<p>And the equivalent in bash, sh, and ksh:</p>
<p>export PATH&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;comm_libs&#x2F;mpi&#x2F;bin:$PATH<br>export MANPATH&#x3D;$MANPATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.7&#x2F;comm_libs&#x2F;mpi&#x2F;man</p>
<p>Please check <a target="_blank" rel="noopener" href="https://developer.nvidia.com/">https://developer.nvidia.com</a> for documentation,<br>use of NVIDIA HPC SDK software, and other questions.</p>
<p>Before issuing the following commands, you must replace X.Y and v8.x.x.x with your specific CUDA and cuDNN versions and package date.</p>
<p>Navigate to your <cudnnpath> directory containing the cuDNN tar file.<br>Unzip the cuDNN package.<br>tar -xvf cudnn-linux-$arch-8.x.x.x_cudaX.Y-archive.tar.xz</p>
<p>Where ${arch} is x86_64, sbsa, or ppc64le.</p>
<p>Copy the following files into the CUDA toolkit directory.</p>
<p>sudo cp cudnn-<em>-archive&#x2F;include&#x2F;cudnn</em>.h &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;include<br>sudo cp -P cudnn-<em>-archive&#x2F;lib&#x2F;libcudnn</em> &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64<br>sudo chmod a+r &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;include&#x2F;cudnn*.h &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64&#x2F;libcudnn*</p>
<h1 id="nvidia-hpc-sdk-FFTW"><a href="#nvidia-hpc-sdk-FFTW" class="headerlink" title="nvidia hpc sdk FFTW"></a>nvidia hpc sdk FFTW</h1><p>NVIDIA HPC SDK（NVHPC）并不直接包含 FFTW 库，但它包含了一个名为 cuFFT 的库，这是一个在 NVIDIA GPU 上运行的 FFTW 兼容库。</p>
<p>如果你需要在 NVHPC 中使用 FFTW，你有两个选择：</p>
<ol>
<li><p>使用 cuFFT。你可以在你的代码中使用 cuFFT 的 API，这些 API 和 FFTW 的 API 非常相似。你可以在 NVHPC 的安装目录下的 <code>CUDAToolkit/include</code> 目录中找到 cuFFT 的头文件，例如 <code>/opt/nvidia/hpc_sdk/Linux_x86_64/21.3/cuda/11.2/include/cufft.h</code>。</p>
</li>
<li><p>自行安装 FFTW。你可以从 FFTW 的官方网站下载 FFTW 的源代码，然后使用 NVHPC 来编译它。你需要在编译 FFTW 时指定 NVHPC 作为编译器，例如 <code>./configure CC=nvc CFLAGS=&#39;-fast -tp=haswell&#39;</code>。</p>
</li>
</ol>
<p>请注意，这些路径可能会根据你的 NVHPC 的安装位置和版本有所不同。你应该根据你的实际情况来修改这些路径。</p>
<h2 id="cc60-cc70-cc80"><a href="#cc60-cc70-cc80" class="headerlink" title="cc60,cc70,cc80"></a>cc60,cc70,cc80</h2><p>-gpu&#x3D;cc60,cc70,cc80 是一个编译选项，用于指定 NVIDIA 编译器（如 NVCC 或 NVHPC）生成的 GPU 代码应该针对哪些计算能力（Compute Capability）的 GPU 进行优化。</p>
<p>在这个选项中，cc60、cc70 和 cc80 分别代表计算能力 6.0、7.0 和 8.0 的 GPU。这些计算能力对应于不同的 GPU 架构：</p>
<p>cc60 对应于 Pascal 架构，例如 GTX 1080。 P100<br>cc70 对应于 Volta 架构，例如 Tesla V100。<br>cc80 对应于 Ampere 架构，例如 RTX 3080。<br>这个选项意味着编译出的程序将包含针对这三种计算能力的 GPU 的优化代码，可以在这些 GPU 上运行。如果你的 GPU 的计算能力不在这个列表中，编译出的程序可能无法在你的 GPU 上运行。</p>
<h1 id="compile-oneapi-VASP"><a href="#compile-oneapi-VASP" class="headerlink" title="compile oneapi VASP"></a>compile oneapi VASP</h1><p><a target="_blank" rel="noopener" href="https://implant.fs.cvut.cz/vasp-intel-compilation/">https://implant.fs.cvut.cz/vasp-intel-compilation/</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br></pre></td><td class="code"><pre><span class="line">Compile VASP (6.4.1) within WSL2 Ubuntu using Intel compilers (oneAPI), supporting MKL accelerator and HDF5</span><br><span class="line">Full description <span class="keyword">for</span> the video: https://youtu.be/_XqB2aADg4Q</span><br><span class="line"></span><br><span class="line">Compiled version: VASP 6.4.1</span><br><span class="line">(10/11/2023)</span><br><span class="line">Contact: lebedmi2@cvut.cz</span><br><span class="line"></span><br><span class="line">Official documentation <span class="keyword">for</span> compiling VASP: https://www.vasp.at/wiki/index.php/Installing_VASP.6.X.X</span><br><span class="line">Official documentation <span class="keyword">for</span> makefiles: https://www.vasp.at/wiki/index.php/Makefile.include</span><br><span class="line"></span><br><span class="line">Tested PC:</span><br><span class="line">Intel(R) Core(TM) i5-14600K 3.50 GHz</span><br><span class="line">RTX 2060 SUPER</span><br><span class="line">Kingston FURY 32GB KIT DDR5 6000MHz CL32 Renegade</span><br><span class="line">WSL2 Ubuntu version: 22.04</span><br><span class="line">Steps:</span><br><span class="line">1) Compile Intel oneAPI Base Toolkit.</span><br><span class="line">2) Compile Intel® HPC Toolkit.</span><br><span class="line">3) Compile OpenMPI using Intel oneAPI compilers.</span><br><span class="line">4) Compile HDF5 using Intel oneAPI compilers to support h5 output format from VASP (useful <span class="keyword">for</span> example when post-processing data with py4vasp)</span><br><span class="line">5) Compile VASP using Intel oneAPI compilers.</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">Prerequisites:</span><br><span class="line">Not all are necessary but might be useful: </span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt upgrade</span><br><span class="line">sudo apt-get install build-essential cmake cmake-curses-gui libopenmpi-dev openmpi-bin libfftw3-dev</span><br><span class="line"> </span><br><span class="line">Intel oneAPI Base Toolkit</span><br><span class="line">Download the newest version from https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html?operatingsystem=linux&amp;distributions=onlinehttps://developer.nvidia.com/hpc-sdk-downloads:</span><br><span class="line"></span><br><span class="line">wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/1b2baedd-a757-4a79-8abb-a5bf15adae9a/l_HPCKit_p_2024.0.0.49589.sh</span><br><span class="line">sudo sh ./l_HPCKit_p_2024.0.0.49589.sh</span><br><span class="line">Continue with the installation according to the instructions (accept terms, recommended installation, ignore warnings about GUI and <span class="built_in">continue</span>, skip Enclipse configuration).</span><br><span class="line"></span><br><span class="line">Activate the oneAPI with: </span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /opt/intel/oneapi/setvars.sh</span><br><span class="line">Add MKL to the ~/.bashrc:</span><br><span class="line"></span><br><span class="line">nano ~/.bashrc</span><br><span class="line"><span class="built_in">export</span> PATH=/opt/intel/oneapi/mkl/2024.0:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/opt/intel/oneapi/mkl/2024.0/lib/intel64:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/opt/intel/oneapi/compiler/2024.0/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"> </span><br><span class="line">Intel® HPC Toolkit</span><br><span class="line">Download the newest version from https://www.intel.com/content/www/us/en/developer/tools/oneapi/hpc-toolkit-download.html?operatingsystem=linux&amp;distributions=online:</span><br><span class="line"></span><br><span class="line">wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/1b2baedd-a757-4a79-8abb-a5bf15adae9a/l_HPCKit_p_2024.0.0.49589.sh</span><br><span class="line">sudo sh ./l_HPCKit_p_2024.0.0.49589.sh</span><br><span class="line">Activate the oneAPI with: </span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /opt/intel/oneapi/setvars.sh</span><br><span class="line"> </span><br><span class="line">OpenMPI compiled with oneAPI</span><br><span class="line">Download OpenMPI (use wget <span class="built_in">command</span> or download from here https://www.open-mpi.org/software/ompi/v5.0/) and compile:</span><br><span class="line"></span><br><span class="line">wget https://download.open-mpi.org/release/open-mpi/v5.0/openmpi-5.0.0.tar.gz</span><br><span class="line"><span class="built_in">mkdir</span> OpenMPI_Intel</span><br><span class="line">tar xvzf openmpi-5.0.0.tar.gz -C OpenMPI_Intel</span><br><span class="line"><span class="built_in">cd</span> OpenMPI_Intel/openmpi-5.0.0</span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line">./configure CC=icx CXX=icpx FC=ifort F77=ifort OMPI_CC=icx OMPI_CXX=icpx OMPI_FC=ifort OMPI_F77=ifort --prefix=/home/lebedmi2/SOFTWARE/OpenMPI/openmpi_intel/openmpi-5.0.0/build</span><br><span class="line">make install -j</span><br><span class="line">Activate it (either write the following into the last line of bashrc <span class="keyword">for</span> permanent activation or write it directly into the console <span class="keyword">for</span> temporal activation):</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=/home/lebedmi2/SOFTWARE/OpenMPI/OpenMPI_Intel/openmpi-5.0.0/build/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/home/lebedmi2/SOFTWARE/OpenMPI/OpenMPI_Intel/openmpi-5.0.0/build/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"> </span><br><span class="line">HDF5 compiled with oneAPI</span><br><span class="line">Create a new folder <span class="built_in">where</span> HDF5 will be compiled:</span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> HDF5_Intel</span><br><span class="line"><span class="built_in">cd</span> HDF5_Intel</span><br><span class="line">Download into this folder Cmake version of HDF5 from https://www.hdfgroup.org/downloads/hdf5/source-code/<span class="comment">#:</span></span><br><span class="line"></span><br><span class="line">tar xvzf CMake-hdf5-1.14.3.tar.gz</span><br><span class="line"><span class="built_in">cd</span> CMake-hdf5-1.14.3/</span><br><span class="line">Compile LIBAEC and ZLib downloaded with HDF5:</span><br><span class="line"></span><br><span class="line">tar xvzf LIBAEC.tar.gz</span><br><span class="line">tar xvzf ZLib.tar.gz</span><br><span class="line"><span class="built_in">cd</span> libaec-v1.0.6</span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">sudo make install</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">cd</span> zlib-1.3</span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">sudo make install</span><br><span class="line">Add libsz.so to path:</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line">Copy hdf5-1.14.3 <span class="built_in">source</span> to the HDF5_Intel <span class="built_in">dir</span>:</span><br><span class="line"></span><br><span class="line"><span class="built_in">cp</span> -r hdf5-1.14.3/ ..</span><br><span class="line">In HDF5_Intel <span class="built_in">dir</span>, make a new directory called “myhdfstuff”. Without this called folder, compilation is problematic:</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">mkdir</span> myhdfstuff</span><br><span class="line">Copy the <span class="built_in">source</span> files <span class="keyword">in</span> hdf5-1.14.3 to myhdfstuff:</span><br><span class="line"></span><br><span class="line"><span class="built_in">cp</span> -r hdf5-1.14.3/ myhdfstuff/</span><br><span class="line">Build HDF5:</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> myhdfstuff</span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake -G <span class="string">&quot;Unix Makefiles&quot;</span> -DBUILD_SHARED_LIBS:BOOL=ON -DHDF5_BUILD_FORTRAN=YES -DHDF5_BUILD_TOOLS:BOOL=ON -DCMAKE_C_COMPILER=icx ../hdf5-1.14.3 </span><br><span class="line">cmake --build . --config Release -j</span><br><span class="line">cpack -C Release CPackConfig.cmake</span><br><span class="line">./HDF5-1.14.3-Linux.sh </span><br><span class="line">Scroll down with enter, accept license with “y”, and write “n” to have it installed <span class="keyword">in</span> the build directory.</span><br><span class="line">Before running the simulations with this version, make sure to either permanently or temporally <span class="built_in">export</span> HDF5 directory to system variables:</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=/home/lebedmi2/SOFTWARE/HDF5_Intel/myhdfstuff/build/HDF_Group/HDF5/1.14.3/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/home/lebedmi2/SOFTWARE/HDF5_Intel/myhdfstuff/build/HDF_Group/HDF5/1.14.3/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"> </span><br><span class="line">VASP compiled with oneAPI and MKL support</span><br><span class="line">tar xvzf vasp.6.4.1.tgz</span><br><span class="line"><span class="built_in">mv</span> vasp.6.4.1 vasp.6.4.1_Intel_MKL</span><br><span class="line"><span class="built_in">cd</span> vasp.6.4.1_Intel_MKL</span><br><span class="line"><span class="built_in">cd</span> vasp.6.4.1</span><br><span class="line">To run commands without sudo (otherwise you could face problems with paths, see below this section), give rights to the currect user <span class="keyword">for</span> the vasp.6.4.1 folder (change only the username ‚lebedmi2‘ <span class="keyword">in</span> the following <span class="built_in">command</span>. You can check name of the user with <span class="built_in">command</span> ‚<span class="built_in">whoami</span>‚):</span><br><span class="line"></span><br><span class="line">sudo <span class="built_in">chown</span> -R lebedmi2 .</span><br><span class="line">Create makefile.include file:</span><br><span class="line"></span><br><span class="line">nano makefile.include</span><br><span class="line">Into makefile.include, copy here from: makefile.include.intel_ompi_mkl_omp_acc (https://www.vasp.at/wiki/index.php/Makefile.include.intel_ompi_mkl_omp or find it <span class="keyword">in</span> <span class="built_in">arch</span> folder of your VASP)..</span><br><span class="line"></span><br><span class="line">In makefile.include, <span class="built_in">set</span> the paths to to MKL (MKLROOT) and HDF5 (HDF5_ROOT). You must also change icc to icx and icpc to icpx. icc and icpc are depreceated and no longer included <span class="keyword">in</span> newer versions of oneAPI.</span><br><span class="line"></span><br><span class="line">MKLROOT    ?= /opt/intel/oneapi/mkl/2024.0</span><br><span class="line">HDF5_ROOT  ?= /home/lebedmi2/SOFTWARE/HDF5_Intel/myhdfstuff/build/HDF_Group/HDF5/1.14.3</span><br><span class="line">CC_LIB = icx</span><br><span class="line">CXX_PARS = icpx</span><br><span class="line">Compile vasp:</span><br><span class="line"></span><br><span class="line">make DEPS=1 -j</span><br><span class="line">It will take some time. If no error appeared, check <span class="keyword">if</span> all libraries are correctly <span class="built_in">set</span> and none are missing:</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> bin</span><br><span class="line">ldd vasp_std</span><br><span class="line">Export number of threads to bashrc:</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> OMP_NUM_THREADS=2</span><br><span class="line">Try <span class="keyword">if</span> the compiled version is working (write the following <span class="built_in">command</span> <span class="keyword">in</span> the same directory <span class="built_in">where</span> the makefile.include is. It should give computed values and no errors):</span><br><span class="line"></span><br><span class="line">make <span class="built_in">test</span> -j </span><br><span class="line">If more than one vasp compilation will be installed on the computer, rename the binary:</span><br><span class="line"></span><br><span class="line"><span class="built_in">mv</span> vasp_std vasp_intel</span><br><span class="line">Add path vasp_intel_mkl to bashrc:</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=/home/lebedmi2/SOFTWARE/VASP/vasp.6.4.1_INTEL/vasp.6.4.1/bin:<span class="variable">$PATH</span></span><br><span class="line"> </span><br><span class="line">Run the simulations with VASP Intel, MKL:</span><br><span class="line">Before running the simulations, all the following should be exported (<span class="keyword">if</span> they are not <span class="built_in">set</span> permanently <span class="keyword">in</span> ~/.bashrc). In my <span class="keyword">case</span>:</span><br><span class="line"></span><br><span class="line"><span class="comment">#Intel compilers, libraries</span></span><br><span class="line"><span class="built_in">source</span> /opt/intel/oneapi/setvars.sh</span><br><span class="line"><span class="comment">#OpenMPI compiled with oneAPI</span></span><br><span class="line"><span class="built_in">export</span> PATH=/home/lebedmi2/SOFTWARE/OpenMPI/openmpi_intel/openmpi-5.0.0/build/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/home/lebedmi2/SOFTWARE/OpenMPI/openmpi_intel/openmpi-5.0.0/build/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="comment">#HDF5 compiled with oneApi</span></span><br><span class="line"><span class="built_in">export</span> PATH=/home/lebedmi2/SOFTWARE/HDF5_Intel/myhdfstuff/build/HDF_Group/HDF5/1.14.3/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/home/lebedmi2/SOFTWARE/HDF5_Intel/myhdfstuff/build/HDF_Group/HDF5/1.14.3/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line">Then run with, e.g.:</span><br><span class="line"></span><br><span class="line">mpirun -np 4 vasp_intel </span><br><span class="line">To run on all processors and threads:</span><br><span class="line"></span><br><span class="line">mpirun --use-hwthread -np N vasp_intel</span><br><span class="line">This may not always be effective, as it depends on the simulation settings and size of the simulated system. For example, with 72 Cr atoms, 10 DAV iterations, 3x3x3 k-sampling, and 350 eV Ecut:</span><br><span class="line"></span><br><span class="line">Command	Elapsed time (s)</span><br><span class="line">mpirun -np 1 vasp_intel</span><br><span class="line">mpirun -np 1 vasp_aocc_aocl, AOCC, AOCL on Intel processor</span><br><span class="line">mpirun -np 1 vasp_gcc_mkl, GNU with MKL</span><br><span class="line">mpirun -np 1 vasp_gpu_mkl ,GPU RTX 2060 SUPER	1289</span><br><span class="line">1519</span><br><span class="line">1394</span><br><span class="line">339</span><br><span class="line">mpirun -np 4 vasp_intel	 293</span><br><span class="line"> mpirun -np 7 vasp_intel	 341</span><br><span class="line">mpirun -np N vasp_intel (N = 10)	 326</span><br><span class="line">mpirun –use-hwthread -np N vasp_intel	 251</span><br><span class="line">The last <span class="built_in">command</span> is running as: 20 mpi-ranks, with 2 threads/rank, on 1 nodes</span><br><span class="line">distrk: each k-point on 20 cores, 1 <span class="built_in">groups</span></span><br><span class="line"></span><br><span class="line">Encountered problems</span><br><span class="line">When running the computation on smaller number of cores, I needed to solve the following error by writting into console:</span><br><span class="line"></span><br><span class="line"><span class="built_in">ulimit</span> -s unlimited</span><br><span class="line">It removes the maximum size restriction on the stack memory <span class="keyword">for</span> programs <span class="keyword">in</span> a Unix-like system, allowing them to use as much stack space as needed.</span><br><span class="line"></span><br><span class="line">forrtl: severe (174): SIGSEGV, segmentation fault occurred</span><br><span class="line">Image PC Routine Line Source</span><br><span class="line">libc.so.6 00007F0D603C9520 Unknown Unknown Unknown</span><br><span class="line">vasp_intel 000000000099B52F Unknown Unknown Unknown</span><br><span class="line">vasp_intel 0000000001209389 Unknown Unknown Unknown</span><br><span class="line">vasp_intel 00000000012A28BB Unknown Unknown Unknown</span><br><span class="line">vasp_intel 0000000001DE5F26 Unknown Unknown Unknown</span><br><span class="line">vasp_intel 0000000001DBD0EA Unknown Unknown Unknown</span><br><span class="line">vasp_intel 000000000041CCED Unknown Unknown Unknown</span><br><span class="line">libc.so.6 00007F0D603B0D90 Unknown Unknown Unknown</span><br><span class="line">libc.so.6 00007F0D603B0E40 __libc_start_main Unknown Unknown</span><br><span class="line">vasp_intel 000000000041CC05 Unknown Unknown Unknown</span><br><span class="line">Solving possible problem with PATHs</span><br><span class="line">In my ‚makefile‘ (it is <span class="keyword">in</span> the same location <span class="built_in">where</span> makefile.include is), I added the following at the first line to check <span class="built_in">which</span> environmental paths are accessible during compilation:</span><br><span class="line"></span><br><span class="line">show-path:</span><br><span class="line">      @<span class="built_in">echo</span> <span class="string">&quot;Current PATH: $<span class="variable">$PATH</span>&quot;</span></span><br><span class="line">When executing ‚make‚, it shows the correct paths (including the path to nvfortran).</span><br><span class="line">When executing ‚sudo make‚, it shows:</span><br><span class="line">Current PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin</span><br><span class="line">These are pre-set secure PATHs used by sudo, not the ones I have <span class="built_in">set</span> <span class="keyword">in</span> ~/.bashrc needed <span class="keyword">for</span> the compilation. The other way how to check the secure paths is to write ‚sudo <span class="built_in">env</span>‚ and see the row starting with ‚PATH‘.</span><br><span class="line"></span><br><span class="line">To have access to paths <span class="keyword">in</span> ~/.bashrc, I would need to run the compilation without sudo, but doing so results <span class="keyword">in</span> a ‚permission denied‘ error <span class="keyword">for</span> some files.</span><br><span class="line"></span><br><span class="line">You can address this by one of the following options (the first one is the most straightforward):</span><br><span class="line"></span><br><span class="line">1) Change the ownership of the folder with VASP and all its content to the user to be able to run ‚make‘ without sudo:</span><br><span class="line"></span><br><span class="line">sudo <span class="built_in">chown</span> -R lebedmi ~/SOFTWARE/VASP/v.6.4.1/vasp.6.4.1</span><br><span class="line">Change the ‚lebedmi‚ <span class="keyword">for</span> your username (you can check it with <span class="built_in">command</span> ‚<span class="built_in">whoami</span>‘) and modify ‚~/SOFTWARE/VASP/v.6.4.1/vasp.6.4.1‚ to the extracted directory with your VASP. Then you can run the compilation as ‚make DEPS=1 -j4‚).</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">2) First remove preset /mnt/ folders from the environment variables by writingthe following <span class="built_in">command</span> to the last line of bashrc (otherwise I was getting error: <span class="built_in">env</span>: ‘Files/NVIDIA’: No such file or directory):</span><br><span class="line"></span><br><span class="line">nano ~/.bashrc</span><br><span class="line"><span class="built_in">export</span> PATH=$(<span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$PATH</span>&quot;</span> | <span class="built_in">tr</span> <span class="string">&#x27;:&#x27;</span> <span class="string">&#x27;\n&#x27;</span> | grep -v <span class="string">&#x27;/mnt/c&#x27;</span> | <span class="built_in">tr</span> <span class="string">&#x27;\n&#x27;</span> <span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">Save and <span class="built_in">exit</span>, <span class="keyword">then</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line">Now you can compile by running the sudo <span class="built_in">command</span> with ‚<span class="built_in">env</span> PATH=<span class="variable">$PATH</span>‘, e.g.:</span><br><span class="line"></span><br><span class="line">sudo <span class="built_in">env</span> PATH=<span class="variable">$PATH</span> make DEPS=1 -j4</span><br><span class="line">3) Write ‚sudo visudo‘ and on the row starting with ‚Defaults secure_path=“…..‘ add the paths you need to have access when running <span class="built_in">command</span> with ‚sudo‘</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">Calculation speed comparison</span><br><span class="line">---&gt; HERE &lt;---</span><br><span class="line">Content of makefile.include <span class="keyword">for</span> VASP Intel MKL compilation:</span><br><span class="line"><span class="comment">#export MKLROOT=/opt/intel/oneapi/mkl/2024.0</span></span><br><span class="line"><span class="comment"># Default precompiler options</span></span><br><span class="line">CPP_OPTIONS = -DHOST=\&quot;LinuxIFC\&quot; \</span><br><span class="line">              -DMPI -DMPI_BLOCK=8000 -Duse_collective \</span><br><span class="line">              -DscaLAPACK \</span><br><span class="line">              -DCACHE_SIZE=4000 \</span><br><span class="line">              -Davoidalloc \</span><br><span class="line">              -Dvasp6 \</span><br><span class="line">              -Duse_bse_te \</span><br><span class="line">              -Dtbdyn \</span><br><span class="line">              -Dfock_dblbuf \</span><br><span class="line">              -D_OPENMP</span><br><span class="line"></span><br><span class="line">CPP         = fpp -f_com=no -free -w0  $*$(FUFFIX) $*$(SUFFIX) $(CPP_OPTIONS)</span><br><span class="line"></span><br><span class="line">FC          = mpif90 -qopenmp</span><br><span class="line">FCL         = mpif90</span><br><span class="line"></span><br><span class="line">FREE        = -free -names lowercase</span><br><span class="line"></span><br><span class="line">FFLAGS      = -assume byterecl -w</span><br><span class="line"></span><br><span class="line">OFLAG       = -O2</span><br><span class="line">OFLAG_IN    = $(OFLAG)</span><br><span class="line">DEBUG       = -O0</span><br><span class="line"></span><br><span class="line">OBJECTS     = fftmpiw.o fftmpi_map.o fftw3d.o fft3dlib.o</span><br><span class="line">OBJECTS_O1 += fftw3d.o fftmpi.o fftmpiw.o</span><br><span class="line">OBJECTS_O2 += fft3dlib.o</span><br><span class="line"></span><br><span class="line"><span class="comment"># For what used to be vasp.5.lib</span></span><br><span class="line">CPP_LIB     = $(CPP)</span><br><span class="line">FC_LIB      = $(FC)</span><br><span class="line">CC_LIB      = icx</span><br><span class="line">CFLAGS_LIB  = -O</span><br><span class="line">FFLAGS_LIB  = -O1</span><br><span class="line">FREE_LIB    = $(FREE)</span><br><span class="line"></span><br><span class="line">OBJECTS_LIB = linpack_double.o</span><br><span class="line"></span><br><span class="line"><span class="comment"># For the parser library</span></span><br><span class="line">CXX_PARS    = icpx</span><br><span class="line">LLIBS       = -lstdc++</span><br><span class="line"></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">## Customize as of this point! Of course you may change the preceding</span></span><br><span class="line"><span class="comment">## part of this file as well if you like, but it should rarely be</span></span><br><span class="line"><span class="comment">## necessary ...</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># When compiling on the target machine itself, change this to the</span></span><br><span class="line"><span class="comment"># relevant target when cross-compiling for another architecture</span></span><br><span class="line">FFLAGS     += -xHOST</span><br><span class="line"></span><br><span class="line"><span class="comment"># Intel MKL (FFTW, BLAS, LAPACK, and scaLAPACK)</span></span><br><span class="line"><span class="comment"># (Note: for Intel Parallel Studio&#x27;s MKL use -mkl instead of -qmkl)</span></span><br><span class="line">FCL        += -qmkl</span><br><span class="line">MKLROOT    ?= /opt/intel/oneapi/mkl/2024.0</span><br><span class="line">LLIBS      += -L$(MKLROOT)/lib/intel64 -lmkl_scalapack_lp64 -lmkl_blacs_openmpi_lp64</span><br><span class="line">INCS        =-I$(MKLROOT)/include/fftw</span><br><span class="line"></span><br><span class="line"><span class="comment"># HDF5-support (optional but strongly recommended)</span></span><br><span class="line">CPP_OPTIONS+= -DVASP_HDF5</span><br><span class="line">HDF5_ROOT  ?= /home/lebedmi2/SOFTWARE/HDF5_Intel/myhdfstuff/build/HDF_Group/HDF5/1.14.3</span><br><span class="line">LLIBS      += -L$(HDF5_ROOT)/lib -lhdf5_fortran</span><br><span class="line">INCS       += -I$(HDF5_ROOT)/include</span><br><span class="line"></span><br><span class="line"><span class="comment"># For the VASP-2-Wannier90 interface (optional)</span></span><br><span class="line"><span class="comment">#CPP_OPTIONS    += -DVASP2WANNIER90</span></span><br><span class="line"><span class="comment">#WANNIER90_ROOT ?= /path/to/your/wannier90/installation</span></span><br><span class="line"><span class="comment">#LLIBS          += -L$(WANNIER90_ROOT)/lib -lwannier</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For the fftlib library (experimental)</span></span><br><span class="line"><span class="comment">#CPP_OPTION += -Dsysv</span></span><br><span class="line"><span class="comment">#FCL         = mpif90 fftlib.o -qmkl</span></span><br><span class="line"><span class="comment">#CXX_FFTLIB  = icpc -qopenmp -std=c++11 -DFFTLIB_USE_MKL -DFFTLIB_THREADSAFE</span></span><br><span class="line"><span class="comment">#INCS_FFTLIB = -I./include -I$(MKLROOT)/include/fftw</span></span><br><span class="line"><span class="comment">#LIBS       += fftlib</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<h1 id="oneapi-docker-images"><a href="#oneapi-docker-images" class="headerlink" title="oneapi docker images"></a>oneapi docker images</h1><p><a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/docs/oneapi-hpc-toolkit/get-started-guide-linux/2023-0/using-containers.html">https://www.intel.com/content/www/us/en/docs/oneapi-hpc-toolkit/get-started-guide-linux/2023-0/using-containers.html</a></p>
<p>docker pull intel&#x2F;oneapi-hpckit<br>docker pull intel&#x2F;oneapi-hpckit:2023.2.1-devel-ubuntu22.04</p>
<h1 id="compile-HDF5"><a href="#compile-HDF5" class="headerlink" title="compile HDF5"></a>compile HDF5</h1><p>.&#x2F;configure –help<br>.&#x2F;configure –prefix&#x3D;&#x2F;home&#x2F;duguex&#x2F;hdf5 –enable-fortran –enable-parallel –enable-shared CC&#x3D;mpiicc FC&#x3D;mpiifort CXX&#x3D;mpiicpc CFLAGS&#x3D;’-O3 -xHost -ip’ CXXFLAGS&#x3D;’-O3 -xHost -ip’ FCFLAGS&#x3D;’-O3 -xHost -ip’<br>make &amp;&amp; make install</p>
<p>or </p>
<p>git clone <a target="_blank" rel="noopener" href="https://github.com/HDFGroup/hdf5.git">https://github.com/HDFGroup/hdf5.git</a><br>.&#x2F;autogen.sh<br>.&#x2F;configure –prefix&#x3D;&#x2F;opt&#x2F;hdf5 –enable-fortran –enable-shared –enable-parallel –with-pic CC&#x3D;mpiicc FC&#x3D;mpiifort CXX&#x3D;mpiicpc CFLAGS&#x3D;”-fPIC -O3 -xHost -ip -fno-alias -align” FFLAGS&#x3D;”-fPIC -O3 -xHost -ip -fno-alias -align” CXXFLAGS&#x3D;”-fPIC -O3 -xHost -ip -fno-alias -align” FFLAGS&#x3D;”-I&#x2F;opt&#x2F;intel&#x2F;oneapi&#x2F;mpi&#x2F;latest&#x2F;include -L&#x2F;opt&#x2F;intel&#x2F;oneapi&#x2F;mpi&#x2F;latest&#x2F;lib”<br>  <!-- --with-szlib=/home/intel/hdf5/szip-2.1 --with-zlib=/home/intel/hdf5/zlib-1.2.7 --><br>make<br>make install<br>make test</p>
<p>build without szip and zlib</p>
<p>&#x2F;opt&#x2F;hdf5&#x2F;lib</p>
<p>export LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;hdf5&#x2F;lib<br>ulimit -s unlimited</p>
<p>&#x2F;home&#x2F;duguex&#x2F;hdf5-1.12.2&#x2F;lib</p>
<p>git clone <a target="_blank" rel="noopener" href="https://github.com/HDFGroup/hdf5.git">https://github.com/HDFGroup/hdf5.git</a><br>.&#x2F;autogen.sh<br>.&#x2F;autogen.sh: 83: autoreconf: not found</p>
<p>sudo apt-get install autoconf</p>
<p>c++&#x2F;src&#x2F;Makefile.am:25: error: Libtool library used but ‘LIBTOOL’ is undefined</p>
<p>sudo apt-get install libtool</p>
<p><a target="_blank" rel="noopener" href="https://support.hdfgroup.org/doc_resource/SZIP/">https://support.hdfgroup.org/doc_resource/SZIP/</a><br><a target="_blank" rel="noopener" href="https://github.com/erdc/szip/blob/master/INSTALL">https://github.com/erdc/szip/blob/master/INSTALL</a></p>
<p>3.1 Installation with encoder (license may be required)</p>
<p>Untar the source into an szip-2.1 directory<br>% tar -xvf szip-2.1.tar</p>
<p>Change directory to the szip-2.1 directory; configure, build, and<br>test for your platform:  </p>
<p>% cd szip-2.1<br>% .&#x2F;configure –prefix&#x3D;&#x2F;opt&#x2F;szip<br>% make<br>% make check<br>% make install</p>
<h1 id="wannier90"><a href="#wannier90" class="headerlink" title="wannier90"></a>wannier90</h1><p>cp .&#x2F;config&#x2F;make.inc.ifort .&#x2F;make.inc<br>make </p>
<p>&#x2F;opt&#x2F;intel&#x2F;mkl&#x2F;lib&#x2F;intel64<br>&#x2F;opt&#x2F;intel&#x2F;oneapi&#x2F;mkl&#x2F;latest&#x2F;lib&#x2F;intel64</p>
<p>make wannier    build the wannier90.x executable<br>make post       build the postw90.x executable<br>make default    (default) build wannier90.x and postw90.x<br>make lib        build the wannier90 library<br>make w90chk2chk build the w90chk2chk.x utility (see ‘Utility’ section of the user guide)<br>make w90vdw     build the van der Waals code<br>make w90pov     build the ray-tracing code<br>make install    install the built binaries<br>make tests      run test cases<br>make doc        build the documentation<br>make dist       make a tar-ball of the distribution<br>make dist-lite  make a tar-ball of the src and tests only<br>make clean      remove object files etc<br>make veryclean  remove all non-distribution file</p>
<p>apt install python-is-python3 for make tests</p>
<p>make install PREFIX&#x3D;&#x2F;opt&#x2F;wannier90</p>
<p>export LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;wannier90&#x2F;lib<br>export OMP_NUM_THREADS&#x3D;1</p>
<h1 id="vasp-test-1"><a href="#vasp-test-1" class="headerlink" title="vasp test"></a>vasp test</h1><p>make test_all<br>make cleantest</p>
<p>VASP_TESTSUITE_RUN_WAN90</p>
<p>PATH&#x3D;$PATH:&#x2F;opt&#x2F;vasp.6.4.3&#x2F;bin<br>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;hdf5&#x2F;lib<br>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;wannier90&#x2F;lib</p>
<p>export OMP_NUM_THREADS&#x3D;1<br>export LD_LIBRARY_PATH<br>export PATH</p>
<p>NSIM<br>NCORE<br>OMP<br>NCPU</p>
<p>singularity run ..&#x2F;vasp_oneapi_6.4.3 mpirun -np 14 -genv I_MPI_PIN_DOMAIN&#x3D;omp -genv I_MPI_PIN&#x3D;yes -genv OMP_NUM_THREADS&#x3D;1 -genv OMP_STACKSIZE&#x3D;4g -genv OMP_PLACES&#x3D;cores -genv OMP_PROC_BIND&#x3D;close -genv I_MPI_DEBUG&#x3D;4 vasp_gam</p>
<h1 id="compile-oneapi-vasp"><a href="#compile-oneapi-vasp" class="headerlink" title="compile oneapi vasp"></a>compile oneapi vasp</h1><p>nvfortran-Fatal-MKLROOT not found. Please set the environment variable MKLROOT to the location of Intel’s Math Kernel Libraries (the part of the path to the *.so files that precedes ‘lib&#x2F;<arch>‘.)<br>export MKLROOT&#x3D;&#x2F;opt&#x2F;intel&#x2F;oneapi&#x2F;mkl&#x2F;2022.2.0</p>
<p>make veryclean<br>make DEPS&#x3D;1 -j</p>
<h1 id="compile-vasp-with-intel-oneapi-container"><a href="#compile-vasp-with-intel-oneapi-container" class="headerlink" title="compile vasp with intel oneapi container"></a>compile vasp with intel oneapi container</h1><p>sudo docker run -it –name&#x3D;vasp_oneapi –shm-size&#x3D;4gb intel&#x2F;oneapi-hpckit:2023.2.1-devel-ubuntu22.04</p>
<p>sudo docker run -it –name&#x3D;vasp_oneapi –ipc&#x3D;host intel&#x2F;oneapi-hpckit:2023.2.1-devel-ubuntu22.04</p>
<p>apt install rsync nano lrzsz<br>use intel omp template</p>
<h1 id="vasp-compiled-by-intel-oneapi-segmentation-fault"><a href="#vasp-compiled-by-intel-oneapi-segmentation-fault" class="headerlink" title="vasp compiled by intel oneapi segmentation fault"></a>vasp compiled by intel oneapi segmentation fault</h1><p>ulimit -s unlimited</p>
<h1 id="docker-oneapi-mpi-bus-error"><a href="#docker-oneapi-mpi-bus-error" class="headerlink" title="docker oneapi mpi bus error"></a>docker oneapi mpi bus error</h1><p><a target="_blank" rel="noopener" href="https://community.intel.com/t5/Intel-HPC-Toolkit/Issue-with-Running-mpirun-inside-docker-container/m-p/1319107">https://community.intel.com/t5/Intel-HPC-Toolkit/Issue-with-Running-mpirun-inside-docker-container/m-p/1319107</a></p>
<p>docker pull intel&#x2F;oneapi-hpckit:2023.2.1-devel-ubuntu22.04<br>docker pull intel&#x2F;oneapi-hpckit<br>docker run –shm-size&#x3D;4gb -it intel&#x2F;oneapi-hpckit<br>–ipc&#x3D;host</p>
<ul>
<li><code>--ipc=host</code>：这个选项让容器使用主机的 IPC 命名空间。IPC 是 Inter-Process Communication 的缩写，用于进程间通信。这个选项通常用于那些需要与主机共享内存的应用。</li>
</ul>
<h1 id="nvidia"><a href="#nvidia" class="headerlink" title="nvidia"></a>nvidia</h1><p>The NVIDIA CUDA compiler<br>nvcc –version</p>
<p>The nvidia-smi command provides monitoring and management capabilities for each of the following NVIDIA cards<br>nvidia-smi</p>
<p>docker pull nvcr.io&#x2F;nvidia&#x2F;nvhpc:23.9-devel-cuda_multi-ubuntu22.04<br><a target="_blank" rel="noopener" href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nvhpc/tags#">https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nvhpc/tags#</a></p>
<h1 id="compile-CUDA-For-installing-NVIDIA-HPC-SDK"><a href="#compile-CUDA-For-installing-NVIDIA-HPC-SDK" class="headerlink" title="compile CUDA (For installing NVIDIA HPC SDK)"></a>compile CUDA (For installing NVIDIA HPC SDK)</h1><p>wget <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin">https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin</a><br>sudo mv cuda-wsl-ubuntu.pin &#x2F;etc&#x2F;apt&#x2F;preferences.d&#x2F;cuda-repository-pin-600<br>wget <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/compute/cuda/12.0.0/local_installers/cuda-repo-wsl-ubuntu-12-0-local_12.0.0-1_amd64.deb">https://developer.download.nvidia.com/compute/cuda/12.0.0/local_installers/cuda-repo-wsl-ubuntu-12-0-local_12.0.0-1_amd64.deb</a><br>sudo dpkg -i cuda-repo-wsl-ubuntu-12-0-local_12.0.0-1_amd64.deb<br>sudo cp &#x2F;var&#x2F;cuda-repo-wsl-ubuntu-12-0-local&#x2F;cuda-*-keyring.gpg &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;<br>sudo apt-get update<br>sudo apt-get -y install cuda</p>
<p>wget <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb">https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb</a><br>sudo dpkg -i cuda-keyring_1.1-1_all.deb<br>sudo apt-get update<br>sudo apt-get -y install cuda-toolkit-12-3</p>
<p>sudo apt-get install -y cuda-drivers</p>
<p>sudo apt-get install -y nvidia-kernel-open-545<br>sudo apt-get install -y cuda-drivers-545</p>
<h1 id="compile-NVIDIA-HPC-SDK-should-match"><a href="#compile-NVIDIA-HPC-SDK-should-match" class="headerlink" title="compile NVIDIA HPC SDK (should match)"></a>compile NVIDIA HPC SDK (should match)</h1><p>wget <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/hpc-sdk/23.1/nvhpc_2023_231_Linux_x86_64_cuda_12.0.tar.gz">https://developer.download.nvidia.com/hpc-sdk/23.1/nvhpc_2023_231_Linux_x86_64_cuda_12.0.tar.gz</a><br>tar xpzf nvhpc_2023_231_Linux_x86_64_cuda_12.0.tar.gz<br>nvhpc_2023_231_Linux_x86_64_cuda_12.0&#x2F;install</p>
<p>$ curl <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/hpc-sdk/ubuntu/DEB-GPG-KEY-NVIDIA-HPC-SDK">https://developer.download.nvidia.com/hpc-sdk/ubuntu/DEB-GPG-KEY-NVIDIA-HPC-SDK</a> | sudo gpg –dearmor -o &#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;nvidia-hpcsdk-archive-keyring.gpg<br>$ echo ‘deb [signed-by&#x3D;&#x2F;usr&#x2F;share&#x2F;keyrings&#x2F;nvidia-hpcsdk-archive-keyring.gpg] <a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/hpc-sdk/ubuntu/amd64">https://developer.download.nvidia.com/hpc-sdk/ubuntu/amd64</a> &#x2F;‘ | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;nvhpc.list<br>$ sudo apt-get update -y<br>$ sudo apt-get install -y nvhpc-23-11-cuda-multi</p>
<h1 id="gfortran-needed"><a href="#gfortran-needed" class="headerlink" title="gfortran needed"></a>gfortran needed</h1><p>Installing NVIDIA HPC SDK version 23.1 into &#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk<br>ERROR: gfortran not found<br>Making symbolic links in &#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;2023</p>
<p>If you use the Environment Modules package, that is, the module load command, the NVIDIA HPC SDK includes a script to set up the appropriate module files.</p>
<p>% module load &#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;modulefiles&#x2F;nvhpc&#x2F;23.1<br>% module load nvhpc&#x2F;23.1</p>
<p>Alternatively, the shell environment may be initialized to use the HPC SDK.</p>
<p>In csh, use these commands:</p>
<p>% setenv MANPATH “$MANPATH”:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;compilers&#x2F;man<br>% set path &#x3D; (&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;compilers&#x2F;bin $path)</p>
<p>In bash, sh, or ksh, use these commands:</p>
<p>$ MANPATH&#x3D;$MANPATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;compilers&#x2F;man; export MANPATH<br>$ PATH&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;compilers&#x2F;bin:$PATH; export PATH</p>
<p>Once the 64-bit compilers are available, you can make the OpenMPI<br>commands and man pages accessible using these commands.</p>
<p>% set path &#x3D; (&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;comm_libs&#x2F;mpi&#x2F;bin $path)<br>% setenv MANPATH “$MANPATH”:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;comm_libs&#x2F;mpi&#x2F;man</p>
<p>And the equivalent in bash, sh, and ksh:</p>
<p>$ export PATH&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;comm_libs&#x2F;mpi&#x2F;bin:$PATH<br>$ export MANPATH&#x3D;$MANPATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;comm_libs&#x2F;mpi&#x2F;man</p>
<h2 id="nvidia-openacc-vasp"><a href="#nvidia-openacc-vasp" class="headerlink" title="nvidia openacc vasp"></a>nvidia openacc vasp</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a></p>
<p>Numerical libraries: FFTW, BLAS, LAPACK, and scaLAPACK. In case you are using the NVIDIA HPC-SDK the only numerical library you will have to install yourself is FFTW. The latter three (BLAS, LAPACK, and scaLAPACK) are shipped with the SDK. Alternatively, you can link against an installation of Intel’s oneAPI MKL library that provides all four.</p>
<p>apt install rsync libfftw3-dev</p>
<p>change the version of nvidia cuda toolkit version</p>
<h1 id="fftw"><a href="#fftw" class="headerlink" title="fftw"></a>fftw</h1><p>Mind: When you compile VASP with OpenMP support and you are not using the FFTs from the Intel-MKL library, you should compile VASP with fftlib. Otherwise, the costs of (planning) the OpenMP-threaded FFTs will become prohibitively large at higher thread counts.</p>
<p>fftlib (recommended when using OpenMP)<br>When you plan to run VASP on multiple OpenMP threads and you are not using the FFTs from the Intel-MKL library, you should link against fftlib (included in the VASP distribution). To do so, uncomment the corresponding sections in the makefile.include.*_omp files. In makefile.include.gnu_omp, for instance, that would be:</p>
<h1 id="For-the-fftlib-library-recommended"><a href="#For-the-fftlib-library-recommended" class="headerlink" title="For the fftlib library (recommended)"></a>For the fftlib library (recommended)</h1><p>CPP_OPTIONS+&#x3D; -Dsysv<br>FCL        +&#x3D; fftlib.o<br>CXX_FFTLIB  &#x3D; g++ -fopenmp -std&#x3D;c++11 -DFFTLIB_THREADSAFE<br>INCS_FFTLIB &#x3D; -I.&#x2F;include -I$(FFTW_ROOT)&#x2F;include<br>LIBS       +&#x3D; fftlib<br>LLIBS      +&#x3D; -ldl</p>
<p>NVROOT      &#x3D;$(shell which nvfortran | awk -F &#x2F;compilers&#x2F;bin&#x2F;nvfortran ‘{ print $$1 }’)</p>
<h1 id="Software-emulation-of-quadruple-precsion-mandatory"><a href="#Software-emulation-of-quadruple-precsion-mandatory" class="headerlink" title="Software emulation of quadruple precsion (mandatory)"></a>Software emulation of quadruple precsion (mandatory)</h1><p>QD         ?&#x3D; $(NVROOT)&#x2F;compilers&#x2F;extras&#x2F;qd<br>LLIBS      +&#x3D; -L$(QD)&#x2F;lib -lqdmod -lqd<br>INCS       +&#x3D; -I$(QD)&#x2F;include&#x2F;qd<br>export LD_LIBRARY_PATH&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.1&#x2F;compilers&#x2F;extras&#x2F;qd&#x2F;lib:$LD_LIBRARY_PATH<br>run with “mpirun -n 1 &#x2F;home&#x2F;duguex&#x2F;vasp.6.4.0&#x2F;openacc&#x2F;vasp_gam</p>
<h1 id="nvidia-openacc-vasp-1"><a href="#nvidia-openacc-vasp-1" class="headerlink" title="nvidia openacc vasp"></a>nvidia openacc vasp</h1><p>install singularity docker nvidia-container-toolkit restart docker</p>
<p>sudo docker run -it –gpus all –shm-size&#x3D;4gb –name vasp_openacc nvcr.io&#x2F;nvidia&#x2F;nvhpc:23.9-devel-cuda_multi-ubuntu22.04</p>
<p>apt update &amp;&amp; apt upgrade<br>apt install lrzsz nano rsync libfftw3-dev libhdf5-openmpi-dev wannier90</p>
<p>sudo docker commit vasp_openacc vasp_openacc:6.4.3<br>sudo docker tag vasp_openacc:6.4.3 192.168.1.114:5000&#x2F;vasp_openacc:6.4.3<br>sudo docker push 192.168.1.114:5000&#x2F;vasp_openacc:6.4.3<br>singularity build –sandbox vasp_6.4.3 docker:&#x2F;&#x2F;192.168.1.114:5000&#x2F;vasp_openacc:6.4.3</p>
<p>tag_name&#x3D;gnu<br>sudo docker commit vasp_$tag_name vasp_$tag_name:6.4.3;sudo docker tag vasp_$tag_name:6.4.3 192.168.1.111:5000&#x2F;vasp_$tag_name:6.4.3;sudo docker push 192.168.1.111:5000&#x2F;vasp_$tag_name:6.4.3;singularity build –sandbox vasp_$tag_name_6.4.3 docker:&#x2F;&#x2F;192.168.1.111:5000&#x2F;vasp_$tag_name:6.4.3</p>
<p>singularity build –sandbox vasp_gnu_6.4.3 docker:&#x2F;&#x2F;192.168.1.111:5000&#x2F;vasp_gnu:6.4.3</p>
<h1 id="–ipc-host-failed-for-vasp-run-with-oneapi-container"><a href="#–ipc-host-failed-for-vasp-run-with-oneapi-container" class="headerlink" title="–ipc host failed for vasp run with oneapi container"></a>–ipc host failed for vasp run with oneapi container</h1><p>actually in oneapi containers, ulimit -s unlimited is needed, and for singularity container, ulimit -s unlimited should be set in host instead of in container<br><a target="_blank" rel="noopener" href="https://github.com/apptainer/singularity/issues/5921">https://github.com/apptainer/singularity/issues/5921</a></p>
<p>IIRC, docker runs similar to the –contain&#x2F;–containall option, in that it creates a new &#x2F;dev structure in the container, where by default Singularity binds in the hosts &#x2F;dev. So the docker –shm-size option should just pass the size&#x3D; option to the &#x2F;dev container mount.</p>
<p>I can’t see a reason you should be getting that error without something else in play… :&#x2F;</p>
<p>Are there any cgroups configured that are changing the memory access? @dtrudg @cclerget Are there other things that could limit shared memory access you can think of?</p>
<p>#!&#x2F;bin&#x2F;bash<br>#SBATCH -J vasp<br>#SBATCH -p compute<br>#SBATCH -n 48<br>#SBATCH -N 1<br>#SBATCH -o %j.log<br>#SBATCH –qos&#x3D;cpu</p>
<p>module load singularity&#x2F;3.4.1<br>singularity run ~&#x2F;vasp_oneapi_6.4.3.sif mpirun vasp_gam</p>
<p>90-environment.sh<br>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;compilers&#x2F;extras&#x2F;qd&#x2F;lib<br>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;cuda&#x2F;extras&#x2F;CUPTI&#x2F;lib64</p>
<p>PATH&#x3D;$PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;compilers&#x2F;extras&#x2F;qd&#x2F;bin<br>PATH&#x3D;$PATH:&#x2F;opt&#x2F;vasp.6.4.3&#x2F;bin</p>
<p>export LD_LIBRARY_PATH<br>export PATH</p>
<p>export NVHPC&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk<br>export NVHPC_ROOT&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9</p>
<p>export OMPI_ALLOW_RUN_AS_ROOT&#x3D;1<br>export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM&#x3D;1</p>
<p>singularity run –nv ~&#x2F;container&#x2F;vasp_6.4.3.sif mpirun -np 3 –map-by ppr:3:socket:PE&#x3D;4 –bind-to core -x OMP_NUM_THREADS&#x3D;4 -x OMP_STACKSIZE&#x3D;14g -x OMP_PLACES&#x3D;cores -x OMP_PROC_BIND&#x3D;close –report-bindings vasp_gam</p>
<p>singularity run –nv ~&#x2F;container&#x2F;vasp_6.4.3.sif mpirun -np 3 vasp_gam</p>
<p>singularity run –nv ~&#x2F;container&#x2F;vasp_6.4.3.sif mpirun -np 3 –map-by ppr:3:socket:PE&#x3D;4 -x OMP_NUM_THREADS&#x3D;4 –report-bindings vasp_gam</p>
<h1 id="singlarity-container-for-nvidia-openacc-vasp"><a href="#singlarity-container-for-nvidia-openacc-vasp" class="headerlink" title="singlarity container for nvidia openacc vasp"></a>singlarity container for nvidia openacc vasp</h1><p>by compare output of export, the following envirmoment variables should added to .singularity.d&#x2F;env&#x2F;90-environment.sh</p>
<p>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;compilers&#x2F;extras&#x2F;qd&#x2F;lib<br>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;cuda&#x2F;extras&#x2F;CUPTI&#x2F;lib64</p>
<p>vasp_gam: error while loading shared libraries: libmkl_intel_lp64.so.2: cannot open shared object file: No such file or directory</p>
<p>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;intel&#x2F;oneapi&#x2F;mkl&#x2F;2023.2.0&#x2F;lib&#x2F;intel64</p>
<p>PATH&#x3D;$PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;compilers&#x2F;extras&#x2F;qd&#x2F;bin<br>PATH&#x3D;$PATH:&#x2F;opt&#x2F;vasp.6.4.2&#x2F;bin</p>
<p>export LD_LIBRARY_PATH<br>export PATH</p>
<p>export MKLROOT&#x3D;&#x2F;opt&#x2F;intel&#x2F;oneapi&#x2F;mkl&#x2F;latest<br>export NVHPC&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk<br>export NVHPC_ROOT&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9</p>
<p>export OMP_NUM_THREADS&#x3D;1<br>export OMP_NUM_THREADS&#x3D;2<br>export OMP_NUM_THREADS&#x3D;3<br>export OMP_NUM_THREADS&#x3D;4<br>export OMP_NUM_THREADS&#x3D;14<br>export OMPI_ALLOW_RUN_AS_ROOT&#x3D;1<br>export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM&#x3D;1</p>
<h1 id="90-environment-sh"><a href="#90-environment-sh" class="headerlink" title="90-environment.sh"></a>90-environment.sh</h1><p>#!&#x2F;bin&#x2F;sh</p>
<h1 id="Custom-environment-shell-code-should-follow"><a href="#Custom-environment-shell-code-should-follow" class="headerlink" title="Custom environment shell code should follow"></a>Custom environment shell code should follow</h1><p>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;compilers&#x2F;extras&#x2F;qd&#x2F;lib<br>LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;cuda&#x2F;extras&#x2F;CUPTI&#x2F;lib64</p>
<p>PATH&#x3D;$PATH:&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9&#x2F;compilers&#x2F;extras&#x2F;qd&#x2F;bin<br>PATH&#x3D;$PATH:&#x2F;opt&#x2F;vasp.6.4.2&#x2F;bin</p>
<p>export LD_LIBRARY_PATH<br>export PATH</p>
<p>export MKLROOT&#x3D;&#x2F;opt&#x2F;intel&#x2F;oneapi&#x2F;mkl&#x2F;latest<br>export NVHPC&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk<br>export NVHPC_ROOT&#x3D;&#x2F;opt&#x2F;nvidia&#x2F;hpc_sdk&#x2F;Linux_x86_64&#x2F;23.9</p>
<p>export OMP_NUM_THREADS&#x3D;1<br>export OMPI_ALLOW_RUN_AS_ROOT&#x3D;1<br>export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM&#x3D;1</p>
<h1 id="install-vasp-aocc-zen2-with-spack"><a href="#install-vasp-aocc-zen2-with-spack" class="headerlink" title="install vasp aocc zen2 with spack"></a>install vasp aocc zen2 with spack</h1><h2 id="install-spack"><a href="#install-spack" class="headerlink" title="install spack"></a>install spack</h2><p>apt update &amp;&amp; apt upgrade;<br>apt install build-essential ca-certificates coreutils curl environment-modules gfortran git gpg lsb-release python3 python3-distutils python3-venv unzip zip;<br>cd &#x2F;opt;<br>git clone -c feature.manyFiles&#x3D;true <a target="_blank" rel="noopener" href="https://github.com/spack/spack.git">https://github.com/spack/spack.git</a>;<br>. ~&#x2F;spack&#x2F;share&#x2F;spack&#x2F;setup-env.sh;</p>
<h2 id="spack-install-aocc"><a href="#spack-install-aocc" class="headerlink" title="spack install aocc"></a>spack install aocc</h2><p>spack install aocc +license-agreed;</p>
<h2 id="spack-install-vasp"><a href="#spack-install-vasp" class="headerlink" title="spack install vasp"></a>spack install vasp</h2><p>spack load aocc<br>spack compiler find<br>spack install -j 8 vasp +scalapack +openmp +fftlib %aocc ^amdfftw ^amdblis threads&#x3D;openmp ^amdlibflame ^amdscalapack ^openmpi fabrics&#x3D;auto</p>
<h2 id="env-setting"><a href="#env-setting" class="headerlink" title="env setting"></a>env setting</h2><p>#. ~&#x2F;container&#x2F;vasp_zen2&#x2F;opt&#x2F;spack&#x2F;share&#x2F;spack&#x2F;setup-env.sh<br>spack load vasp</p>
<h1 id="Running-multiple-OpenMP-threads-per-MPI-rank"><a href="#Running-multiple-OpenMP-threads-per-MPI-rank" class="headerlink" title="Running multiple OpenMP threads per MPI rank"></a>Running multiple OpenMP threads per MPI rank</h1><p>In principle, running VASP on n MPI ranks with m OpenMP threads per rank is as simple as:</p>
<p>export OMP_NUM_THREADS&#x3D;<m> ; mpirun -np <n> <your-vasp-executable><br>Here, the mpirun part of the command depends on the flavor of MPI one uses and has to be replaced appropriately. Below, we will only discuss the use of OpenMPI and IntelMPI.</p>
<p>For proper performance, it is crucial to ensure that the MPI ranks, and the associated OpenMP threads they spawn, are placed optimally onto the physical cores of the node(s), and are pinned to these cores. As an example (for a typical Intel Xeon-like architecture): Let us assume we plan to run on 2 nodes, each with 16 physical cores. These 16 cores per node are further divided into 2 packages (aka sockets) of 8 cores each. The cores on a socket share access to a block of memory and in addition, they may access the memory associated with the other package on their node via a so-called crossbar switch. The latter, however, comes at a (slight) performance penalty.</p>
<p>In the aforementioned situation, a possible placement of MPI ranks and OpenMP threads would for instance be the following: place 2 MPI ranks on each package (i.e., 8 MPI ranks in total) and have each MPI rank spawn 4 OpenMP threads on the same package. These OpenMP threads will all have fast access to the memory associated with their package, and will not have to access memory through the crossbar switch.</p>
<p>To achieve this we have to tell both the OpenMP runtime library as well as the MPI library what to do.</p>
<p>Warning: In the above we purposely mention physical cores. When your CPU supports hyperthreading (and if this is enabled in the BIOS) there are more logical cores than physical cores (typically a factor 2). As a rule of thumb: makes sure that the total number of MPI ranks × OMP_NUM_THREADS (in the above: m×n) does not exceed the total number of physical cores (i.e., do not oversubscribe the nodes). In general VASP runs do not benefit from oversubscription.<br>For the OpenMP runtime<br>Tell the OpenMP runtime it may spawn 4 threads per MPI rank:</p>
<p>export OMP_NUM_THREADS&#x3D;4<br>and that it should bind the threads to the physical cores, and put them onto cores that are as close as possible to the core that is running the corresponding MPI rank (and OpenMP master thread):</p>
<p>export OMP_PLACES&#x3D;cores<br>export OMP_PROC_BIND&#x3D;close<br>In addition to taking care of thread placement, it is often necessary to increase the size of the private stack of the OpenMP threads (to 256 or even 512 Mbytes), since the default is in many cases too small for VASP to run, and will cause segmentation faults:</p>
<p>export OMP_STACKSIZE&#x3D;512m<br>Mind: The Intel OpenMP-runtime library (libiomp5.so) offers an alternative set of environment variables to control OpenMP-thread placement, stacksize etc.</p>
<h1 id="Mapping-of-process-to-hardware-resources"><a href="#Mapping-of-process-to-hardware-resources" class="headerlink" title="Mapping of process to hardware resources"></a>Mapping of process to hardware resources</h1><p>For AMD EPYC processors it is recommended to use a single rank per L3 cache and set OMP_NUM_THREADS to the number of cores per L3 cache. Below is the example for 4th Gen EPYC processors with 8 cores per L3 cache, hence using OMP_NUM_THREADS&#x3D;8<br>export NUM_CORES&#x3D;$(( $(nproc) &#x2F; 2 ))<br>export OMP_NUM_THREADS&#x3D;4<br>NUM_MPI_RANKS&#x3D;$(( $NUM_CORES &#x2F; $OMP_NUM_THREADS ))</p>
<h1 id="Running-VASP-1"><a href="#Running-VASP-1" class="headerlink" title="Running VASP"></a>Running VASP</h1><p>mpirun -np $NUM_MPI_RANKS –map-by ppr:1:l3cache:pe&#x3D;$OMP_NUM_THREADS –report-bindings vasp_gam</p>
<h2 id="Using-OpenMPI"><a href="#Using-OpenMPI" class="headerlink" title="Using OpenMPI"></a>Using OpenMPI</h2><p>Now start 8 MPI ranks (-np 8), with the following placement specification: 2 ranks&#x2F;socket, assigning 4 subsequent cores to each rank (–map-by ppr:2:socket:PE&#x3D;4), and bind them to their physical cores (–bind-to core):</p>
<p>mpirun -np 8 –map-by ppr:2:socket:PE&#x3D;4 –bind-to core <your-vasp-executable><br>Or all of the above wrapped into a single command:</p>
<p>mpirun -np 8 –map-by ppr:2:socket:PE&#x3D;4 –bind-to core <br>              -x OMP_NUM_THREADS&#x3D;4 -x OMP_STACKSIZE&#x3D;512m <br>              -x OMP_PLACES&#x3D;cores -x OMP_PROC_BIND&#x3D;close <br>              –report-bindings <your-vasp-executable><br>where the –report-bindings is optional but a good idea to use at least once to check whether the rank and thread placement is as intended.</p>
<p>singularity run –nv ~&#x2F;container&#x2F;vasp_acc mpirun -np 2 –map-by ppr:1:socket:PE&#x3D;4 –bind-to core -x OMP_NUM_THREADS&#x3D;4 -x OMP_STACKSIZE&#x3D;10g -x OMP_PLACES&#x3D;cores -x OMP_PROC_BIND&#x3D;close –report-bindings vasp_gam</p>
<p>singularity run –nv ~&#x2F;vasp_gpu mpirun -np 1 –map-by ppr:1:socket:PE&#x3D;4 –bind-to core -x OMP_NUM_THREADS&#x3D;4 -x OMP_STACKSIZE&#x3D;4g -x OMP_PLACES&#x3D;cores -x OMP_PROC_BIND&#x3D;close –report-bindings vasp_gam</p>
<p>singularity run –nv ~&#x2F;vasp_gpu nvidia-smi</p>
<p>In our example, the above will assure that the OpenMP threads each MPI rank spawns reside on the same package&#x2F;socket, and pins both the MPI ranks as well as the OpenMP threads to specific cores. This is crucial for performance.</p>
<h2 id="Using-IntelMPI"><a href="#Using-IntelMPI" class="headerlink" title="Using IntelMPI"></a>Using IntelMPI</h2><p>Tell MPI to reserve a domain of OMP_NUM_THREADS cores for each rank</p>
<p>export I_MPI_PIN_DOMAIN&#x3D;omp<br>and pin the MPI ranks to the cores</p>
<p>export I_MPI_PIN&#x3D;yes<br>Then start VASP on 8 MPI ranks</p>
<p>mpirun -np 8 <your-vasp-executable><br>In case one uses Intel MPI, things are fortunately a bit less involved. Distributing 8 MPI-ranks over 2 nodes with 16 physical cores each (2 sockets per node) allowing for 4 OpenMP threads per MPI-rank is as simple as:</p>
<p>mpirun -np 8 -genv I_MPI_PIN&#x3D;yes -genv I_MPI_PIN_DOMAIN&#x3D;omp -genv I_MPI_DEBUG&#x3D;4<br>Or all of the above wrapped up into a single command:</p>
<p>mpirun -np 8 -genv I_MPI_PIN_DOMAIN&#x3D;omp -genv I_MPI_PIN&#x3D;yes -genv OMP_NUM_THREADS&#x3D;4 -genv OMP_STACKSIZE&#x3D;512m -genv OMP_PLACES&#x3D;cores -genv OMP_PROC_BIND&#x3D;close -genv I_MPI_DEBUG&#x3D;4 <your-vasp-executable></p>
<p>ulimit -s unlimited</p>
<p>singularity run ~&#x2F;container&#x2F;vasp_intel_2690v2 mpirun -np 20 -genv I_MPI_PIN_DOMAIN&#x3D;omp -genv I_MPI_PIN&#x3D;yes -genv OMP_NUM_THREADS&#x3D;1 -genv OMP_STACKSIZE&#x3D;512m -genv OMP_PLACES&#x3D;cores -genv OMP_PROC_BIND&#x3D;close -genv I_MPI_DEBUG&#x3D;4 vasp_gam</p>
<p>mpirun -np 14 -genv I_MPI_PIN_DOMAIN&#x3D;omp -genv I_MPI_PIN&#x3D;yes -genv OMP_NUM_THREADS&#x3D;1 -genv OMP_STACKSIZE&#x3D;4g -genv OMP_PLACES&#x3D;cores -genv OMP_PROC_BIND&#x3D;close -genv I_MPI_DEBUG&#x3D;4 vasp_gam</p>
<p>where the -genv I_MPI_DEBUG&#x3D;4 is optional but a good idea to use at least once to check whether the rank and thread placement is as intended.</p>
<p>In our example, the above will assure that the OpenMP threads each MPI rank spawns reside on the same package&#x2F;socket, and pins both the MPI ranks as well as the OpenMP threads to specific cores. This is crucial for performance.</p>
<h2 id="MPI-versus-MPI-OpenMP-the-main-difference"><a href="#MPI-versus-MPI-OpenMP-the-main-difference" class="headerlink" title="MPI versus MPI&#x2F;OpenMP: the main difference"></a>MPI versus MPI&#x2F;OpenMP: the main difference</h2><p>By default VASP distributes work and data over the MPI ranks on a per-orbital basis (in a round-robin fashion): Bloch orbital 1 resides on rank 1, orbital 2 on rank 2. and so on. Concurrently, however, the work and data may be further distributed in the sense that not a single, but a group of MPI ranks, is responsible for the optimization (and related FFTs) of a particular orbital. In the pure MPI version of VASP, this is specified by means of the NCORE tag.</p>
<p>For instance, to distribute each individual Bloch orbital over 4 MPI ranks, one specifies:</p>
<p>NCORE &#x3D; 4<br>The main difference between the pure MPI and the hybrid MPI&#x2F;OpenMP version of VASP is that the latter will not distribute a single Bloch orbital over multiple MPI ranks but will distribute the work on a single Bloch orbital over multiple OpenMP threads.</p>
<p>As such one does not set NCORE&#x3D;4 in the INCAR file but starts VASP with 4 OpenMP-threads&#x2F;MPI-rank.</p>
<p>Warning: The hybrid MPI&#x2F;OpenMP version of VASP will internally set NCORE&#x3D;1, regardless of what was specified in the INCAR file, when it detects it has been started on more than one OpenMP thread.</p>
<h1 id="docker-vasp-warning"><a href="#docker-vasp-warning" class="headerlink" title="docker vasp warning"></a>docker vasp warning</h1><hr>
<p>WARNING: Open MPI tried to bind a process but failed.  This is a<br>warning only; your job will continue, though performance may<br>be degraded.</p>
<p>  Local host:        d2ea6c9add4f<br>  Application name:  &#x2F;opt&#x2F;vasp.6.4.2&#x2F;testsuite&#x2F;..&#x2F;bin&#x2F;vasp_std<br>  Error message:     failed to bind memory<br>  Location:          ..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;orte&#x2F;mca&#x2F;rtc&#x2F;hwloc&#x2F;rtc_hwloc.c:447</p>
<h2 id="might-be-the-issue-of-docker-https-github-com-open-mpi-ompi-issues-7368"><a href="#might-be-the-issue-of-docker-https-github-com-open-mpi-ompi-issues-7368" class="headerlink" title="might be the issue of docker https://github.com/open-mpi/ompi/issues/7368"></a>might be the issue of docker <a target="_blank" rel="noopener" href="https://github.com/open-mpi/ompi/issues/7368">https://github.com/open-mpi/ompi/issues/7368</a></h2><p>[LOG_CAT_ML] You must specify a valid HCA device by setting:<br>-x HCOLL_MAIN_IB&#x3D;&lt;dev_name:port&gt; or -x UCX_NET_DEVICES&#x3D;&lt;dev_name:port&gt;.<br>If no device was specified for HCOLL (or the calling library), automatic device detection will be run.<br>In case of unfounded HCA device please contact your system administrator.</p>
<p>[d2ea6c9add4f:38517] Error: ..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;ompi&#x2F;mca&#x2F;coll&#x2F;hcoll&#x2F;coll_hcoll_module.c:310 - mca_coll_hcoll_comm_query() Hcol library init failed</p>
<p> running    4 mpi-ranks, with    2 threads&#x2F;rank, on    1 nodes<br> distrk:  each k-point on    2 cores,    2 groups<br> distr:  one band on    1 cores,    2 groups<br> OpenACC runtime initialized …    1 GPUs detected<br> WARNING: INIT_ACC: several MPI-ranks need to share a GPU, which is not<br>     supported by NCCL. The use of NCCL will be switched off. To avoid this,<br>     reduce the number of MPI-ranks: #-of-ranks &lt;&#x3D; #-of-GPUs (on every node!).</p>
<p>[d2ea6c9add4f:38510] 3 more processes have sent help message help-orte-odls-default.txt &#x2F; memory not bound<br>[d2ea6c9add4f:38510] Set MCA parameter “orte_base_help_aggregate” to 0 to see all help &#x2F; error messages</p>
<h1 id="avx-test"><a href="#avx-test" class="headerlink" title="avx test"></a>avx test</h1><p>avx avx2 avx512</p>
<p>#SBATCH -n 6<br>#SBATCH -N 1<br>#SBATCH –gres&#x3D;gpu:p100:3<br>#SBATCH -o %j.log</p>
<p>singularity run –nv &#x2F;home&#x2F;duguex&#x2F;container&#x2F;vasp_6.4.3_openacc_p100_7940x.sif mpirun -np 3 -x OMP_NUM_THREADS&#x3D;1 vasp_gam</p>
<p>is good</p>
<h1 id="kunpeng-920-vasp-hyperfine"><a href="#kunpeng-920-vasp-hyperfine" class="headerlink" title="kunpeng 920 vasp hyperfine"></a>kunpeng 920 vasp hyperfine</h1><p>LEFG is good, LHYPERFINE is bad<br>       N       E                     dE             d eps       ncg     rms          rms(c)<br>*** Error in <code>vasp_gam&#39;: free(): invalid pointer: 0x0000000044f69970 *** *** Error in </code>vasp_gam’: double free or corruption (!prev): 0x000000001953bb30 ***<br>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; Backtrace: &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<br>&#x2F;lib64&#x2F;libc.so.6(+0x7d1ec)[0x40000f33d1ec]<br>vasp_gam[0x657bc0]</p>
<h1 id="显著影响速度"><a href="#显著影响速度" class="headerlink" title="显著影响速度"></a>显著影响速度</h1><p>NUPDOWN&#x3D;2</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/vasp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/vasp/" class="post-title-link" itemprop="url">vasp_tags</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 17:09:36" itemprop="dateCreated datePublished" datetime="2024-06-15T17:09:36+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:21" itemprop="dateModified" datetime="2024-07-30T00:45:21+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="INCAR-tags"><a href="#INCAR-tags" class="headerlink" title="INCAR tags"></a>INCAR tags</h1><p>控制占据<br>ISMEAR&#x3D;-2<br>FERWE&#x3D;643<em>1.0 1</em>0.0 1.0 500<em>0.0<br>FERDO&#x3D;643</em>1.0 1<em>0.0 1.0 500</em>0.0</p>
<p>旋轨耦合<br>LSORBIT&#x3D;.TRUE.<br>SAXIS&#x3D;0 0 1<br>MAGMOM&#x3D;0 0 3 500*0</p>
<p>杂化密度泛函<br>LHFCALC&#x3D;.TRUE.<br>HFSCREEN&#x3D;0.2<br>AEXX&#x3D;0.25<br>ALGO&#x3D;All<br>PRECFOCK&#x3D;Fast</p>
<p>HSE06<br>GGA &#x3D; PE<br>ALGO&#x3D;All<br>LHFCALC &#x3D; .TRUE.<br>HFSCREEN &#x3D; 0.2<br>AEXX&#x3D;0.25<br>PRECFOCK&#x3D;Fast</p>
<p>with the default values AEXX&#x3D;0.25, AGGAX&#x3D;1-AEXX&#x3D;0.75, AGGAC&#x3D;1.0, and ALDAC&#x3D;1.0.</p>
<p>HSE03<br>LHFCALC &#x3D; .TRUE.<br>GGA &#x3D; PE<br>HFSCREEN &#x3D; 0.3<br>with the default values AEXX&#x3D;0.25, AGGAX&#x3D;1-AEXX&#x3D;0.75, AGGAC&#x3D;1.0, and ALDAC&#x3D;1.0.</p>
<p>HSEsol<br>LHFCALC &#x3D; .TRUE.<br>GGA &#x3D; PS<br>HFSCREEN &#x3D; 0.2<br>with the default values AEXX&#x3D;0.25, AGGAX&#x3D;1-AEXX&#x3D;0.75, AGGAC&#x3D;1.0, and ALDAC&#x3D;1.0.<br>Unscreened hybrid functionals</p>
<p>PBEh (PBE0)<br>LHFCALC &#x3D; .TRUE.<br>GGA &#x3D; PE<br>with the default values AEXX&#x3D;0.25, AGGAX&#x3D;1-AEXX&#x3D;0.75, AGGAC&#x3D;1.0, and ALDAC&#x3D;1.0.</p>
<p>B3LYP with VWN3 (or VWN5) for LDA correlation<br>LHFCALC &#x3D; .TRUE.<br>GGA     &#x3D; B3 (or B5)<br>AEXX    &#x3D; 0.2<br>AGGAX   &#x3D; 0.72<br>AGGAC   &#x3D; 0.81<br>ALDAC   &#x3D; 0.19<br>with the default value ALDAX&#x3D;1-AEXX&#x3D;0.8.</p>
<p>B3PW91 (using Libxc, see the tag LIBXC1)<br>LHFCALC &#x3D; .TRUE.<br>GGA &#x3D; LIBXC<br>LIBXC1 &#x3D; HYB_GGA_XC_B3PW91 # or 401<br>AEXX &#x3D; 0.2</p>
<p>B1-WC (using Libxc, see the tag LIBXC1)<br>LHFCALC &#x3D; .TRUE.<br>GGA &#x3D; LIBXC<br>LIBXC1 &#x3D; HYB_GGA_XC_B1WC # or 412<br>AEXX &#x3D; 0.16</p>
<p>SCAN0<br>LHFCALC &#x3D; .TRUE.<br>METAGGA &#x3D; SCAN<br>with the default values AEXX&#x3D;0.25, AMGGAX&#x3D;1-AEXX&#x3D;0.75, and AMGGAC&#x3D;1.0.</p>
<p>METAGGA&#x3D;SCAN<br>The SCAN (Strongly constrained and appropriately normed) functional is a semilocal density functional that fulfills all known constraints that the exact density functional must fulfill. There are indications that this functional is superior to most gradient corrected functionals. This functional is only available as of VASP version ≥ 5.4.3.<br>METAGGA&#x3D;RSCAN<br>The rSCAN (regularized SCAN) functional, introduces regularizations that improve the numerical sensitivity and convergence behavior. These regularizations break several of the exact constraints that the parent SCAN functional was designed to satisfy. However, testing has indicated that the accuracy of rSCAN can be inferior to SCAN in some cases. This functional is available as of VASP version ≥ 6.2.0.<br>METAGGA&#x3D;R2SCAN<br>The r2SCAN (regularized-restored SCAN) functional modifies the regularizations introduced in rSCAN to enforce adherence to the exact constraints obeyed by SCAN. It fulfills all known constraints. However, it only recovers the slowly varying density-gradient expansion for exchange to second order, while SCAN recovers the expansion to 4th order. Testing indicates that r2SCAN at least matches the accuracy of the parent SCAN functional but with significantly improved numerical efficiency and accuracy under low-cost computational settings. This functional is available as of VASP version ≥ 6.2.0, or in version 5.4.4 by patch 4.<br>METAGGA&#x3D;SCAN_X, RSCAN_X, or R2SCAN_X<br>The exchange component of SCAN, RSCAN, or R2SCAN. Available since VASP.6.4.3.<br>METAGGA&#x3D;SCAN_C, RSCAN_C, or R2SCAN_C<br>The correlation component of SCAN, RSCAN, or R2SCAN. Available since VASP.6.4.3.<br>METAGGA&#x3D;SCANL, RSCANL, or R2SCANL<br>The functionals SCAN-L, rSCAN-L, and r2SCAN-L are deorbitalized versions of SCAN, rSCAN, and r2SCAN, respectively. They do not depend on the kinetic-energy density tau , but on the Laplacian of the density instead.</p>
<p>Hartree-Fock (no correlation)<br>LHFCALC &#x3D; .TRUE.<br>AEXX    &#x3D; 1.0<br>with the default values AGGAX&#x3D;1-AEXX&#x3D;0.0, ALDAC&#x3D;0.0, and AGGAC&#x3D;0.0.</p>
<p>LHFCALC &#x3D; .TRUE.<br>GGA &#x3D; PE<br>HFSCREEN &#x3D; 0.2</p>
<p>LDA+U<br>LDAU&#x3D;.TRUE.<br>LDAUL&#x3D;1 -1 -1 -1<br>LDAUU&#x3D;3 0 0 0<br>LDAUJ&#x3D;0 0 0 0</p>
<p>电荷密度<br>LPARD &#x3D; .T.<br>IBAND &#x3D; 872<br>LSEPB &#x3D; .TRUE.</p>
<p>杂化密度泛函+控制占据<br><a target="_blank" rel="noopener" href="https://wiki.kfki.hu/nano/Easy_manual_occupancy_of_Kohn-Sham_levels_with_FERWE_and_FERDO">https://wiki.kfki.hu/nano/Easy_manual_occupancy_of_Kohn-Sham_levels_with_FERWE_and_FERDO</a><br>LHFCALC&#x3D;.TRUE.<br>HFSCREEN&#x3D;0<br>AEXX&#x3D;0.32<br>ALGO&#x3D;All<br>PRECFOCK&#x3D;Fast<br>LDIAG &#x3D; .FALSE.<br>LSUBROT &#x3D; .FALSE.</p>
<h1 id="Nonlocal-vdW-DF-functionals"><a href="#Nonlocal-vdW-DF-functionals" class="headerlink" title="Nonlocal vdW-DF functionals"></a>Nonlocal vdW-DF functionals</h1><p>Jump to navigationJump to search The vdW-DF method originally proposed by Dion et al.[1] consists of a semilocal exchange-correlation functional that is augmented with a nonlocal correlation functional {\displaystyle E_{\text{c,disp}}} that approximately accounts for dispersion interactions. In VASP, the nonlocal functional is implemented using the algorithm of Román-Pérez and Soler[2] that is based on FFTs and the convolution theorem to calculate efficiently the double real-space integral. Several versions of the vdW-DF functionals proposed in the literature can be used (see list below).</p>
<p>The vdW-DF functionals are available since the 5.2.12.26May2011 version of VASP for the calculation of total energies and forces. The stress tensor calculation for the cell optimization (ISIF&#x3D;3) is available since the VASP 5.2.12.11Nov2011 version for spin-unpolarized systems and VASP 5.3.1 for spin-polarized systems. They have been implemented by J. Klimeš. If you make use of the vdW-DF functionals presented in this section, we ask you to cite Ref. [3]. Please also cite the original vdW-DF paper of Dion et al.[1] and the paper of Román-Pérez and Soler[2].</p>
<p>An overview of the performance of the vdW-DF functionals can be found for instance in Ref. [3][4][5].</p>
<p>Contents<br>1	List of nonlocal vdW-DF functionals<br>2	Important technical remarks<br>3	Related Tags and Sections<br>4	References<br>List of nonlocal vdW-DF functionals<br>To add a nonlocal correlation energy {\displaystyle E_{\text{c,disp}}} to the semilocal exchange-correlation energy (selected with the GGA or METAGGA tag) one needs to set LUSE_VDW&#x3D;.TRUE. in the INCAR file.<br>Note that for all vdW-DF functionals listed below except rVV10 and SCAN+rVV10, the GGA component of the semilocal (PBE) correlation needs to be removed (with AGGAC&#x3D;0.0), so that only LDA correlation is left.<br>In the vdW-DF2 and rev-vdW-DF2 functionals, the nonlocal correlation consists of the Dion et al. functional, but with the parameter {\displaystyle Z_{ab}} that is changed from -0.8491 (the default value in VASP) to -1.8867 by setting ZAB_VDW&#x3D;-1.8867.<br>Since vdW-DF functionals tend to yield less spherical densities than standard GGA functionals, it is recommended to set LASPH&#x3D;.TRUE. to get reasonably accurate contributions from the spheres around the atoms.<br>Mind: In versions of VASP prior to 6.4.0, a meta-GGA functional (e.g., SCAN) could be combined only with the rVV10 nonlocal functional. Conversely, a GGA functional could be combined only with the original nonlocal functional of Dion et al.. This restriction is lifted since VASP.6.4.0 thanks to the introduction of the IVDW_NL tag.<br>Mind: Since VASP.6.4.0, the spin-polarized formulation of the nonlocal vdW correlation term[6] is available. It can be switched on with the logical tag LSPIN_VDW (.FALSE. by default), however its use is limited to the the functional of Dion et al. (not available for rVV10) and only when the nonlocal term is combined with a GGA functional. In other cases (and in prior versions of VASP), the nonlocal correlation functional is evaluated with the sum of the spin-up and spin-down electron densities.<br>Mind: In VASP.6.2 (and prior versions) the stress tensor is broken for rVV10 (it is correct for other vdW-DF though). From VASP.6.3.0 onwards, the stress tensor for rVV10 is correct.<br>Examples of INCAR files are shown below.</p>
<p>Original vdW-DF of Dion et al.[1]:<br>GGA      &#x3D; RE<br>AGGAC    &#x3D; 0.0<br>LUSE_VDW &#x3D; .TRUE.<br>LASPH    &#x3D; .TRUE.<br>vdW-DF2 of Lee et al. (2nd version of vdW-DF)[7]:<br>GGA      &#x3D; ML<br>AGGAC    &#x3D; 0.0<br>LUSE_VDW &#x3D; .TRUE.<br>ZAB_VDW  &#x3D; -1.8867 # the default is -0.8491<br>LASPH    &#x3D; .TRUE.<br>optPBE-vdW of Klimeš et al.[8]:<br>GGA      &#x3D; OR<br>AGGAC    &#x3D; 0.0<br>LUSE_VDW &#x3D; .TRUE.<br>LASPH    &#x3D; .TRUE.<br>optB88-vdW of Klimeš et al.[8]:<br>GGA      &#x3D; BO<br>PARAM1   &#x3D; 0.1833333333<br>PARAM2   &#x3D; 0.22<br>AGGAC    &#x3D; 0.0<br>LUSE_VDW &#x3D; .TRUE.<br>LASPH    &#x3D; .TRUE.<br>optB86b-vdW of Klimeš et al.[3]:<br>GGA      &#x3D; MK<br>PARAM1   &#x3D; 0.1234<br>PARAM2   &#x3D; 1.0<br>AGGAC    &#x3D; 0.0<br>LUSE_VDW &#x3D; .TRUE.<br>LASPH    &#x3D; .TRUE.<br>rev-vdW-DF2 (also known as vdW-DF2-B86R) of Hamada[9]:<br>GGA      &#x3D; MK<br>PARAM1   &#x3D; 0.1234567 # 10&#x2F;81~0.1234567<br>PARAM2   &#x3D; 0.7114<br>AGGAC    &#x3D; 0.0<br>LUSE_VDW &#x3D; .TRUE.<br>ZAB_VDW  &#x3D; -1.8867 # the default is -0.8491<br>LASPH    &#x3D; .TRUE.<br>vdW-DF-cx of Berland and Hyldgaard[10]:<br>GGA      &#x3D; CX<br>AGGAC    &#x3D; 0.0<br>LUSE_VDW &#x3D; .TRUE.<br>LASPH    &#x3D; .TRUE.<br>rVV10 of Sabatini et al. [11]:<br>GGA      &#x3D; ML<br>LUSE_VDW &#x3D; .TRUE.<br>IVDW_NL  &#x3D; 2<br>BPARAM   &#x3D; 6.3     # default but can be overwritten by this tag<br>CPARAM   &#x3D; 0.0093  # default but can be overwritten by this tag<br>LASPH    &#x3D; .TRUE.<br>SCAN+rVV10 of Peng et al. [12]:<br>METAGGA  &#x3D; SCAN<br>LUSE_VDW &#x3D; .TRUE.<br>BPARAM   &#x3D; 15.7    # the default value is 6.3<br>CPARAM   &#x3D; 0.0093  # default but can be overwritten by this tag<br>LASPH    &#x3D; .TRUE.<br>r2SCAN+rVV10 of Ning et al. [13]:<br>METAGGA  &#x3D; R2SCAN<br>LUSE_VDW &#x3D; .TRUE.<br>BPARAM   &#x3D; 11.95   # the default value is 6.3<br>CPARAM   &#x3D; 0.0093  # default but can be overwritten by this tag<br>LASPH    &#x3D; .TRUE.<br>Important technical remarks<br>The calculation of the nonlocal correlation functional of Dion et al. (used in all functionals listed above except rVV10 and SCAN+rVV10) requires a precalculated kernel which is distributed via the VASP download portal (VASP -&gt; src -&gt; vdw_kernel.bindat). If VASP does not find this file, the kernel will be calculated, which is however rather demanding. The kernel needs to be either copied to the VASP run directory for each calculation or can be stored in a central location and read from there. The location needs to be set in routine PHI_GENERATE. This does not work on some clusters and the kernel needs to be copied into the run directory in such cases. The distributed file uses little endian convention and won’t be read on big endian machines. The big endian version of the file is available from the VASP team. In the case of the rVV10 nonlocal correlation functional, no precalculated kernel is required and it is calculated on the fly, which is however not as demanding as in the case of the functional of Dion et al..<br>There are no special POTCAR files for the vdW-DF functionals and the PBE or LDA POTCAR files can be used. Currently the evaluation of the nonlocal correlation functional is not done fully within the PAW method, but the sum of the pseudo-valence density and partial core density is used. This approximation works rather well, as is discussed in [3], and the accuracy generally increases when the number of valence electrons is increased or when harder PAW datasets are used. For example, for adsorption it is recommended to compare the adsorption energy obtained with standard PAW datasets and more-electron POTCAR files for both PBE calculations and vdW-DF calculations to assess the quality of the results.<br>The evaluation of the nonlocal correlation energy requires some additional time. Most of it is spent on performing FFTs to evaluate the energy and potential. Thus the additional time is determined by the number of FFT grid points, basically the size of the simulation cell. It is almost independent on the number of the atoms in the cell. Thus the relative cost of the vdW-DF method depends on the “filling” of the cell and increases with the amount of vacuum in the cell. The relative increase is high for isolated molecules in large cells, but small for solids in smaller cells with many k-points.</p>
<h1 id="NSIM"><a href="#NSIM" class="headerlink" title="NSIM"></a>NSIM</h1><p>To achieve the best performance it is important to chose KPAR and NSIM wisely. Unfortunately, the ideal values will depend on the particulars of your system, both in the sense of workload as well as hardware, so you will have to experiment with different settings. However, as a rule of thumb one can say:<br>Set KPAR to the number of GPUs (&#x3D; MPI-ranks) you are going to use. This only makes sense, though, when the number of irreducible k-points in your calculation is more or less evenly dividable by KPAR, otherwise the distribution of the work over the MPI-ranks will be strongly imbalanced. This means your options in choosing this parameter are somewhat limited.<br>NSIM determines the number of bands that are optimized simultaneously in many of the electronic solvers (e.g RMM-DIIS and blocked-Davidson). As a rule, one should choose this parameter larger to get good performance on GPUs than one would for CPU-sided execution.<br>N.B.: For optimal CPU-sided execution of VASP one would normally experiment with different settings for NCORE as well. When running on GPUs anything different from NCORE&#x3D;1 will adversely affect performance, and VASP will automatically switch to NCORE&#x3D;1, even if otherwise specified in the INCAR file.</p>
<hr>
<p>NSIM &#x3D; [integer]<br>Default: NSIM &#x3D; 4 </p>
<p>Description: NSIM sets the number of bands that are optimized simultaneously by the RMM-DIIS algorithm.</p>
<p>The RMM-DIIS algorithm (IALGO&#x3D;48) works in a blocked mode. NSIM bands are optimized at the same time. This allows to use matrix-matrix operations instead of matrix-vector operation for the evaluations of the non local projection operators in real space, and might speed up calculations on some machines. There should be no difference in the total energy and the convergence behavior between NSIM&#x3D;1 and NSIM&gt;1, only the performance should improve.</p>
<h1 id="phonopy-phonon-basic-use-and-animation"><a href="#phonopy-phonon-basic-use-and-animation" class="headerlink" title="phonopy phonon basic use and animation"></a>phonopy phonon basic use and animation</h1><p>conda install -c conda-forge phonopy<br>conda install conda-forge::seekpath</p>
<p>phonopy -d –dim&#x3D;”1 1 1”;phonopy –fc vasprun.xml;<br>echo -e “DIM &#x3D; 1 1 1\nPRIMITIVE_AXES&#x3D;Auto\nBAND &#x3D;0 0 0 0 0 0\nFORCE_CONSTANTS&#x3D; READ\nEIGENVECTORS&#x3D;.TRUE.\nBAND_POINTS&#x3D;1\n” &gt; band.conf;<br>phonopy band.conf;</p>
<p>band.conf<br>ATOM_NAME &#x3D;Si<br>DIM &#x3D; 1 1 1<br>PRIMITIVE_AXES&#x3D;Auto<br>MP &#x3D; 24 24 24<br>BAND &#x3D;-0.333333 0.666667 0.0  0.0 0.0 0.0  0.0 0.0 0.5<br>BAND_POINTS &#x3D; 101<br>FORCE_CONSTANTS&#x3D; READ</p>
<p>mesh.conf<br>DIM &#x3D; 1 1 1<br>MP &#x3D; 7 7 7<br>PRIMITIVE_AXES&#x3D;Auto<br>FORCE_CONSTANTS&#x3D; READ</p>
<p>DIM&#x3D; 1 1 1<br>FORCE_CONSTANTS&#x3D;read<br>EIGENVECTORS&#x3D;.TRUE.<br>BAND&#x3D; 0 0 0 0 0 0<br>PRIMITIVE_AXES&#x3D;Auto<br>BAND_POINTS&#x3D;1<br>ANIME_TYPE &#x3D; XYZ<br>ANIME &#x3D; 4 5 20</p>
<p><a target="_blank" rel="noopener" href="https://phonopy.github.io/phonopy/setting-tags.html?highlight=anim#create-animation-file">https://phonopy.github.io/phonopy/setting-tags.html?highlight=anim#create-animation-file</a><br>Create animation file<br>ANIME_TYPE<br>ANIME_TYPE &#x3D; JMOL<br>There are V_SIM, ARC, XYZ, JMOL, and POSCAR settings. Those may be viewed by v_sim, gdis, jmol (animation), jmol (vibration), respectively. For POSCAR, a set of POSCAR format structure files corresponding to respective animation images are created such as APOSCAR-000, APOSCAR-001,….</p>
<p>There are several parameters to be set in the ANIME tag.</p>
<p>ANIME<br>The format of ANIME tag was modified after ver. 0.9.3.3.</p>
<p>For v_sim<br>ANIME &#x3D; 0.5 0.5 0<br>The values are the q-point to be calculated. An animation file of anime.ascii is generated.</p>
<p>How to watch animation<br>For the other animation formats<br>Phonon is only calculated at  point. So q-point is not necessary to be set.</p>
<p>anime.arc, anime.xyz, anime.xyz_jmol, or APOSCAR-* are generated according to the ANIME_TYPE setting.</p>
<p>ANIME &#x3D; 4 5 20 0.5 0.5 0<br>The values are as follows from left:</p>
<p>Band index given by ascending order in phonon frequency.</p>
<p>Magnitude to be multiplied. In the harmonic phonon calculation, there is no amplitude information obtained directly. The relative amplitude among atoms in primitive cell can be obtained from eigenvectors with the constraint of the norm or the eigenvectors equals one, i.e., number of atoms in the primitive is large, the displacements become small. Therefore this has to be adjusted to make the animation good looking.</p>
<p>Number of images in one phonon period.</p>
<p>(4-6) Shift of atomic points in reduced coordinate in real space. These values can be omitted and the default values are 0 0 0.</p>
<p>For anime.xyz_jmol, the first and third values are not used, however dummy values, e.g. 0, are required.</p>
<h1 id="NGYROMAG"><a href="#NGYROMAG" class="headerlink" title="NGYROMAG"></a>NGYROMAG</h1><p>Default: NGYROMAG &#x3D; NTYP*1.0</p>
<h1 id="QUAD-EFG"><a href="#QUAD-EFG" class="headerlink" title="QUAD_EFG"></a>QUAD_EFG</h1><p>Default: QUAD_EFG &#x3D; NTYP*1.0 </p>
<p>For IBRION&#x3D;0, a molecular dynamics is performed, whereas all other algorithms are destined for relaxations into a local energy minimum. For difficult relaxation problems it is recommended to use the conjugate gradient algorithm (IBRION&#x3D;2), which presently possesses the most reliable backup routines. Damped molecular dynamics (IBRION&#x3D;3) are often useful when starting from very bad initial guesses. Close to the local minimum the RMM-DIIS (IBRION&#x3D;1) is usually the best choice. IBRION&#x3D;5 and IBRION&#x3D;6 are using finite differences to determine the second derivatives (Hessian matrix and phonon frequencies), whereas IBRION&#x3D;7 and IBRION&#x3D;8 use density functional perturbation theory to calculate the derivatives.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/15/keychain/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/15/keychain/" class="post-title-link" itemprop="url">keychain</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-15 16:43:51" itemprop="dateCreated datePublished" datetime="2024-06-15T16:43:51+08:00">2024-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:20" itemprop="dateModified" datetime="2024-07-30T00:45:20+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="vasp"><a href="#vasp" class="headerlink" title="vasp"></a>vasp</h1><p>changkui_duan1 cqupt413</p>
<h1 id="servers"><a href="#servers" class="headerlink" title="servers"></a>servers</h1><table>
<thead>
<tr>
<th>username</th>
<th>password</th>
<th>Authenticator</th>
</tr>
</thead>
<tbody><tr>
<td><a href="mailto:&#106;&#106;&#x63;&#x61;&#105;&#x40;&#50;&#x31;&#49;&#46;&#x38;&#x36;&#x2e;&#x31;&#53;&#x31;&#46;&#49;&#48;&#54;">&#106;&#106;&#x63;&#x61;&#105;&#x40;&#50;&#x31;&#49;&#46;&#x38;&#x36;&#x2e;&#x31;&#53;&#x31;&#46;&#49;&#48;&#54;</a></td>
<td>jjcai@wuli619b</td>
<td>GCPPNZY2DBKU5AVXBWOEQ467NM</td>
</tr>
<tr>
<td><a href="mailto:&#122;&#x68;&#x61;&#111;&#108;&#x75;&#48;&#49;&#x40;&#x32;&#x31;&#49;&#x2e;&#x38;&#54;&#46;&#49;&#53;&#49;&#46;&#49;&#x30;&#x36;">&#122;&#x68;&#x61;&#111;&#108;&#x75;&#48;&#49;&#x40;&#x32;&#x31;&#49;&#x2e;&#x38;&#54;&#46;&#49;&#53;&#49;&#46;&#49;&#x30;&#x36;</a></td>
<td>zhaolu01@619bphys</td>
<td>ZZAS2PLFJMV4EBI7TLLY3E5L4A</td>
</tr>
<tr>
<td><a href="mailto:&#x71;&#x69;&#x66;&#64;&#50;&#x31;&#x31;&#x2e;&#x38;&#x36;&#46;&#49;&#53;&#x31;&#x2e;&#x31;&#x30;&#x36;">&#x71;&#x69;&#x66;&#64;&#50;&#x31;&#x31;&#x2e;&#x38;&#x36;&#46;&#49;&#53;&#x31;&#x2e;&#x31;&#x30;&#x36;</a></td>
<td>lmz@qif@619b</td>
<td>V5WJEI5VLDRFJNROKA2Q4JG2GE</td>
</tr>
<tr>
<td><a href="mailto:&#x63;&#x6b;&#100;&#117;&#x61;&#110;&#x40;&#x32;&#49;&#x31;&#x2e;&#x38;&#54;&#x2e;&#49;&#53;&#x31;&#46;&#x31;&#x30;&#x36;">&#x63;&#x6b;&#100;&#117;&#x61;&#110;&#x40;&#x32;&#49;&#x31;&#x2e;&#x38;&#54;&#x2e;&#49;&#53;&#x31;&#46;&#x31;&#x30;&#x36;</a></td>
<td>uD#UrNyRh3Gn</td>
<td>VBX27BK5D6NJJG423KSJHQTVJY</td>
</tr>
<tr>
<td><a href="mailto:&#x6c;&#98;&#x62;&#48;&#55;&#64;&#x32;&#x31;&#x31;&#x2e;&#x38;&#54;&#46;&#x31;&#53;&#x31;&#x2e;&#49;&#x30;&#x36;">&#x6c;&#98;&#x62;&#48;&#55;&#64;&#x32;&#x31;&#x31;&#x2e;&#x38;&#54;&#46;&#x31;&#53;&#x31;&#x2e;&#49;&#x30;&#x36;</a></td>
<td>lbb07@wuli619b</td>
<td>MWSYQAA7EWJO6AVICFYCDYJUQA</td>
</tr>
<tr>
<td><a href="mailto:&#x63;&#107;&#x64;&#x75;&#x61;&#110;&#49;&#x40;&#x32;&#49;&#x31;&#46;&#56;&#x36;&#46;&#x31;&#x35;&#x31;&#x2e;&#x31;&#48;&#x36;">&#x63;&#107;&#x64;&#x75;&#x61;&#110;&#49;&#x40;&#x32;&#49;&#x31;&#46;&#56;&#x36;&#46;&#x31;&#x35;&#x31;&#x2e;&#x31;&#48;&#x36;</a></td>
<td>4tAR,OtEqbUr</td>
<td>LA7MUV6ZBFLD2QN5GMVG2HL2DU</td>
</tr>
<tr>
<td><a href="mailto:&#99;&#107;&#x64;&#117;&#x61;&#x6e;&#50;&#x40;&#x32;&#x31;&#x31;&#46;&#56;&#54;&#x2e;&#49;&#53;&#x31;&#x2e;&#49;&#48;&#x36;">&#99;&#107;&#x64;&#117;&#x61;&#x6e;&#50;&#x40;&#x32;&#x31;&#x31;&#46;&#56;&#54;&#x2e;&#49;&#53;&#x31;&#x2e;&#49;&#48;&#x36;</a></td>
<td>9oS!EmJ3g1EJ</td>
<td>STSMMMW27XRBH46U2N26EBYVOY</td>
</tr>
<tr>
<td><a href="mailto:&#100;&#117;&#103;&#x75;&#x65;&#120;&#x40;&#50;&#49;&#49;&#46;&#x38;&#54;&#x2e;&#x31;&#x35;&#x31;&#x2e;&#49;&#x31;&#x36;">&#100;&#117;&#103;&#x75;&#x65;&#120;&#x40;&#50;&#49;&#49;&#46;&#x38;&#54;&#x2e;&#x31;&#x35;&#x31;&#x2e;&#49;&#x31;&#x36;</a></td>
<td>V-ng6kAYHb</td>
<td>HV4AIOYZMQRVJIAYV7F7FUZ6PM</td>
</tr>
<tr>
<td><a href="mailto:&#99;&#x6b;&#x64;&#117;&#x61;&#110;&#x40;&#x31;&#49;&#x34;&#46;&#x32;&#49;&#x34;&#x2e;&#x32;&#48;&#x37;&#x2e;&#49;&#54;&#55;">&#99;&#x6b;&#x64;&#117;&#x61;&#110;&#x40;&#x31;&#49;&#x34;&#46;&#x32;&#49;&#x34;&#x2e;&#x32;&#48;&#x37;&#x2e;&#49;&#54;&#55;</a></td>
<td>lIZ@7U$OE%</td>
<td></td>
</tr>
</tbody></table>
<h1 id="material-project"><a href="#material-project" class="headerlink" title="material project"></a>material project</h1><p><a href="mailto:&#100;&#x75;&#x67;&#x75;&#101;&#x78;&#x40;&#49;&#x32;&#54;&#x2e;&#99;&#111;&#109;">&#100;&#x75;&#x67;&#x75;&#101;&#x78;&#x40;&#49;&#x32;&#54;&#x2e;&#99;&#111;&#109;</a> VUswQqBEWe4VFBZD25</p>
<p>xrayfree  <a target="_blank" rel="noopener" href="https://tt.vg/freev2">https://tt.vg/freev2</a><br>freefq <a target="_blank" rel="noopener" href="https://raw.fastgit.org/freefq/free/master/v2">https://raw.fastgit.org/freefq/free/master/v2</a><br>Pawdroid <a target="_blank" rel="noopener" href="https://ghproxy.com/https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub">https://ghproxy.com/https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub</a></p>
<h1 id="IBM-quantum-computer-token"><a href="#IBM-quantum-computer-token" class="headerlink" title="IBM quantum computer token"></a>IBM quantum computer token</h1><p>33a89599ff7db5c88718ebf7b9d35c2a72e863f23b6dd0ad3f582a54e2571cf9248f2c3e214c8d1c9d5c5387cb254f7964a9d1291580dd87aa36eb31b37fb159</p>
<h1 id="博士后基金"><a href="#博士后基金" class="headerlink" title="博士后基金"></a>博士后基金</h1><p>liumingzhe2024<br>Aa1?Aa1?Aa1?</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://tobedetermined.com/2024/06/14/todo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Mingzhe Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TODO">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | TODO">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/14/todo/" class="post-title-link" itemprop="url">todo</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-14 20:19:24" itemprop="dateCreated datePublished" datetime="2024-06-14T20:19:24+08:00">2024-06-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-30 00:45:21" itemprop="dateModified" datetime="2024-07-30T00:45:21+08:00">2024-07-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>future (vasp) tag<br>orca<br>网络代理 旁路由<br>测试节点性能 指令集 avx512<br>本地chatgpt<br>github actions<br>enrich va2ray订阅</p>
<p>Ollama<br><a target="_blank" rel="noopener" href="https://sspai.com/post/85193#">https://sspai.com/post/85193#</a>!<br><a target="_blank" rel="noopener" href="https://github.com/ollama/ollama#community-integrations">https://github.com/ollama/ollama#community-integrations</a><br><a target="_blank" rel="noopener" href="https://ollama.com/">https://ollama.com/</a><br><a target="_blank" rel="noopener" href="https://ollama.fan/getting-started/">https://ollama.fan/getting-started/</a><br>大模型联网 图片</p>
<p>SCAN vdw_kernel.bindat test</p>
<p>二代epyc …. 想想就离谱，windows咱没用过不清楚，unix下面，超微的bios内存还得手动设置L3 numa domain</p>
<p>Kubernetes</p>
<p>py4vasp</p>
<p>gpaw</p>
<h1 id="GTPack-A-Mathematica-Group"><a href="#GTPack-A-Mathematica-Group" class="headerlink" title="GTPack: A Mathematica Group"></a>GTPack: A Mathematica Group</h1><p>copy the GTPack folder “GroupTheory” to the Applications folder of Mathematica $UserBaseDirectory or $BaseDirectory.</p>
<p>Needs[“GroupTheory&#96;”] in notebook</p>
<p>file:&#x2F;&#x2F;&#x2F;D:&#x2F;portal&#x2F;old&#x2F;Group%20Theory%20in%20Solid%20State%20Physics%20and%20Photonics%20-%202018%20-%20Hergert.pdf<br>file:&#x2F;&#x2F;&#x2F;D:&#x2F;portal&#x2F;old&#x2F;2018%20gtpack.pdf</p>
<p>cluster expansion<br><a target="_blank" rel="noopener" href="https://publish.illinois.edu/atomicscale/cluster-expansion/">https://publish.illinois.edu/atomicscale/cluster-expansion/</a></p>
<p>jupyter ipython mpi</p>
<p>重复TDDFT <a target="_blank" rel="noopener" href="https://doi.org/10.1021/acs.jctc.3c00986">https://doi.org/10.1021/acs.jctc.3c00986</a></p>
<h1 id="ansible-like"><a href="#ansible-like" class="headerlink" title="ansible like"></a>ansible like</h1><h2 id="automation"><a href="#automation" class="headerlink" title="automation"></a>automation</h2><p>paramiko</p>
<h2 id="消息推送"><a href="#消息推送" class="headerlink" title="消息推送"></a>消息推送</h2><p>qq频道 机器人 botpy</p>
<h2 id="webui"><a href="#webui" class="headerlink" title="webui"></a>webui</h2><p>pywebio</p>
<h1 id="量子蒙特卡洛方法"><a href="#量子蒙特卡洛方法" class="headerlink" title="量子蒙特卡洛方法"></a>量子蒙特卡洛方法</h1><h1 id="Grad-DFT"><a href="#Grad-DFT" class="headerlink" title="Grad DFT"></a><a target="_blank" rel="noopener" href="https://github.com/XanaduAI/GradDFT">Grad DFT</a></h1><p>Grad DFT is a JAX-based library enabling the differentiable design and experimentation of exchange-correlation functionals using machine learning techniques. The library provides significant functionality, including (but not limited to) training neural functionals with fully differentiable and just-in-time compilable self-consistent-field loops, direct optimization of the Kohn-Sham orbitals, and implementation of many of the known constraints of the exact functional.</p>
<p>Density functional theory (DFT) stands as a cornerstone method in computational quantum chemistry and materials science due to its remarkable versatility and scalability. Yet, it suffers from limitations in accuracy, particularly when dealing with strongly correlated systems. To address these shortcomings, recent work has begun to explore how machine learning can expand the capabilities of DFT: an endeavor with many open questions and technical challenges. In this work, we present GradDFT a fully differentiable JAX-based DFT library, enabling quick prototyping and experimentation with machine learning-enhanced exchange–correlation energy functionals. GradDFT employs a pioneering parametrization of exchange–correlation functionals constructed using a weighted sum of energy densities, where the weights are determined using neural networks. Moreover, GradDFT encompasses a comprehensive suite of auxiliary functions, notably featuring a just-in-time compilable and fully differentiable self-consistent iterative procedure. To support training and benchmarking efforts, we additionally compile a curated dataset of experimental dissociation energies of dimers, half of which contain transition metal atoms characterized by strong electronic correlations. The software library is tested against experimental results to study the generalization capabilities of a neural functional across potential energy surfaces and atomic species, as well as the effect of training data noise on the resulting model accuracy.</p>
<h1 id="Retrieval-Augmented-Generation-RAG"><a href="#Retrieval-Augmented-Generation-RAG" class="headerlink" title="Retrieval-Augmented Generation (RAG)"></a>Retrieval-Augmented Generation (RAG)</h1><p>Nature 长文综述：类脑智能与脉冲神经网络前沿<br>Towards spike-based machine intelligence with neuromorphic computing</p>
<p>Brain cell census<br><a target="_blank" rel="noopener" href="https://www.science.org/toc/science/382/6667">https://www.science.org/toc/science/382/6667</a></p>
<p>AMD EPYC 9754 &amp; 9654基准测试：量子化学和第一性原理计算程序<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/659191428">https://zhuanlan.zhihu.com/p/659191428</a></p>
<p>PyCDFT: A Python package for constrained densityfunctional theory</p>
<p>ARM64 Mac 运行 AzurLaneAutoScript<br><a target="_blank" rel="noopener" href="https://www.binss.me/blog/run-azurlaneautoscript-on-arm64/">https://www.binss.me/blog/run-azurlaneautoscript-on-arm64/</a></p>
<p>p100机器<br><a target="_blank" rel="noopener" href="http://bbs.keinsci.com/thread-34411-1-1.html">http://bbs.keinsci.com/thread-34411-1-1.html</a></p>
<p>PyProcar<br><a target="_blank" rel="noopener" href="https://romerogroup.github.io/pyprocar/getting-started/index.html">https://romerogroup.github.io/pyprocar/getting-started/index.html</a></p>
<p>ASE<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/446086740">https://zhuanlan.zhihu.com/p/446086740</a></p>
<p>spack<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/426743137">https://zhuanlan.zhihu.com/p/426743137</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2310.14776.pdf">GPAW: open Python package for electronic-structure calculations</a></p>
<p>Uwe Gerstmann<br><a target="_blank" rel="noopener" href="https://journals.aps.org/prresearch/pdf/10.1103/PhysRevResearch.2.023071">https://journals.aps.org/prresearch/pdf/10.1103/PhysRevResearch.2.023071</a></p>
<p>A Comprehensive Overview of Large Language Models<br><a target="_blank" rel="noopener" href="https://arxiv.org/html/2307.06435v7">https://arxiv.org/html/2307.06435v7</a></p>
<p>Science in the age of large language models<br><a target="_blank" rel="noopener" href="https://www.nature.com/articles/s42254-023-00581-4">https://www.nature.com/articles/s42254-023-00581-4</a></p>
<p>All-electron density functional calculations for electron and nuclear spin interactions in molecules and solids<br><a target="_blank" rel="noopener" href="https://journals.aps.org/prmaterials/abstract/10.1103/PhysRevMaterials.3.043801">https://journals.aps.org/prmaterials/abstract/10.1103/PhysRevMaterials.3.043801</a></p>
<p>Spin–spin interactions in defects in solids from mixed all-electron and pseudopotential first-principles calculations<br><a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41524-021-00590-w">https://www.nature.com/articles/s41524-021-00590-w</a></p>
<p>Calculation of spin-spin zero-field splitting within periodic boundary conditions:<br>Towards all-electron accuracy<br><a target="_blank" rel="noopener" href="https://journals.aps.org/prb/pdf/10.1103/PhysRevB.97.115135">https://journals.aps.org/prb/pdf/10.1103/PhysRevB.97.115135</a></p>
<p>Excited State Properties of Point Defects in Semiconductors and Insulators Investigated with Time-Dependent Density Functional Theory<br><a target="_blank" rel="noopener" href="https://pubs.acs.org/doi/10.1021/acs.jctc.3c00986">https://pubs.acs.org/doi/10.1021/acs.jctc.3c00986</a></p>
<h1 id="PennyLane-Qiskit-Plugin"><a href="#PennyLane-Qiskit-Plugin" class="headerlink" title="PennyLane-Qiskit Plugin"></a>PennyLane-Qiskit Plugin</h1><h1 id="Overlapper-preparing-and-assessing-initial-states-for-quantum-algorithms-on-molecules"><a href="#Overlapper-preparing-and-assessing-initial-states-for-quantum-algorithms-on-molecules" class="headerlink" title="Overlapper: preparing and assessing initial states for quantum algorithms on molecules"></a>Overlapper: preparing and assessing initial states for quantum algorithms on molecules</h1><p>Many quantum algorithms for ground-state energy estimation of molecules require a high-quality initial state as a starting point. One way of preparing these states is by pre-computing a wavefunction using a traditional quantum chemistry wavefunction-based method.</p>
<p>The purpose of the Overlapper software library is to simplify the preparation of such initial states for molecules. By interfacing with packages implementing state-of-the-art quantum chemistry methods, most prominently coupled cluster with singles and doubles (CCSD), density-matrix renormalization group (DMRG) and semistochastic heat-bath configuration integration (SHCI), Overlapper provides easy access to initial states from these methods.</p>
<p>Beyond that, it transforms them into one of two unified formats, the sum of Slater determinants (SOS) or matrix-product state (MPS), and enables, for the first time, their straightforward comparison to each other – using either wavefunction overlap or the newly developed energy distribution picture.</p>
<h1 id="block2-DMRG-Density-Matrix-Renormalization-Group"><a href="#block2-DMRG-Density-Matrix-Renormalization-Group" class="headerlink" title="block2 DMRG (Density Matrix Renormalization Group)"></a>block2 DMRG (Density Matrix Renormalization Group)</h1><p><a target="_blank" rel="noopener" href="https://block2.readthedocs.io/en/latest/index.html">https://block2.readthedocs.io/en/latest/index.html</a></p>
<h1 id="在Rigetti的量子云服务（QCS）上使用pyquil-36-37-实现了这个Gutzwiller量子-经典嵌入（GQCE）模拟框架，并用它在量子计算机上进行了无限周期关联电子模型的第一次自洽计算。"><a href="#在Rigetti的量子云服务（QCS）上使用pyquil-36-37-实现了这个Gutzwiller量子-经典嵌入（GQCE）模拟框架，并用它在量子计算机上进行了无限周期关联电子模型的第一次自洽计算。" class="headerlink" title="在Rigetti的量子云服务（QCS）上使用pyquil[36,37]实现了这个Gutzwiller量子-经典嵌入（GQCE）模拟框架，并用它在量子计算机上进行了无限周期关联电子模型的第一次自洽计算。"></a>在Rigetti的量子云服务（QCS）上使用pyquil[36,37]实现了这个Gutzwiller量子-经典嵌入（GQCE）模拟框架，并用它在量子计算机上进行了无限周期关联电子模型的第一次自洽计算。</h1><p>cRPA</p>
<p>量子子空间扩展方法得到激发态</p>
<p>OpenFermion</p>
<h1 id="徐勇"><a href="#徐勇" class="headerlink" title="徐勇"></a>徐勇</h1><p>报告摘要：</p>
<p>　　从发现量子力学到材料计算预测经历了上百年的发展，由此诞生了以密度泛函理论为代表的第一性原理计算方法，从此原子、电子层次的材料计算设计变为可能。然而，受限于高昂的计算代价，第一性原理方法只适用于小尺寸材料计算；数据驱动的材料发现被认为是富有潜力的未来发展方向，但现有第一性原理材料数据库规模太小，离真正意义的材料大数据还很遥远，这也极大地限制了该领域发展。近年来，AlphaGo、AlphaFold、ChatGPT等代表性工作的出现宣誓了人工智能新时代的来临，第一性原理计算领域也迎来了变革性转变的历史机遇。</p>
<p>　　在该报告中，我将介绍一个新兴的研究方向——第一性原理人工智能，即利用先进的人工神经网络方法克服第一性原理计算面临的效率瓶颈，为未来物理、材料发现带来新的研究范式。作为最新的进展之一，我将重点介绍一种普适的、泛化能力极强的深度学习哈密顿量模型DeepH [1-10]，它用神经网络替代复杂的密度泛函理论自洽计算，在保持第一性原理精度的同时可将计算效率提升多个量级；更为重要的是，随着训练数据的增加，神经网络方法将变得越来越智能，能演化出高效的材料生成模型，实现人工智能驱动的新物理、新材料发现。上述工作展示了第一性原理人工智能的巨大优势，将深刻改变科学计算与材料发现的未来发展。 </p>
<p>参考文献：</p>
<p>[1] H. Li, et al. Nature Computational Science 2, 367 (2022)</p>
<p>[2] X. Gong, et al. Nature Communications 14, 2848 (2023)</p>
<p>[3] H. Li, et al. Nature Computational Science Sci. 3, 321 (2023) 封面文章</p>
<p>[4] H. Li, et al. Materials Genome Engineering Advances e16 (2023)</p>
<p>[5] H. Li, et al. Physical Review Letters 132, 096401 (2024) 编辑推荐</p>
<p>[6] Z. Tang, et al., arXiv:2302.08221</p>
<p>[7] Z Yuan, et al., arXiv:2402.04864</p>
<p>[8] Y Wang, et al., arXiv:2401.17015</p>
<p>[9] T. Bao, et al. arXiv:2404.06449</p>
<p>[10] Y. Li, et al. arXiv:2403.11287</p>
<p>报告人简介：</p>
<p>　　徐勇，清华大学物理系长聘教授、日本理化学研究所 (RIKEN) 兼职研究员、国家杰出青年基金获得者、科睿唯安全球高被引科学家。主要研究方向：拓扑量子物态、第一性原理计算、人工智能驱动的科学发现。</p>
<p>去玩本地部署的酒馆，claude3写小作文+sd生图+sovist朗读<br>C站还能直接用他们服务器出图<br>comfyui</p>
<h1 id="日月同辉"><a href="#日月同辉" class="headerlink" title="日月同辉"></a>日月同辉</h1><p>sunshine是布置在电脑pc端的作为云端，接收端的是moonlight，只要你能在你设备上下moonlight，且能保持和pc在同一局域网下就行。</p>
<p>指定节点<br>加tag<br>kill显示</p>
<h1 id="跃迁矩阵元"><a href="#跃迁矩阵元" class="headerlink" title="跃迁矩阵元"></a>跃迁矩阵元</h1><p><a target="_blank" rel="noopener" href="https://wiki.fysik.dtu.dk/gpaw/_modules/gpaw/lcao/dipoletransition.html#get_momentum_transitions">https://wiki.fysik.dtu.dk/gpaw/_modules/gpaw/lcao/dipoletransition.html#get_momentum_transitions</a></p>
<p><a target="_blank" rel="noopener" href="https://journals.aps.org/prb/cited-by/10.1103/PhysRevB.56.14985?page=1">https://journals.aps.org/prb/cited-by/10.1103/PhysRevB.56.14985?page=1</a></p>
<h1 id="Momentum-matrix-element"><a href="#Momentum-matrix-element" class="headerlink" title="Momentum-matrix-element"></a>Momentum-matrix-element</h1><p>Momentum-matrix-element calculation using pseudopotentials</p>
<h1 id="Xingao-Gong"><a href="#Xingao-Gong" class="headerlink" title="Xingao Gong"></a>Xingao Gong</h1><p>HamGNN<br>Universal Machine Learning Kohn-Sham Hamiltonian for<br>Materials<br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2402.09251">https://arxiv.org/pdf/2402.09251</a></p>
<h1 id="spack"><a href="#spack" class="headerlink" title="spack"></a><a target="_blank" rel="noopener" href="https://spack.readthedocs.io/en/latest/index.html">spack</a></h1>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Mingzhe Liu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
